<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>My AI Blog</title><link>https://hobbytp.github.io/</link><description>Recent content on My AI Blog</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Tue, 13 May 2025 23:03:00 +0800</lastBuildDate><atom:link href="https://hobbytp.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Qwen3 Tech Report解读</title><link>https://hobbytp.github.io/zh/qwen/qwen3/</link><pubDate>Tue, 13 May 2025 23:03:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/qwen/qwen3/</guid><description>全方位解读Qwen3的论文技术报告</description></item><item><title>Agent经济：红杉资本2025 AI峰会释放的超级信号</title><link>https://hobbytp.github.io/my_insights/ai_ascent_2025/</link><pubDate>Tue, 13 May 2025 15:10:00 +0800</pubDate><guid>https://hobbytp.github.io/my_insights/ai_ascent_2025/</guid><description>Agent经济：红杉资本2025 AI峰会释放的超级信号</description></item><item><title>日常想法随手记-2025</title><link>https://hobbytp.github.io/my_insights/daily_thinks_2025/</link><pubDate>Tue, 13 May 2025 14:20:00 +0800</pubDate><guid>https://hobbytp.github.io/my_insights/daily_thinks_2025/</guid><description>日常想法随手记</description></item><item><title>Reinforced Self-play Reasoning with Zero Data 论文解读</title><link>https://hobbytp.github.io/papers/reinforced_selfplay_reasoning_w_zero_data/</link><pubDate>Sun, 11 May 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/papers/reinforced_selfplay_reasoning_w_zero_data/</guid><description>论文介绍了强化自博弈推理的零数据范式，通过自博弈生成任务和验证，实现无需依赖人工标注数据或预设任务的自主学习推理。</description></item><item><title>OpenAI: AI in the Enterprise</title><link>https://hobbytp.github.io/big_companies/openai_ai_in_the_enterprise/</link><pubDate>Tue, 06 May 2025 20:14:00 +0800</pubDate><guid>https://hobbytp.github.io/big_companies/openai_ai_in_the_enterprise/</guid><description>OpenAI关于企业级AI应用的详细简报</description></item><item><title>模型上下文协议（MCP）深度解析：Agent互操作性的新纪元</title><link>https://hobbytp.github.io/zh/claude/mcp_analysis/</link><pubDate>Tue, 29 Apr 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/claude/mcp_analysis/</guid><description>本文介绍了模型上下文协议（MCP），并对其技术原理、主要贡献、当前优劣、生态系统现状，并与Google A2A等相关技术进行比较，展望其未来发展趋势。</description></item><item><title>模型上下文协议（MCP）深度解析：Agent互操作性的新纪元</title><link>https://hobbytp.github.io/zh/claude/mcp_usecases/</link><pubDate>Tue, 29 Apr 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/claude/mcp_usecases/</guid><description>本文介绍了模型上下文协议（MCP），并对其技术原理、主要贡献、当前优劣、生态系统现状，并与Google A2A等相关技术进行比较，展望其未来发展趋势。</description></item><item><title>Python 3.x 高级语法与语言特性深度剖析</title><link>https://hobbytp.github.io/technologies/python3/</link><pubDate>Tue, 22 Apr 2025 10:34:00 +0800</pubDate><guid>https://hobbytp.github.io/technologies/python3/</guid><description>Python 3.x 高级语法与语言特性深度剖析</description></item><item><title>Python 的 orjson 库</title><link>https://hobbytp.github.io/technologies/python_orjson/</link><pubDate>Tue, 22 Apr 2025 10:34:00 +0800</pubDate><guid>https://hobbytp.github.io/technologies/python_orjson/</guid><description>Python 的 orjson 库</description></item><item><title>编程能力对比分析一撇</title><link>https://hobbytp.github.io/zh/validation/code_level/</link><pubDate>Sun, 20 Apr 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/validation/code_level/</guid><description>关于编程能力对比分析一撇</description></item><item><title>我在AI领域的一些思考</title><link>https://hobbytp.github.io/my_insights/mythinkings/</link><pubDate>Sun, 20 Apr 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/my_insights/mythinkings/</guid><description>我在AI领域的一些思考</description></item><item><title>EMOS: Embodiment-Aware Multi-Robot Operating System with LLM Agents</title><link>https://hobbytp.github.io/zh/robot/emos/</link><pubDate>Fri, 18 Apr 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/robot/emos/</guid><description>本文介绍了EMOS: Embodiment-Aware Multi-Robot Operating System with LLM Agents，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>Google: 一种通往技术通用人工智能安全的方法</title><link>https://hobbytp.github.io/zh/agi/google_safety_security_approach/</link><pubDate>Thu, 17 Apr 2025 20:20:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/agi/google_safety_security_approach/</guid><description>本文介绍了Google关于AGI安全的技术报告，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>Agent经济：红杉资本2025 AI峰会释放的超级信号</title><link>https://hobbytp.github.io/draft/deepresearch/</link><pubDate>Sun, 13 Apr 2025 15:10:00 +0800</pubDate><guid>https://hobbytp.github.io/draft/deepresearch/</guid><description>Agent经济：红杉资本2025 AI峰会释放的超级信号</description></item><item><title>Cursor AI 最佳实践：提升编码效率与代码质量的权威指南</title><link>https://hobbytp.github.io/zh/products/cursor/</link><pubDate>Sat, 12 Apr 2025 21:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/products/cursor/</guid><description>Cursor AI 最佳实践：提升编码效率与代码质量的权威指南</description></item><item><title>Agent2Agent (A2A) 协议</title><link>https://hobbytp.github.io/zh/google/a2a/</link><pubDate>Sat, 12 Apr 2025 16:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/google/a2a/</guid><description>本文介绍了Google公司A2A协议详细解读。</description></item><item><title>Llama 4 模型系列</title><link>https://hobbytp.github.io/zh/llama/llama4/</link><pubDate>Thu, 03 Apr 2025 16:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/llama/llama4/</guid><description>本文介绍了Llama 4 模型系列详细解读。</description></item><item><title>CAMEL 工具包</title><link>https://hobbytp.github.io/zh/camel/camel_tools/</link><pubDate>Wed, 19 Mar 2025 23:20:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/camel/camel_tools/</guid><description>CAMEL Tools CAMEL工具包是一个模块化框架，旨在通过统一接口扩展AI智能体的能力，使其能够连接外部服务、数据源和计算工具。它提供了多种工具包，涵盖搜索、学术、社交媒体、数据分析、媒体处理、开发、金融和生产力等领域，帮助开发者加速开发、提升可靠性并简化API集成。
CAMEL工具包通过一致的API设计（基于BaseToolkit类）和模型上下文协议（MCP）标准化了工具使用，简化了学习和实施过程。 工具包解决了API集成开销、不一致的接口、网络和错误处理以及维护问题。 主要工具包包括： 网络和搜索工具包：支持多种搜索引擎和知识库，提供实时数据访问。 学术和研究工具包：如arXiv、Google Scholar、PubMed等，专注于学术文献检索和分析。 社交媒体和通信工具包：如Twitter、Reddit、LinkedIn等，支持社交媒体数据分析和交互。 数据分析和计算工具包：如数学、SymPy、NetworkX等，支持数学运算、网络分析和数据处理。 媒体处理工具包：如DALL-E、音频分析、视频分析等，用于图像、音频和视频内容的生成和分析。 开发和编码工具包：如GitHub、终端、代码执行工具包等，支持开发者任务自动化。 金融和商业工具包：如Stripe、OpenBB等，支持支付处理和金融数据分析。 生产力和集成工具包：如MCP、Notion、Excel等，支持项目管理、文档处理和跨平台集成。 CAMEL工具包的优势包括：加速开发、一致接口、可组合性、可靠性与未来兼容性。 不同工具包适用于不同场景，如信息获取、业务优化、创意生成、开发辅助和复杂AI系统。 CAMEL框架通过模块化设计支持工具包的轻松更新和扩展，满足不断变化的市场需求。 1. 网络和搜索类工具包 工具包名称 主要功能 适用场景 搜索工具包 • Google、Bing、DuckDuckGo等搜索引擎集成
• Tavily、Linkup专业搜索
• Wikipedia、Wolfram Alpha知识库访问 • 事实查询
• 最新信息获取
• 研究助手开发 浏览器工具包 • 网页导航
• 内容提取
• 表单填写
• 会话管理 • 网站数据抓取
• 表单自动化
• 电商助手开发 天气工具包 • 全球天气数据获取
• 天气预报
• 历史记录查询 • 旅行规划
• 物流路线优化
• 环境感知服务 2. 学术和研究类工具包 工具包名称 主要功能 适用场景 Arxiv工具包 • 科学论文搜索</description></item><item><title>雷·达里奥：美国隐藏的内战，以及在技术，经济和学术界击败中国的竞赛</title><link>https://hobbytp.github.io/zh/agi/ai_usa_impact/</link><pubDate>Thu, 06 Mar 2025 22:50:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/agi/ai_usa_impact/</guid><description>本文介绍了雷·达里奥（Ray Dalio）与塔克·卡尔森（Tucker Carlson）之间一场深刻而广泛的对话，涉及美国社会内部的分裂状态、人工智能技术的颠覆性影响、中美之间的科技竞争，以及人际关系、社会和谐与教育在未来社会中的关键作用。</description></item><item><title>QwQ-32B Qwen推理大模型解读</title><link>https://hobbytp.github.io/zh/qwen/qwq32b/</link><pubDate>Thu, 06 Mar 2025 20:21:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/qwen/qwq32b/</guid><description>本文介绍了深度求索（DeepSeek）公司推出的新一代推理模型QwQ-32B，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>Chain of Draft 论文解读</title><link>https://hobbytp.github.io/zh/cod-chain-of-draft/</link><pubDate>Sat, 01 Mar 2025 20:00:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/cod-chain-of-draft/</guid><description>本文介绍了Chain of Draft（CoD）论文，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>微调</title><link>https://hobbytp.github.io/zh/finetuning/</link><pubDate>Wed, 26 Feb 2025 22:14:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/finetuning/</guid><description>本文介绍了微调的常见挑战及其克服方法，并详细介绍了如何使用Unsloth在消费级GPU上对DeepSeek-R1进行微调。</description></item><item><title>DeepSeek FlashMLA 代码解读</title><link>https://hobbytp.github.io/zh/deepseek/deepseek_flashmla/</link><pubDate>Mon, 24 Feb 2025 16:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/deepseek/deepseek_flashmla/</guid><description>本文介绍了深度求索（DeepSeek）公司FlashMLA代码详细解读。</description></item><item><title>Google AI协同科学家系统</title><link>https://hobbytp.github.io/zh/google_ai_co-scientist/</link><pubDate>Thu, 20 Feb 2025 22:40:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/google_ai_co-scientist/</guid><description>本文介绍了Google开发的AI协同科学家系统（AI co-scientist），并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>Test-Time Scaling 相关论文解读</title><link>https://hobbytp.github.io/zh/test_time_scaling/</link><pubDate>Wed, 19 Feb 2025 16:40:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/test_time_scaling/</guid><description>本文介绍了Test-Time Scaling（测试时扩展）的概念，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>DeepSeek 开源 LLM 对闭源 LLM 的影响</title><link>https://hobbytp.github.io/zh/deepseek/deepseek_impact/</link><pubDate>Tue, 18 Feb 2025 23:20:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/deepseek/deepseek_impact/</guid><description>本文介绍了DeepSeek开源LLM对闭源LLM的影响，包括性能基准测试和竞争、成本效益、开源可用性和定制、市场动态和战略转变、创新与社区发展、环境影响以及AI研究和应用的转变。</description></item><item><title>OpenAI 推理模型最佳实践总结</title><link>https://hobbytp.github.io/zh/openai/openai_bestpractise/</link><pubDate>Fri, 14 Feb 2025 20:54:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/openai/openai_bestpractise/</guid><description>本文总结了OpenAI推理模型最佳实践。</description></item><item><title>OpenAI 推理模型最佳实践总结</title><link>https://hobbytp.github.io/zh/openai_bestpractise/</link><pubDate>Fri, 14 Feb 2025 20:54:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/openai_bestpractise/</guid><description>本文总结了OpenAI推理模型最佳实践。</description></item><item><title>DeepSeek V3 论文解读</title><link>https://hobbytp.github.io/zh/deepseek/deepseek_v3/</link><pubDate>Fri, 14 Feb 2025 18:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/deepseek/deepseek_v3/</guid><description>本文介绍了深度求索（DeepSeek）公司推出的新一代推理模型DeepSeek-V3，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>DeepSeek 微调</title><link>https://hobbytp.github.io/zh/deepseek/deepseek-finetuning/</link><pubDate>Fri, 14 Feb 2025 18:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/deepseek/deepseek-finetuning/</guid><description>本文介绍了如何使用合成推理数据集微调DeepSeek-R1模型.</description></item><item><title>字节跳动OmniHuman-1 开源项目解读</title><link>https://hobbytp.github.io/zh/bytedancing/bytedancing_omnihuman/</link><pubDate>Tue, 11 Feb 2025 20:22:48 +0800</pubDate><guid>https://hobbytp.github.io/zh/bytedancing/bytedancing_omnihuman/</guid><description>字节跳动开源的OmniHuman-1项目，并对其技术原理、功能特点、应用前景和伦理风险进行了详细解读。</description></item><item><title>Simple Test-Time Scaling 论文解读</title><link>https://hobbytp.github.io/zh/s1_simple_testtimescaling/</link><pubDate>Mon, 10 Feb 2025 21:36:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/s1_simple_testtimescaling/</guid><description>本文介绍了来自李飞飞团队的Simple Test-Time Scaling论文，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>DeepSeek R1 Paper Review</title><link>https://hobbytp.github.io/en/deepseek_r1/</link><pubDate>Mon, 10 Feb 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/en/deepseek_r1/</guid><description>A comprehensive review of the DeepSeek R1 paper</description></item><item><title>DeepSeek R1 论文解读</title><link>https://hobbytp.github.io/zh/deepseek/deepseek_r1/</link><pubDate>Mon, 10 Feb 2025 20:10:00 +0800</pubDate><guid>https://hobbytp.github.io/zh/deepseek/deepseek_r1/</guid><description>本文介绍了深度求索（DeepSeek）公司推出的新一代推理模型DeepSeek-R1，并对其技术原理、主要贡献、论文方法、评估结果和局限性进行了详细解读。</description></item><item><title>欢迎来到我的AI博客</title><link>https://hobbytp.github.io/posts/welcome/</link><pubDate>Sat, 06 Apr 2024 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/posts/welcome/</guid><description>这是一个专注于AI领域的技术博客，包含论文解读、技术分析、项目介绍等内容</description></item><item><title>示例论文解读：GPT-4 技术报告解析</title><link>https://hobbytp.github.io/papers/example/</link><pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/papers/example/</guid><description>深入解读 GPT-4 技术报告的关键创新点和技术突破</description></item><item><title/><link>https://hobbytp.github.io/big_companies/google_ai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/big_companies/google_ai/</guid><description>整体概况 Gemini Google AI Studio Google Learn about Google Vertex AI Google Cloud AI Google AI Research</description></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/andrawwu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/andrawwu/</guid><description/></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/andrej_karpathy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/andrej_karpathy/</guid><description/></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/elonmusk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/elonmusk/</guid><description/></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/feifeilee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/feifeilee/</guid><description/></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/geoffrey_hinton/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/geoffrey_hinton/</guid><description/></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/ilyasutskever/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/ilyasutskever/</guid><description/></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/luqi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/luqi/</guid><description>当前大模型的春秋战国时代 当前scaling law的情况 当前scaling law的进展 当前scaling law的进展</description></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/samaltman/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/samaltman/</guid><description>访谈 访谈Sam Altman https://mp.weixin.qq.com/s/Fc9k0w3FTzXfM21YtMGLzw</description></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/stephen_wolfram/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/stephen_wolfram/</guid><description>Stephen Wolfram：计算宇宙的拓荒者 斯蒂芬·沃尔弗拉姆（Stephen Wolfram），1959年出生于伦敦，是一位横跨物理学、数学和人工智能（AI）领域的多才多艺科学家、企业家和思想家。他以非凡的学术天赋、创新精神和争议性理论闻名于世。
早年天赋与学术成就 沃尔弗拉姆12岁开始编写物理词典，15岁发表物理学论文，20岁获加州理工学院（Caltech）理论物理学博士学位，导师包括理查德·费曼（Richard Feynman）。21岁时，他成为最年轻的麦克阿瑟奖学金（MacArthur Fellowship）获得者。早期研究聚焦粒子物理和量子场论，发表多篇论文，展现了超凡的学术能力。
其研究领域横跨粒子物理、元胞自动机、复杂性理论、人工智能等，尤其在计算科学范式的推广上被视为先驱。他提出的“计算等价性原理”和“计算不可约性”概念，被认为揭示了复杂系统演化的本质规律。
个性与工作方式 沃尔弗拉姆以自信、独立和高度系统化著称。他习惯收集个人数据（如25年邮件、击键次数等），日常生活高度结构化，每天从上午10:30工作至凌晨2点，采用块状时间管理。他坦言自己比大多数人更聪明，这促使他充分利用才智。部分人认为他谦逊平易近人，也有人觉得他自信甚至近乎傲慢，尤其在其理论未经过传统同行评审时。家庭对他有一定影响，近年来因孩子鼓励才开始更多旅行。
科学贡献与创新 物理学与复杂系统 沃尔弗拉姆早期在粒子物理领域取得显著成就，后转向复杂系统和细胞自动机研究。在普林斯顿高等研究院与费曼合作，利用细胞自动机模拟物理过程。2002年，他出版了《一种新科学》（A New Kind of Science），提出自然界复杂性可由简单计算规则生成，挑战传统物理学范式。2020年，他发起沃尔弗拉姆物理项目（Wolfram Physics Project），试图用超图和最小改写规则解释宇宙法则，声称能重现相对论和量子力学核心结果。尽管这些理论因缺乏实验验证和定量预测而备受争议，但为物理学提供了全新视角。
贡献领域 详情 年份 备注 粒子物理研究 15岁发表论文，1980年获博士学位 1970s-80s 早期成就显著 复杂系统与细胞自动机 与费曼合作，提出计算规则解释复杂性 1980s 奠定《一种新科学》基础 《一种新科学》 简单规则生成复杂性，引发争议 2002 A New Kind of Science 沃尔弗拉姆物理项目 用超图和改写规则解释物理定律，争议性理论 2020 Wolfram Physics Project 数学与计算工具 沃尔弗拉姆在数学领域的最大贡献是开发了Mathematica（1988年）和Wolfram Language（2014年正式命名），极大提升了科学计算效率。Mathematica成为科学、工程和数学研究的标准工具，被NASA用于火星探测轨道优化，也被《财富》500强公司广泛采用。他还曾开发SMP（Symbolic Manipulation Program），但因知识产权纠纷辞职。Wolfram Research公司坚持私有化运营，以“超越科技计算极限”为目标，成为科技创新的标杆企业。
AI与知识计算 2009年，沃尔弗拉姆推出Wolfram Alpha——一款基于自然语言处理的知识计算引擎，被集成至Siri等平台，广泛应用于教育和专业领域。Wolfram Language集成计算智能，推动AI在编程和知识表示中的应用。他的细胞自动机和复杂系统研究为AI理解复杂行为提供理论基础。沃尔弗拉姆认为AI本质是计算模拟，受限于&amp;quot;计算不可约性&amp;quot;，对AI热潮持冷静批判态度，强调AI目标由人类设定。
贡献领域 详情 年份 备注 Wolfram Alpha 基于自然语言处理的知识引擎，支持API扩展 2009 Wolfram Alpha Wolfram Language 多范式编程语言，集计算智能，增强AI应用 2014 之前通过Mathematica提供 细胞自动机与复杂系统 提出计算规则解释复杂性，被广泛引用 1980s 影响AI复杂行为研究 方法论与哲学 沃尔弗拉姆以高强度专注著称，曾用4000多个夜晚完成《一种新科学》，并建立个性化时间管理与文档系统。他倡导&amp;quot;万物皆计算&amp;quot;哲学，试图用计算思维统一解释物理宇宙，将相对论、量子力学纳入计算框架。这种跨界整合能力和高效生产力模式备受业界关注。</description></item><item><title/><link>https://hobbytp.github.io/celebrity_insights/yann_lecun/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/celebrity_insights/yann_lecun/</guid><description/></item><item><title/><link>https://hobbytp.github.io/draft/mas_comparing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/draft/mas_comparing/</guid><description>人工智能多智能体系统：架构、交互与应用综合研究报告 1. 引言 1.1 目的与范围 多智能体系统（Multi-Agent Systems, MAS）作为人工智能（AI）和分布式系统领域的一个重要范式，近年来受到了广泛关注 1。本报告旨在基于英文学术文献和技术文档，对不同的人工智能多智能体系统进行全面的调研、分析和比较，并以中文形式呈现研究结果。报告将系统性地探讨MAS的定义、核心概念、关键组件、不同架构类型、典型框架与实例、智能体间的通信机制、协调与协商策略、学习能力（特别是多智能体强化学习）以及主要应用领域，最终进行综合比较分析。
1.2 MAS的重要性 MAS之所以日益重要，在于其独特的解决复杂问题的能力。许多现实世界的问题对于单个智能体或单一的、集成的（monolithic）系统而言过于庞大或复杂，难以有效解决 1。MAS通过将问题分解，利用多个自主智能体的交互与协作，能够应对这种复杂性 3。此外，MAS天然适用于分布式环境，其架构特性使其具备良好的灵活性、可扩展性和鲁棒性，能够适应动态变化的环境 14。这些优势使得MAS在机器人、智能电网、交通管理、电子商务、社会模拟等众多领域展现出巨大的应用潜力 1。
1.3 报告结构 本报告结构如下：第二部分介绍MAS的基础知识，包括定义、核心概念和关键组件；第三部分探讨MAS的不同架构分类；第四部分介绍著名的MAS框架和实例；第五部分分析智能体间的通信语言与协议；第六部分研究MAS中的协调、合作与协商策略；第七部分深入探讨MAS的学习能力，特别是MARL；第八部分识别MAS的主要应用领域；第九部分对不同MAS进行综合比较与分析；最后，第十部分总结研究发现并展望未来发展方向。
2. 多智能体系统基础 2.1 定义与核心概念 定义： 多智能体系统（MAS）通常被定义为由多个交互的、自主的智能体组成的计算或分布式系统 1。这些智能体可以是软件程序、物理机器人、传感器、无人机，甚至是人类或人机混合团队 1。它们共同存在于一个共享的环境中，通过感知环境、进行决策并采取行动来实现各自或集体的目标 1。
智能体： “智能体”（Agent）是MAS的核心构成单元，它是一个能够自主行动的实体 14。智能体能够感知其所处的环境（物理或虚拟），基于感知信息和内部知识进行推理和决策，并执行动作以影响环境，旨在达成其预设的目标或任务 1。根据其能力和行为复杂性，智能体可以被分为不同类型，例如：被动智能体（无目标，如环境中的障碍物）、主动智能体（具有简单目标，如鸟群中的鸟）和认知智能体（能够进行复杂计算和推理）1。
智能体特征： MAS中的智能体通常具备以下关键特征：
自主性（Autonomy）: 智能体至少是部分独立的，能够控制自身的内部状态和行为，无需外部直接干预 1。 局部视角（Local Views）: 通常情况下，没有一个智能体拥有完整的全局信息或系统状态视图，或者系统过于复杂以至于单个智能体无法利用全局知识 1。 去中心化（Decentralization）: 系统中通常没有指定的中心控制器（除非特殊设计，但这可能使其退化为单体系统），控制和决策权分布在各个智能体中 1。 交互性（Interaction）: 智能体之间通过通信、协调、合作或竞争等方式进行交互，以实现个体或集体目标 2。 与其他范式的区别： MAS与传统的软件范式（如面向对象编程）和单体AI系统有所不同。与对象（Object）主要封装状态并通过方法被动调用不同，智能体主动控制自身的行为，决定何时以及如何行动 4。与单体AI系统相比，MAS强调分布式、自主性、智能体间的交互以及可能的专业化分工 14。
MAS作为隐喻与工具： MAS不仅仅是一种工程范式，用于构建复杂的分布式系统，它也提供了一种强大的隐喻和工具，用于建模和理解自然界和社会系统中的复杂现象 1。例如，基于智能体的建模（Agent-Based Modeling, ABM）旨在通过模拟遵守简单规则的个体智能体（不一定需要“智能”）的行为，来探究群体行为的涌现机制，尤其是在自然系统（如鸟群、捕食者-猎物模型）或社会系统（如市场动态、流行病传播、交通流）中 1。这种双重角色——既是解决工程问题的方案，又是理解复杂现象的科学工具——深刻影响着MAS的设计理念和评估标准。用于工程应用的MAS可能更侧重于效率、鲁棒性和任务完成度，而用于科学建模的MAS则可能更注重行为的真实性、模型的解释力和对现象的洞察力 1。
2.2 关键组件 一个典型的MAS由以下几个关键组件构成：
智能体（Agents）: 系统的核心执行者，拥有特定的角色、能力、行为模式和知识模型 1。智能体的智能性体现在其学习、规划、推理和决策能力上 14。 环境（Environment）: 智能体所处的外部世界，可以是物理空间（如工厂、道路、电网）或模拟空间 1。智能体通过传感器感知环境状态，并通过执行器对环境施加影响 14。环境的特性，如可访问性（能否获取完整信息）、确定性（动作效果是否确定）、动态性（环境变化速度和影响因素）、离散性等，都会影响MAS的设计和行为 1。 交互/通信（Interactions/Communication）: 智能体之间进行信息交换和协调的机制。这可以通过标准化的智能体通信语言（ACL）进行显式通信 3，也可以通过环境进行间接通信，例如留下信息素（pheromone）供其他智能体感知 1。 组织/结构（Organization/Structure）: 定义了智能体之间的关系、角色和控制流程。组织结构可以是预定义的，如层级式控制 14，也可以是动态形成的，基于智能体交互和自组织规则 14。 2.</description></item><item><title/><link>https://hobbytp.github.io/en/weekly_paper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/en/weekly_paper/</guid><description/></item><item><title/><link>https://hobbytp.github.io/zh/agi/agi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/agi/agi/</guid><description>参考 https://tongyi.aliyun.com/efficiency/doc/read?taskId=5036083</description></item><item><title/><link>https://hobbytp.github.io/zh/base/attention_is_all_you_need/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/base/attention_is_all_you_need/</guid><description>Transformer 模型学习指南 I. 复习大纲
引言 •序列转换模型的局限性（循环神经网络和卷积神经网络）。 •Transformer 模型的提出：完全基于注意力机制，摒弃循环和卷积。 •Transformer 模型的优点：并行化能力强，训练时间短，翻译质量高。 •Transformer 模型在机器翻译和英语成分句法分析上的成功应用。
背景 •减少序列计算的必要性。 •卷积神经网络模型（Extended Neural GPU, ByteNet, ConvS2S）的并行计算方式及其局限性。 •自注意力机制的定义和应用。 •Transformer 模型与其他模型的区别和优势。
模型架构 •3.1 编码器和解码器堆栈编码器： •N=6 个相同的层堆叠而成。 •每一层包含两个子层：多头自注意力机制和位置式全连接前馈网络。 •残差连接和层归一化。 •所有子层和嵌入层的输出维度 dmodel = 512。 •解码器： •N=6 个相同的层堆叠而成。 •每一层包含三个子层：多头自注意力机制，编码器输出的多头注意力机制和位置式全连接前馈网络。 •残差连接和层归一化。 •掩码机制防止解码器关注后续位置。 •3.2 注意力机制定义：将查询（query）和键值对（key-value pairs）映射到输出的函数。 •输出是值的加权和，权重由查询与对应键的兼容性函数计算。 •3.2.1 缩放点积注意力（Scaled Dot-Product Attention）：计算查询和所有键的点积，除以 √dk，应用 softmax 函数得到权重。 •公式：Attention(Q, K, V) = softmax(QKT/√dk)V •与加性注意力（additive attention）的比较。 •3.2.2 多头注意力（Multi-Head Attention）：将查询、键和值线性投影 h 次到不同的 dk、dk 和 dv 维度。 •在每个投影版本上并行执行注意力函数。 •将输出连接并再次投影得到最终值。 •公式：MultiHead(Q, K, V) = Concat(head1, &amp;hellip;, headh)WO •head_i = Attention(QWQ_i, KWK_i, VWV_i) •优点：允许模型共同关注来自不同表示子空间的信息。 •3.</description></item><item><title/><link>https://hobbytp.github.io/zh/base/embedding_vector_app/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/base/embedding_vector_app/</guid><description>什么是 Vector 数据库？ Vector 数据库在自然语言处理、Image Recognition、推荐系统和语义搜索等各个领域发挥着举足轻重的作用，并随着 LLM 的日益普及而变得更加重要。
这些数据库具有非凡的价值，因为它们为 LLM 提供了获取实时专有数据的 Accessibility，使得开发 Retrieval Augmentation (RAG) 应用程序成为可能。
矢量数据库的核心是依靠使用 Embedding 来捕捉数据的含义，并衡量不同矢量对之间的相似性，在大量数据集中进行筛选，找出最相似的矢量。
本课程将帮助您获得相关知识，以便就何时在应用程序中应用 Vector 数据库做出明智的决定。您将探索
如何使用 Vector 数据库和 LLM 深入洞察您的数据。
建立实验室，展示如何形成 Embedding 并使用多种搜索技术查找相似的嵌入。
探索在庞大的数据集中进行快速搜索的算法，并构建从 Algorithm 到多语言搜索的各种应用。
Coursera : Vector Database Fundamentals 专项课程
Coursera : Vector Databases from Embeddings to Applications 课程</description></item><item><title/><link>https://hobbytp.github.io/zh/base/neuralnetworks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/base/neuralnetworks/</guid><description>为什么说神经网络几乎可以学习任何东西？ 核心观点： 神经网络之所以被认为几乎能学习任何东西，其核心在于它们的通用近似能力 (Universal Approximation Capability)。这主要由通用近似定理 (Universal Approximation Theorem, UAT) 提供理论支撑。
1. 专业严谨的解释 (基于通用近似定理)
通用近似定理 (UAT) 的核心内容: 最经典的通用近似定理（由 George Cybenko 在1989年针对Sigmoid型激活函数证明，后续 Kurt Hornik 等人扩展到更一般的激活函数）指出：
对于一个具有一个隐藏层、有限数量神经元、并使用非线性激活函数（例如 Sigmoid、Tanh、ReLU 等，只要该函数不是多项式）的前馈神经网络 (Feedforward Neural Network)，只要隐藏层神经元数量足够多，它就可以以任意精度 ($\epsilon &amp;gt; 0$) 去近似定义在输入空间的一个紧集 (Compact Set) 上的任何连续函数 ($f$)。
关键概念分解:
前馈神经网络 (Feedforward Neural Network): 信息单向流动，从输入层经过一个或多个隐藏层到达输出层，没有循环连接。 一个隐藏层: 定理最初的证明是基于单隐藏层的，但足以证明其表达能力。实践中多层（深度）网络可能在效率和效果上更优。 非线性激活函数: 这是至关重要的。如果只有线性激活函数，整个网络无论多少层都等价于一个简单的线性变换，无法拟合复杂的非线性关系。常见的非线性激活函数（如 Sigmoid, Tanh, ReLU）引入了“弯曲”或“折断”的能力。 足够多的神经元: 理论上保证存在足够数量的神经元可以达到所需精度，但定理本身不告诉我们具体需要多少个。网络的“宽度”是关键。 任意精度 ($\epsilon$): 这意味着只要你愿意增加神经元数量，理论上可以将神经网络的输出与目标连续函数之间的误差（比如均方误差）缩小到任意小的正数 $\epsilon$ 以下。 紧集上的连续函数: “紧集”在数学上表示有界闭集（在有限维欧氏空间中）。“连续函数”意味着函数图形没有断裂或跳跃。这个条件覆盖了现实世界中绝大多数我们想要建模的函数关系。 定理的意义: UAT 证明了，从表达能力 (Representational Power) 的角度看，即使是相对简单的单隐藏层神经网络结构，也具备了拟合极其广泛函数类别的潜力。它告诉我们神经网络能够成为一个“万能函数逼近器”。
2. 通俗易懂的解释 (类比与直觉)
想象一下你想用简单的材料来搭建一个非常复杂的雕塑（代表你想学习的复杂函数或模式）。</description></item><item><title/><link>https://hobbytp.github.io/zh/base/rag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/base/rag/</guid><description>查询扩展（Query Expansion） 在信息检索中，**查询扩展（Query Expansion）**的核心作用是通过补充或优化用户原始查询的关键词，提升系统对用户需求的理解范围和匹配精度。简单来说，它像一个“智能助手”，帮助搜索引擎或检索系统更全面地捕捉用户意图，避免因用户表达简略、模糊或词汇局限导致的漏检问题。以下是其具体作用和实现逻辑的通俗解释：
1. 解决用户表达的局限性 场景举例：当用户输入“手机”时，可能实际需要的是“智能手机评测”或“手机品牌推荐”，但原始查询过于简短。 技术逻辑：查询扩展通过分析用户意图，自动补充同义词（如“移动设备”）、近义词（如“终端”）、上下位词（如“安卓手机”是“手机”的下位词）或相关短语（如“5G手机”），将原始查询扩展为更丰富的表达。 2. 提高召回率（Recall） 核心目标：避免因词汇不匹配而遗漏相关结果。例如，某篇网页提到“AI技术”，但用户未使用该术语，仅搜索“人工智能”。通过扩展“人工智能→AI”，系统能召回更多潜在相关网页。 技术实现： 基于语义关联：利用词向量（如Word2Vec）或知识图谱（如WordNet）挖掘语义相近的词汇。 基于用户行为：分析历史搜索日志，统计高频共现词（如“旅游”常与“攻略”“景点”关联）作为扩展词。 3. 处理歧义性查询 场景举例：用户搜索“苹果”，可能指水果、手机品牌或公司。通过上下文分析（如用户历史点击记录）或结合领域知识，扩展为“iPhone 15”或“红富士苹果”，明确意图。 技术实现： 伪相关反馈（PRF）：从初始检索结果中提取高频相关词（如“iPhone”相关网页中出现“iOS”“摄像头”等词）作为扩展词。 大语言模型（LLM）：利用LLM生成假设性答案，从中提取关键词（如“苹果公司2023年财报”中的“营收”“供应链”）。 4. 增强时效性与领域适应性 时效性需求：对于时间敏感的查询（如“2024年奥运会最新赛程”），传统检索可能依赖过时数据，而查询扩展可结合实时知识库或网络爬取的最新信息进行补充。 领域适配：在医疗、法律等专业领域，扩展词可能包括术语（如“心肌梗死→心梗”）或行业标准词汇，提升领域相关性。 5. 平衡召回率与精确率 挑战：扩展词过多可能导致无关结果（如“手机”扩展出“手机壳维修”）。 解决方案： 动态权重调整：为扩展词分配不同权重（如同义词权重高于上位词）。 重排序（Reranking）：通过二级模型对扩展后的结果二次排序，过滤噪声。 总结 查询扩展的本质是弥合用户表达与系统理解之间的鸿沟。它通过语义分析、用户行为挖掘和外部知识融合，将用户的“简短提问”转化为“全面检索指令”，从而在保证结果相关性的同时，尽可能覆盖更多潜在需求。这一技术广泛应用于搜索引擎、智能客服、RAG（检索增强生成）等场景，是提升信息检索效果的关键技术之一。</description></item><item><title/><link>https://hobbytp.github.io/zh/base/youtube_karpathy_deepdive_llm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/base/youtube_karpathy_deepdive_llm/</guid><description>Deep Dive into Large Language Models https://www.youtube.com/watch?v=zjkBMFhNj_g
在 YouTube 视频脚本《Deep Dive into LLMs like ChatGPT》中，主讲人 Andrej Karpathy 按照构建和理解大型语言模型的完整流程展开讲述，他试图从一个高屋建瓴的角度，向普通观众介绍 LLM 的内部工作机制及其能力与局限性。其讲述方式大致遵循以下顺序：
导论与核心问题提出：首先，Karpathy 强调了 LLM（如 ChatGPT）的魔力与强大，同时也指出了其不足和需要注意的“锋利边缘”。他提出了听众可能关心的核心问题，例如文本框后发生了什么、模型如何生成词语、以及我们究竟在与什么对话。
构建 LLM 的流程：他随后开始详细介绍构建一个类似 ChatGPT 的 LLM 的完整流水线 (pipeline)，并强调这将是一个顺序排列的多个阶段。
预训练阶段 (Pre-training Stage)：这是第一个阶段，重点在于知识的获取。
下载和处理互联网数据：他介绍了获取大量高质量、多样性互联网文本数据的过程，并推荐了 Hugging Face 的 FineWeb 数据集作为参考。 训练目标：预测下一个 token：他解释了预训练的核心任务是预测序列中的下一个 token，并提到了上下文窗口大小的限制。 训练数据规模：他用 GPT-2 的训练数据量（约 1000 亿 tokens）和 FineWeb 的数据量（15 万亿 tokens）进行了对比，展示了数据规模的演进。他还分享了自己复现 GPT-2 的经历和训练成本。 模型发布 (Model Release)：他解释了发布一个基础模型需要模型代码（描述神经网络操作序列的 Python 代码）和模型参数（神经网络中数十亿个“旋钮”的正确设置）。他用 GPT-2 和更现代的 Llama 3 作为例子进行了说明。他还演示了如何与一个基础模型（Llama 3）进行交互，强调其本质是一个“昂贵的自动补全”工具，尚未成为一个助手。
指令微调与助手模型 (Instruct Model)：他解释了如何通过在对话数据集上进行持续训练 (continue training) 将基础模型转化为可以回答问题的助手模型。</description></item><item><title/><link>https://hobbytp.github.io/zh/base/yt_karpathy_intro_llm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/base/yt_karpathy_intro_llm/</guid><description>[1hr Talk] Intro to Large Language Models https://www.youtube.com/watch?v=zjkBMFhNj_g 该视频讲稿系统地介绍了大型语言模型（LLMs）。首先，它从基本概念入手，解释了LLM的构成（参数文件和运行代码），并以Llama 2为例进行了说明，强调了其开放权重的特点。接着，深入探讨了LLM的训练过程，分为预训练（海量互联网文本、高昂算力成本）和微调（高质量人工标注数据，塑造助手模型）两个阶段，并提及了可选的**通过人类反馈强化学习（RLHF）**进行性能提升。
随后，讲稿展示了LLM的强大能力，例如工具使用（浏览器、计算器、代码执行、图像生成），以及多模态特性（处理文本、图像、音频等）。展望未来，它探讨了LLM的发展方向，包括模拟人类的系统二思维、自我改进的可能性，以及定制化的应用前景，并提出了LLM可能成为新兴操作系统内核的类比。
最后，讲稿也强调了LLM带来的安全挑战，通过越狱攻击、提示注入攻击和数据投毒/后门攻击等实例，揭示了LLM安全领域的攻防博弈。总而言之，该视频旨在为听众提供一个关于LLM的全面入门，既展现了其潜力，也指出了其面临的挑战。</description></item><item><title/><link>https://hobbytp.github.io/zh/camel/camel_arch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/camel/camel_arch/</guid><description/></item><item><title/><link>https://hobbytp.github.io/zh/camel/owl_design/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/camel/owl_design/</guid><description/></item><item><title/><link>https://hobbytp.github.io/zh/claude/claude_history/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/claude/claude_history/</guid><description/></item><item><title/><link>https://hobbytp.github.io/zh/deepseek/deepseek_usage_tips/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/deepseek/deepseek_usage_tips/</guid><description>提示词 不同类别的提示词如下：
个性化写作风格（Personalize your writing style）： Analyze the writing style of the text provided below: [text] Now write an essay of [number of words] words on [specific topic]. You do not have to mention anything related to the previous text, it is simply provided to elicit a response that imitates the tone, structure, and vocabulary. Answer me only with the requested essay. 分析以下文本的写作风格（示例：学术论文/营销文案/新闻报道）：[text] 现在写一篇关于[特定主题]的[字数]字的文章。你不需要提到与前面文本的任何关系，它只是为了引发一个模仿前面文本的写作风格、结构和词汇的回答。只回答我请求的文章。 通过获取反馈提升写作（Improve your writing by getting feedback）： [paste your writing] Please proofread the text above.</description></item><item><title/><link>https://hobbytp.github.io/zh/deepthinking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/deepthinking/</guid><description>DeepSeek R1 的技术流程 DeepSeek R1 的技术流程可总结为以下范式： 1.DeepSeek R1-Zero 的生成： 基于 DeepSeek V3-Base 模型，通过强化学习（RL），直接训练出 DeepSeek R1-Zero 模型。该阶段不进行监督微调 (SFT)，旨在探索模型自主发展推理能力的潜力。 2.推理链可读性增强：
冷启动数据微调： 采用高质量的冷启动数据（包括人工专家撰写和模型生成并经过筛选的高质量、符合格式规范的推理数据）对 R1-Zero 进行监督微调。
以推理为中心的强化学习： 以微调后的模型为基础，进一步进行强化学习，从而提升推理链的可读性。 3.通用能力和安全性提升：
全领域监督微调： 通过拒绝采样 (Rejection Sampling) 筛选高质量数据，并结合全领域数据进行监督微调，提升模型的通用能力。
全领域强化学习： 在全领域任务上进行强化学习训练：
推理任务：采用规则奖励。
通用任务 (如聊天)：进行偏好建模。
通过上述措施，在提升模型通用能力的同时，增强其安全性。
DeepSeek R1 Zero 的强化训练过程 DeepSeek R1 Zero 是完全从基础模型（DeepSeek V3)开始构建，完全依赖强化学习，而不使用人类专家标注的监督微调（SFT）。在训练过程中随着训练步骤的增加，模型也是逐渐展现出长文本推理以及长链修复的能力。随着推理路径的逐步增长，模型来表现出自我反思的能力，能够发现并修复之前的错误。DeepSeek R1-Zero 通过 直接在基础模型上应用强化学习，并设计 基于规则的奖励函数，实现了在没有监督数据的情况下发展强大的推理能力 DeepSeek R1 Zero 的强化训练过程中，设计了奖励机制，以优化模型的推理能力。具体来说，奖励机制的设计主要集中在以下几个方面： 没有使用监督微调 (SFT)：DeepSeek R1-Zero 直接应用强化学习 (RL) 到基础模型，而没有依赖于监督微调作为初步步骤。这种方法允许模型探索解决复杂问题的思维链 (CoT)，从而发展 DeepSeek R1-Zero。 奖励函数：DeepSeek R1 采用 基于规则的奖励系统，而不是神经奖励模型，以避免奖励 &amp;ldquo;黑客行为&amp;rdquo; 和过度的计算成本。主要的奖励函数包括：
准确性奖励：确保模型生成在事实上正确且可验证的响应。这对于具有确定性结果的任务（如数学和编码）特别有用。DeepSeek R1 在奖励建模中，采用基于规则的奖励，直接利用程序进行判断正误的奖励信号 [110, see earlier turn].</description></item><item><title/><link>https://hobbytp.github.io/zh/google/gemini/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/google/gemini/</guid><description>google Gemini相关产品 大模型平台：Gemini Pro Gemini 2.5 Pro
Gemini相关应用 Deep Research 每天20个Deep Research
2025年4月9日，Google Deep Research 使用 Gemini 2.5 Pro
NotebookLM 目前支持
生成播客,并且支持用户加入播客。 生成脑图 如何使用NotebookLM https://notebooklm.com/docs/getting-started/overview</description></item><item><title/><link>https://hobbytp.github.io/zh/google/google_cloud/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/google/google_cloud/</guid><description>graph TD subgraph GCP [&amp;#34;Google Cloud Platform&amp;#34;] direction LR subgraph GlobalInfrastructure [&amp;#34;全球基础设施&amp;#34;] direction TB Region1[&amp;#34;区域 1 (例如: us-central1)&amp;#34;] Region2[&amp;#34;区域 N (例如: asia-northeast1)&amp;#34;] Zone1A[&amp;#34;可用区 1-A&amp;#34;] Zone1B[&amp;#34;可用区 1-B&amp;#34;] ZoneNA[&amp;#34;可用区 N-A&amp;#34;] PoP[&amp;#34;边缘节点 PoP&amp;#34;] Region1 --- Zone1A &amp;amp; Zone1B Region2 --- ZoneNA GlobalNetwork[&amp;#34;全球高速网络&amp;#34;] --- Region1 &amp;amp; Region2 &amp;amp; PoP end subgraph CoreServices [&amp;#34;核心服务&amp;#34;] direction TB subgraph Compute [&amp;#34;计算服务&amp;#34;] GCE[&amp;#34;Compute Engine (VMs)&amp;#34;] GKE[&amp;#34;Kubernetes Engine (容器)&amp;#34;] AppEngine[&amp;#34;App Engine (PaaS)&amp;#34;] CloudFunctions[&amp;#34;Cloud Functions (FaaS)&amp;#34;] end subgraph Storage [&amp;#34;存储服务&amp;#34;] CloudStorage[&amp;#34;Cloud Storage (对象)&amp;#34;] PersistentDisk[&amp;#34;Persistent Disk (块)&amp;#34;] Filestore[&amp;#34;Filestore (文件)&amp;#34;] CloudSQL[&amp;#34;Cloud SQL (关系型DB)&amp;#34;] Spanner[&amp;#34;Spanner (全球DB)&amp;#34;] Bigtable[&amp;#34;Bigtable (NoSQL)&amp;#34;] end subgraph Networking [&amp;#34;网络服务&amp;#34;] VPC[&amp;#34;VPC 网络&amp;#34;] LoadBalancing[&amp;#34;Cloud Load Balancing&amp;#34;] CloudDNS[&amp;#34;Cloud DNS&amp;#34;] CloudCDN[&amp;#34;Cloud CDN&amp;#34;] end subgraph DataAnalytics [&amp;#34;数据与分析&amp;#34;] BigQuery[&amp;#34;BigQuery (数据仓库)&amp;#34;] Dataflow[&amp;#34;Dataflow (数据处理)&amp;#34;] PubSub[&amp;#34;Pub/Sub (消息传递)&amp;#34;] end %% 连接关系 (高层次示意) Compute -- 使用 --&amp;gt; Storage Compute -- 连接 --&amp;gt; Networking Networking -- 连接 --&amp;gt; GlobalInfrastructure PoP -- 集成 --&amp;gt; CloudCDN DataAnalytics -- 处理 --&amp;gt; Storage DataAnalytics -- 交互 --&amp;gt; PubSub AppEngine &amp;amp; CloudFunctions -- 触发 --&amp;gt; PubSub end subgraph ManagementSecurity [&amp;#34;管理与安全 (贯穿各层)&amp;#34;] direction TB IAM[&amp;#34;Identity &amp;amp; Access Management (IAM)&amp;#34;] SecurityCommand[&amp;#34;Security Command Center&amp;#34;] CloudArmor[&amp;#34;Cloud Armor&amp;#34;] Monitoring[&amp;#34;Cloud Monitoring&amp;#34;] Logging[&amp;#34;Cloud Logging&amp;#34;] Console[&amp;#34;Cloud Console / CLI&amp;#34;] end %% 整体关系 CoreServices -- 运行于 --&amp;gt; GlobalInfrastructure ManagementSecurity -- 管理与保护 --&amp;gt; CoreServices &amp;amp; GlobalInfrastructure end User[&amp;#34;用户 / 应用&amp;#34;] --&amp;gt; LoadBalancing User --&amp;gt; CloudCDN User --&amp;gt; Console %% 样式 (可选) classDef default fill:#f9f,stroke:#333,stroke-width:2px; classDef infra fill:#e6f2ff,stroke:#36c,stroke-width:2px; classDef compute fill:#fff0e6,stroke:#f60,stroke-width:2px; classDef storage fill:#e6ffe6,stroke:#090,stroke-width:2px; classDef network fill:#ffe6e6,stroke:#c00,stroke-width:2px; classDef data fill:#ffffcc,stroke:#cc0,stroke-width:2px; classDef mgmt fill:#f0f0f0,stroke:#666,stroke-width:2px; class GlobalInfrastructure,Region1,Region2,Zone1A,Zone1B,ZoneNA,PoP,GlobalNetwork infra; class Compute,GCE,GKE,AppEngine,CloudFunctions compute; class Storage,CloudStorage,PersistentDisk,Filestore,CloudSQL,Spanner,Bigtable storage; class Networking,VPC,LoadBalancing,CloudDNS,CloudCDN network; class DataAnalytics,BigQuery,Dataflow,PubSub data; class ManagementSecurity,IAM,SecurityCommand,CloudArmor,Monitoring,Logging,Console mgmt; Google Cloud Platform (GCP) 核心基础设施详解 全球基础设施与核心服务概览</description></item><item><title/><link>https://hobbytp.github.io/zh/knowledge_graph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/knowledge_graph/</guid><description>Neo4j LLM Knowledge Graph Builder Neo4j推出了2025年首个版本的LLM知识图谱构建器（LLM Knowledge Graph Builder），这是一个开源工具，旨在从非结构化数据中提取知识并构建知识图谱。该工具通过将文档分块、生成文本嵌入、提取实体及其关系，并存储在Neo4j图数据库中来实现更高效的数据交互和检索。新版本增加了多项功能，包括社区摘要生成、多检索器并行运行、支持自定义提取指令以及用户体验改进等。
关键点 Neo4j发布了LLM知识图谱构建器的2025年首个版本，提供了从非结构化数据中提取知识的解决方案。 工具支持将文档分块、生成文本嵌入、提取实体及其关系，并存储在Neo4j图数据库中。 新增功能包括社区摘要生成、全局和局部检索器、多检索器并行运行以及检索器评估。 支持用户自定义提取指令，允许更精确地提取特定主题或部分内容。 提供了用户体验改进，如只读数据库访问、图谱可视化优化以及实验性的图谱合并功能。 工具支持多种最新的LLM模型，如OpenAI GPT-4o、Google Gemini等，并进行了内部测试和集成。 用户可以通过Neo4j的AuraDB免费版或专业版试用该工具，并参与其相关博客系列了解更多技术细节。 Neo4j LLM Knowledge Graph Builder</description></item><item><title/><link>https://hobbytp.github.io/zh/mas/multipleagents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/mas/multipleagents/</guid><description>参考 -一份全面的AI Agent知识地图</description></item><item><title/><link>https://hobbytp.github.io/zh/rag/rag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/rag/rag/</guid><description/></item><item><title/><link>https://hobbytp.github.io/zh/rag/rankify/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/rag/rankify/</guid><description>Rankify摘要 一个模块化且高效的检索、重排序和 RAG 框架，专为最新的检索、排序和 RAG 任务模型设计。
Rankify 是一个 Python 工具包，专为统一的检索、重排序和检索增强生成（RAG）研究而构建。该工具包集成了 40 个预检索的基准数据集，支持 7 种检索技术，包含 24 种最先进的重排序模型，并支持多种 RAG 方法。Rankify 提供一个模块化且可扩展的框架，使研究人员和实践者能够轻松进行实验和基准测试，涵盖完整的检索流程。详细的文档、开源实现和预构建的评估工具，使 Rankify 成为该领域研究者和工程师的强大工具。
参考 Rankify 文档 Rankify 官网 Rankify Github Rankify 论文 Rankify 视频 Rankify 完全指南</description></item><item><title/><link>https://hobbytp.github.io/zh/tencent/yuanbao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/tencent/yuanbao/</guid><description>Chatbot 元宝 安装腾讯元宝app，OS 应用，小程序。 外网访问：https://llm.hunyuan.tencent.com/#/chat/hy-t1</description></item><item><title/><link>https://hobbytp.github.io/zh/test_time_training/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/test_time_training/</guid><description>The Surprising Effectiveness of Test-Time Training for Abstract Reasoning
MIT: The Surprising Effectiveness of Test-Time Training for Abstract Reasoning</description></item><item><title/><link>https://hobbytp.github.io/zh/theory_chinchila/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/theory_chinchila/</guid><description>Scaling Laws 下面是一张表格，总结了scaling law各种曲线和相关参数之间的关系，有助于对比它们各自的设计理念和重点关注的参数。
2. Chinchilla 理论曲线 订正说明：Chinchilla模型由DeepMind团队在论文《Training Compute-Optimal Large Language Models》中提出，发表于2022年，论文ID为arxiv:2203.15556。 更正后信息： 论文ID：2203.15556 发表时间：2022 3. Deep Scaling Laws 订正说明：该理论通常与OpenAI的缩放定律研究相关，但表格中的描述更接近Chinchilla的结论。若特指参数、数据、计算复杂度三者的联合优化，可能对应论文《Scaling Laws for Neural Language Models》（2020年，ID:2001.08361）。 更正后信息： 论文ID：2001.08361 发表时间：2020 5. Scaling Laws for Transfer Learning 订正说明：该领域的研究分散，但Google与OpenAI合作的论文《Scaling Laws for Transfer》发表于2021年，ID为arxiv:2102.01293（需核实具体内容是否匹配）。 更正后信息： 论文ID：2102.01293（示例，需进一步验证） 发表时间：2021 6. Data Scaling Laws 订正说明：Google的PaLM项目相关论文《PaLM: Scaling Language Modeling with Pathways》发表于2022年，ID为arxiv:2204.02311。 更正后信息： 论文ID：2204.02311 发表时间：2022 7. Lottery Ticket Hypothesis 订正说明：原始论文由Frankle &amp;amp; Carbin于2018年发表，ID为arxiv:1803.03635，信息准确。 无需更正。 8. Scaling Laws for Multimodal Models 订正说明：OpenAI的CLIP模型论文《Learning Transferable Visual Models From Natural Language Supervision》发表于2021年，ID为arxiv:2103.</description></item><item><title/><link>https://hobbytp.github.io/zh/worldlab/worldlab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hobbytp.github.io/zh/worldlab/worldlab/</guid><description>世界生成统一评估基准：WorldScore WorldScore 对 AI 业界的特殊贡献 WorldScore 是首个统一评估基准，专注于评估 3D、4D 和视频模型在世界生成任务中的表现。它的出现填补了现有基准在多场景、多序列长度和动态性评估方面的空白，对 AI 业界的贡献具有以下几个关键点：
1. 统一评估标准 核心贡献：WorldScore 提供了一个统一的框架，将世界生成任务分解为一系列基于显式相机轨迹的下一场景生成任务。 意义：这一方法让 3D、4D 和视频生成模型可以在同一基准下进行比较，解决了以往基准无法覆盖多模态、多任务模型的局限性。 2. 多维度评估指标 WorldScore 提出了三个核心评估维度：
可控性（Controllability）：评估模型是否能够根据指令生成符合布局和内容的场景。 质量（Quality）：包括 3D 一致性、光度一致性、风格一致性和主观质量等。 动态性（Dynamics）：评估模型生成动态场景的运动准确性、平滑性和幅度。 这些指标全面覆盖了世界生成任务的关键挑战，为模型开发者提供了多层次的性能反馈。
3. 弥补现有基准的不足 与现有基准（如 TC-Bench、EvalCrafter、VBench 等）相比，WorldScore 在以下方面表现出独特优势：
多场景与长序列支持：评估生成模型是否能处理复杂的多场景任务。 精确的相机控制：评估模型是否能够严格遵循相机轨迹指令。 3D 一致性评估：确保模型生成的场景在几何和纹理上保持一致。 覆盖动态场景生成：现有基准大多仅关注静态场景，而 WorldScore 引入了动态性评估，填补了这一重要领域的空白。 4. 推动多模态生成技术发展 WorldScore 支持对 3D、4D、I2V（图像到视频）和 T2V（文本到视频）模型的统一评估。这种广泛的适用性直接推动了多模态生成技术的研究和发展，为学术界和工业界提供了一个通用的测试基准。
5. 提升模型实际应用能力 通过对 19 个代表性模型的评估，WorldScore 揭示了当前模型在可控性、动态性和质量上的不足。例如：
某些模型在动态场景生成中表现较弱（如运动平滑性不足）。 部分模型在复杂场景生成中无法保持 3D 一致性。 这些洞察帮助开发者更有针对性地优化模型，从而提升模型在实际应用中的可靠性。 6. 丰富的公开资源 数据集：WorldScore 提供了一个包含 3,000 个多样化场景的高质量数据集，涵盖静态与动态、室内与室外、写实与风格化等多种场景。 排行榜：通过 Hugging Face 平台提供实时更新的模型排名，方便研究者和开发者了解最新的模型性能。 7. 学术与工业影响力 学术价值：作为一项开创性工作，WorldScore 为世界生成领域提供了系统化的研究工具，促进了该领域的进一步探索。 工业价值：在虚拟现实（VR）、增强现实（AR）、影视制作、游戏开发等应用场景中，生成高质量的动态世界是关键需求。WorldScore 的评估标准为这些行业提供了可靠的参考。 脑洞建议：未来的可能方向 扩展至实时生成能力评估： 增加对模型实时生成能力的测试，特别是在交互式场景中的表现。 引入多模态交互评估： 例如，结合语音、手势等多模态输入，评估模型的响应能力。 自动化优化反馈： 基于 WorldScore 的评估结果，开发自动化调优工具，为模型开发者提供优化建议。 与元宇宙结合： 将 WorldScore 评估框架嵌入元宇宙平台，实时测试生成模型在虚拟世界中的表现。 总之，WorldScore 的推出为世界生成领域树立了新的标杆，其统一评估框架和多维度指标将持续推动 AI 技术在生成式任务上的进步。</description></item></channel></rss>