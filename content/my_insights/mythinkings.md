---
title: "我在AI领域的一些思考"
date: "2025-04-20T20:10:00+08:00"
description: "关于数学，物理等跨学科到AI领域的思考"
tags: ["AI Agent", "大模型", "计算不可约性", "数学", "物理", "数学", "物理"]
---
这里会持续更新我在AI领域的一些思考。这是一个动态更新的过程，但是我会保留最开始的粗略想法和其演进过程，尽可能保留所有的痕迹。

## 计算不可约性(Computational Irreducibility)

### 计算不可约性理论在AI Agent中的体现

当前AI Agent（如智能体、LLM驱动的工具型AI）常常需要借助外部工具（如搜索引擎、数据库、代码执行环境等）来完成复杂任务，尤其是当任务本身涉及大量不可预知、动态变化或信息量极大的情境时。

其理论解释是，在不可约性视角下，很多真实世界任务（如开放式问答、复杂推理、多步决策）本质上就是“不可约”的：没有一条简单的公式或神经网络能在内部一步到位地直接给出最终答案。
这也就意味着，AI Agent即使模型能力再强，也无法“内部化”所有世界知识和外部状态变化，只能通过调用外部工具/环境来“实际运行”所需的推理或数据检索过程，这与不可约性中“只能逐步模拟”高度一致。

以下是一些具体的例子：

- 搜索引擎调用：当Agent遇到新知识点时，无法仅靠训练参数推出答案，必须“查一查”——这就是对复杂系统不可约性的现实应对。
- 代码执行/环境交互：比如Copilot、GPT-4等Agent需要运行代码片段、与外部API交互，实际上是通过“外部模拟”来获得结果，绕不开计算不可约性带来的不可压缩性。
- 多Agent协作：多个Agent分工协作、彼此调用，也是在“分布式地”模拟一个不可约的复杂过程。

“计算不可约”对AI Agent系统设计的启示：

- 外部工具集成是必然趋势：既然不可约性普遍存在，AI系统设计时就应天然支持与外部世界的高效接口，而不是追求“全知全能的封闭模型”。
- Agent的本质是“调度器”：智能体的核心价值，逐渐转向如何高效组织、调度外部资源和工具，提升整体推理效率，而不是仅靠内在模型参数“猜”出一切。

“计算不可约”在AI模拟城市的指导意义：

- AI Agent或多智能体系统，正是通过模拟每个“市民”、“企业”、“交通工具”等微观个体的行为和交互，逐步推进城市状态演化。你无法通过简单的参数拟合或静态建模就预测出整个城市的未来状态，必须通过仿真（agent-based simulation, multi-agent system, reinforcement learning等）不断推进，才能发现潜在的涌现现象和复杂格局。这正是“计算不可约性”在工程实践中的最佳写照：现实问题太复杂，只能一步步算出来。
- AI模拟城市的具体体现
  - 城市交通仿真：交通流量、拥堵点、出行模式，只有通过交通微观模拟（如SUMO、MATSim等）才能真实再现，无法用公式直接预判。
  - 城市政策实验：比如限号、调控、税收变化对经济和人口迁移的影响，只有通过多Agent模拟才能看到长期的动态反馈。
  - 应急管理：灾害响应、疫情传播、资源调度等，都是高度不可约的过程，必须依赖AI或多Agent系统动态推演。

## 深度学习能学习任何东西吗？

## 数据 vs. 算法，哪个更重要？

## 长上下文 vs. 记忆

这里的思考主要关注大模型的长上下文的支持，以及大模型在记忆方面的能力。

## 大模型Scaling Law失效了吗？

## 当前Transformer-based大模型的局限性在哪里？
