---
title: "我在AI领域的一些思考"
date: "2025-04-20T20:10:00+08:00"
description: "关于数学，物理等跨学科到AI领域的思考"
tags: ["AI", "大模型", "数学"]
layout: mythinkings
---
这里会持续更新我在AI领域的一些思考。这是一个动态更新的过程，但是我会保留最开始的粗略想法和其演进过程，尽可能保留所有的痕迹。

## Agent系统的演进 vs. 父母培养孩子的过程

Agent系统演进的过程就像父母培养孩子的理想状态：既有底线（workflow）和引导（协作Agent + 推理模型），又给足空间和资源（外部Tools+Resource）；既能保证安全和方向，又能激发创造和成长（自主Agent）。而孩子最终长大成人超越父母（Bitter Lesson）。

## MCP Hub, MCP Store, MCP Registry, MCP Gateway, MCP Proxy

MCP Hub是MCP的官方仓库，用于存储MCP的协议文档和实现。

## 自动生成MCP Server

看起来大家都不约而同的希望通过大模型或Agent通过阅读MCP协议的文档和Server端应用能提供的服务，然后自动生成一个MCP Server。

## A2A为什么这个时候出现

A2A (Agent-to-Agent)是Google公司提出的一个开源框架，我的理解A2A之于MAS，就像Kubernetes之于微服务系统，旨在通过多智能体之间的协作来提升MAS系统的能力和效率。A2A通过引入多个智能体之间的交互和协作，来实现更复杂、更高效的任务处理。之前的诸多MAS框架（如AutoGen、LangChain, CAMEL，MetaGPT等）都是使用自家的多Agent通信协议来实现的，他们之间是不能互通的，比如AutoGen的Agent找不到LangGraph的Agent，也不能与之通信，而A2A则强调了智能体之间的协作和信息共享。为打通各个MAS框架，A2A提供了一个统一的通信协议和交互方式，并还提供了一个统一的Agent Orchestrator和Agent 管理平台，允许用户在一个平台上管理和监控所有的智能体，想想K8s的集群管理，服务发现。并且A2A day0就支持MCP协议，这个就有点像K8S里面CxI（CNI，CSI, CRI等）的概念，A2A负责整个MAS的编排和管理，而MCP负责Agent和各种服务，Tool，信息源头之间的通信，就像K8s里面，Pod通过CNI访问网络，Pod通过CSI访问存储，Pod通过CRI使用不同底层容器技术。同理，在A2A里面，Agent通过MCP协议来和其他服务连接。

当然，如果你把你的Agent（或MAS）包装成MCP Server，那么它也可以与其他任何遵循MCP协议的Agent进行通信了。但是A2A的愿景是打通所有MAS框架，而MCP只是其中支持的一个协议罢了。A2A和MCP在某种程度上是互补的。2025年在各种Deep Research，（PC, Web）Operator，Claude Desktop，Manus出现后，俨然一副MAS大火的元年的架势，而google在这个时候推出支持MCP的MAS的编排框架A2A，显然是看到了这个趋势，并协同50家厂商一举占领市场用户的心智。在国内虽然也有ANP，都是从各方影响力来看差距很大，Google作为开源界的优等生兼超级大佬，市场的号召力和影响力是毋庸置疑的。

# A2A：Google如何用"Kubernetes式思维"重新定义多智能体系统？

在2025年这个被业界称为"多智能体系统(MAS)元年"的时代，Google再次展现了其作为开源界超级大佬的前瞻性，推出了A2A(Agent-to-Agent)框架——这个可能彻底改变MAS生态的游戏规则改变者。

## 从碎片化到统一：A2A的颠覆性设计理念

想象一下Kubernetes对微服务世界的革命性影响，A2A对MAS领域带来的正是这种级别的范式转变。当前市场上的MAS框架——无论是AutoGen、LangChain、CAMEL还是MetaGPT——都像是一座座孤岛，各自使用专有的通信协议，导致不同框架的智能体根本无法相互发现和协作。这就像早期的容器编排系统，每家都有自己的解决方案，直到Kubernetes出现才统一了江湖。

A2A的核心创新在于它提供了一个**统一的通信协议和交互标准**，并配备了完整的**Agent Orchestrator**和**管理平台**。这相当于为MAS世界带来了K8s式的集群管理能力，让开发者能够在一个平台上管理和监控所有智能体，无论它们原本属于哪个框架。

## MCP协议：A2A生态的"CNI/CSI/CRI"

特别值得关注的是A2A从Day 0就支持的MCP协议——这堪称MAS领域的"基础设施插件标准"。在Kubernetes中，我们有CNI(网络)、CSI(存储)、CRI(容器运行时)等标准接口；而在A2A生态中，MCP协议扮演着类似的角色，负责智能体与各种服务、工具和信息源之间的标准化通信。

这种设计的美妙之处在于它的**可扩展性**：任何将自己的Agent或MAS系统包装成MCP Server的实现，都能无缝接入A2A生态。但Google的野心显然不止于此——MCP只是A2A支持的众多协议之一，其终极目标是成为连接所有MAS框架的"万能胶水"。

## 2025：MAS元年的天时地利

Google选择在2025年推出A2A绝非偶然。随着Deep Research、PC/Web Operator、Claude Desktop、Manus等创新产品的爆发式增长，MAS技术确实迎来了它的高光时刻。Google联合50家厂商共同推进A2A生态，这种"联盟式"打法不仅展现了其市场号召力，更是一种精心策划的生态占领策略。

相比之下，国内虽然也有ANP等类似尝试，但在影响力和生态建设上确实存在明显差距。作为开源界的"优等生"，Google再次证明了自己定义行业标准的能力——就像当年Android统一移动操作系统、Kubernetes统一容器编排一样，A2A很可能会成为MAS领域的事实标准。

## 未来展望：当每个Agent都成为A2A公民

A2A的出现预示着MAS发展将进入新阶段：

- **开发效率革命**：再也不用为不同框架的兼容性头疼
- **资源利用率提升**：跨系统的Agent协作成为可能
- **创新加速**：开发者可以专注于业务逻辑而非底层通信

这不禁让人想起Kubernetes早期的发展轨迹——从被质疑到被接受，再到成为行业标配。A2A是否也会沿着同样的路径发展？在MAS元年的背景下，答案很可能是肯定的。

作为技术人，我们或许正在见证一个新时代的开端——当A2A让每个智能体都能自由沟通协作时，真正的分布式人工智能才算是迈出了坚实的一步。Google这次又走在了前面，而我们要做的，就是准备好迎接这场由A2A带来的MAS生态大统一。

## 为什么MCP怎么火

MCP (Model-Context-Protocol)是xxx

火的原因有几个：
解决了几个痛点：当前的大模型不够聪明

OpenAI的Function calling不是行业规范，虽然它到目前为止是事实标准，但是其他的大模型对它的支持并不友好。而且这个由OepnAI完全掌控，会让别的大模型完全只能是follower，这显然不利于生态的健康发展。当新的接口出来后，其他大模型必须被动支持，时间上会滞后，甚至会被OpenAI的更新打乱节奏。

MCP是一个开源的标准，基于的技术JSON-RPC协议是非常成熟的通用规范，任何大模型理论上都已经支持它。MCP协议的变化性是在MCP Client和Server的实现上，而不是在协议本身，将来的演进更多是依赖于MCP协议而不是大模型。

MCP目前的短板是安全方面，MCP协议本身并不涉及安全性的考量。但是MCP Client和Server的实现是可以考虑安全的。比如，MCP Server可以只允许可信的Client连接，或者对某些敏感操作进行权限控制等。

将来的趋势：
短期趋势：MCP协议可以作为基于不同框架实现的Agent间，Agent和工具之间的通信协议，注意不是MAS框架。MCP协议的标准化和规范化将为AI Agent的开发和应用提供更多的可能性，特别是在多Agent协作、跨平台交互等方面。
长期趋势：MCP不再存在，因为当大模型都足够聪明的情况下，所有的协议都可以现学现用。而将来的协议可以是基于自然语言的协议，或者是大模型之间自己协商的。当然这个听起来比较科幻，仅仅用来开开脑洞。

1. 目标是开源的规范：

## RL强化训练的局限性

[Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org/pdf/2504.13837)

## 计算不可约性(Computational Irreducibility)

### 计算不可约性理论在AI Agent中的体现

当前AI Agent（如智能体、LLM驱动的工具型AI）常常需要借助外部工具（如搜索引擎、数据库、代码执行环境等）来完成复杂任务，尤其是当任务本身涉及大量不可预知、动态变化或信息量极大的情境时。

其理论解释是，在不可约性视角下，很多真实世界任务（如开放式问答、复杂推理、多步决策）本质上就是"不可约"的：没有一条简单的公式或神经网络能在内部一步到位地直接给出最终答案。
这也就意味着，AI Agent即使模型能力再强，也无法"内部化"所有世界知识和外部状态变化，只能通过调用外部工具/环境来"实际运行"所需的推理或数据检索过程，这与不可约性中"只能逐步模拟"高度一致。

以下是一些具体的例子：

- 搜索引擎调用：当Agent遇到新知识点时，无法仅靠训练参数推出答案，必须"查一查"——这就是对复杂系统不可约性的现实应对。
- 代码执行/环境交互：比如Copilot、GPT-4等Agent需要运行代码片段、与外部API交互，实际上是通过"外部模拟"来获得结果，绕不开计算不可约性带来的不可压缩性。
- 多Agent协作：多个Agent分工协作、彼此调用，也是在"分布式地"模拟一个不可约的复杂过程。

"计算不可约"对AI Agent系统设计的启示：

- 外部工具集成是必然趋势：既然不可约性普遍存在，AI系统设计时就应天然支持与外部世界的高效接口，而不是追求"全知全能的封闭模型"。
- Agent的本质是"调度器"：智能体的核心价值，逐渐转向如何高效组织、调度外部资源和工具，提升整体推理效率，而不是仅靠内在模型参数"猜"出一切。

"计算不可约"在AI模拟城市的指导意义：

- AI Agent或多智能体系统，正是通过模拟每个"市民"、"企业"、"交通工具"等微观个体的行为和交互，逐步推进城市状态演化。你无法通过简单的参数拟合或静态建模就预测出整个城市的未来状态，必须通过仿真（agent-based simulation, multi-agent system, reinforcement learning等）不断推进，才能发现潜在的涌现现象和复杂格局。这正是"计算不可约性"在工程实践中的最佳写照：现实问题太复杂，只能一步步算出来。
- AI模拟城市的具体体现
  - 城市交通仿真：交通流量、拥堵点、出行模式，只有通过交通微观模拟（如SUMO、MATSim等）才能真实再现，无法用公式直接预判。
  - 城市政策实验：比如限号、调控、税收变化对经济和人口迁移的影响，只有通过多Agent模拟才能看到长期的动态反馈。
  - 应急管理：灾害响应、疫情传播、资源调度等，都是高度不可约的过程，必须依赖AI或多Agent系统动态推演。

## 学习深度学习的理论和各种调优理论和工程方法有利于优化个人学习的方法论

深度学习是一群很牛的科学家试图用数学的方法来模拟大脑的神经网络，而大脑的神经网络是人类长期进化而来的，它具有很强的学习能力，能够通过少量的数据学习到很多知识，并且能够举一反三，融会贯通。
而对于普通个人来说，并不能熟练掌握高效的学习方法来极大挖掘人类大脑的能力。所以这群牛人从人脑学习方式挖掘出来一套方法论，通过实验成功应用到深度学习中，并取得了巨大的成功, 而这套方法论其实可以反过来指导个人的掌握更优的学习方法，也就是说，深度学习的理论和方法论可以迁移到个人学习中，对优化个人学习的方法论有非常强的指导意义。这个看起来是个双向奔赴的过程，科学家从人脑的工作模式中得到启发，从而不断优化深度学习的方法论，而普通个人则可以借鉴深度学习的方法论，从而优化个人学习的方法论。

深度学习的训练，调优，微调，蒸馏，迁移学习，多任务学习，多模态学习，多Agent学习，等等，这些理论和方法论可以迁移到个人学习中，对优化个人学习的方法论有非常强的指导意义。
比如，训练讲究要优质数据（数据数量，质量，多样性，均衡性，等），这个和个人的学习很像，优质数据决定了模型学习的上限，而模型调优决定了模型学习下限，而掌握第一性原理所需要的优质知识，往往也是我们个人学习第一时间需要收集的。
训练中，数据集的划分，训练集，验证集，测试集，这个和个人的学习很像，个人的学习也需要分阶段，不同的阶段需要不同的数据集，比如，新手期，成长期，成熟期，探索期，等等。
训练中，超参数的调整，就像个人在学习中找到适合自己的学习方法，比如，学习率（学习速度），batch size（每次学习的内容量，比如，一次学习100个单词，还是1000个单词，每次半小时或1小时中间休息一下（比如番茄学习法）），epoch（每个周期，每个学科的学习次数），等等。
训练的优化，包括数据，模型，算法，这三个方面，而个人学习也是如此，个人学习需要找到适合自己的学习材料，学习方法，学习环境，学习伙伴，等等。
训练的优化，需要有目标，需要有评估标准，需要有优化方法，需要有反馈机制，需要有调整机制，需要有持续改进的机制，等等。
训练的优化，常常优化/满足指标框架与正交化原则可以协同工作。一旦满足某个指标达标，个人可以更"正交"地聚焦于使用特定的"旋钮"来提升优化指标，而不必过分担心对其他已达标指标的负面影响，比如，主要学科成绩，其他学科成绩，兴趣爱好，身体健康，心理健康，等等。这些指标之间是正交的，互不影响的。个人要做的是，找到主要学科的短板，优先改进，单个学科内部，找到短板，优先改进，比如语文，内部分为阅读，写作，古文，英语分为听说读写，等等。而各个知识点之间，又是正交的，互不影响的，个人要对所有知识点做到心中有数，不遗漏，又能按部就班，循序渐进逐步掌握。不同的方法（调优），比如，快速阅读，深度学习（讲究举一反三，融会贯通，把好的题目做通做透），多模态学习（比如，图像，视频，音频，文本等），多Agent学习（比如，协作学习，竞争学习，等等），等等。

训练中，loss function的设计，这个和个人的学习中的反省，反思，总结经验教训很像，个人的学习也需要经常回顾之前的学习内容，效果，通过测试来评估学习效果，并根据测试结果调整学习方法。而要优化的目标也是多维度的，包括知识点的掌握，知识的灵活应用的程度，能否举一反三，能否创新，等等。
训练中，模型的选择，这个就像学习不同的学科，不同的学习方法之间既有大的相同之处，又有不同的细微之处，因为不同领域可能激活不同的大脑区域， 不同的学习方法（文字更需要抽象能力，图像（结构图，流程图，脑图等）更能极大压缩大量熟悉的信息。 而监督学习就像平时的考试，不断检验知识点是否都掌握，无监督学习，就像是自学，根据材料的上下文自组织学习和检验，迁移学习和强化学习更是举一反三，能在之前没有学习过的领域，快速掌握学习方法，实现跨界学习。

## 深度学习能学习任何东西吗？

## 数据 vs. 算法，哪个更重要？

## 长上下文 vs. 记忆

这里的思考主要关注大模型的长上下文的支持，以及大模型在记忆方面的能力。

## 大模型Scaling Law失效了吗？

## 当前Transformer-based大模型的局限性在哪里？

## AI 多Agent系统的发展趋势

AI 多Agent系统的发展趋势主要体现在以下几个方面：
