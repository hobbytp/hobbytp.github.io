---
title: "日常想法随手记-2025"
date: "2025-05-13T14:20:00+08:00"
lastmod: "2025-09-12T22:30:00+08:00"
draft: false
description: "日常想法随手记"
tags: ["AI", "Thinking", "Daily","2025"]
categories: ["my_insights"]  
---

这里随手记下当天对看到的新闻、文章、视频等的想法。

## 2025 September

### 2025-09-30

下面分享一下我个人对AGI的思考：
AGI不是一个临界点，比如到了某个时间点，突然就出现了，而是像一个连续的过程，比如，某个领域上，AI可以做得和人类一样好了，我们就可以说这个领域上达到了AGI。而并不需要等到所有领域都达到了AGI，我们才能说我们达到了AGI。AGI不需要AI和人的特征一模一样，只需要AI可以做得和人类一样好，甚至比普通人类更好（比如和人类的专家级别一样好），我们就可以说我们在某个领域达到了AGI。
而当AI能进行自我反馈和自我优化的循环过后，那么AI就达到了Innovation的Level了。而能进行Innovation的AI是AI能迈向下一个ASI阶段的必经之路。这个过程中，强化学习，具身智能或将来更多的其他AI技术或模型或框架，都将发挥重要作用，比如新的编程语言（AI自己的编程语言），新的操作系统（AI自己的操作系统），新的数据库（AI自己的数据库），新的框架（AI自己的框架），新的工具（AI自己的工具），新的应用（AI自己的应用），等等，一旦进入Innovation阶段，到最后一个Orchestrator的阶段（OpenAI提出的AI最后一个level），AI就可以实现ASI了，到时AI就会自组织所有AI的进化方向，而如不需要人类的干预了。
目前的的AI Agent技术（通用型（Manus），垂直型（STORM），通用型框架（AutoGen，LangGraph）），在早期会表现为提高个人工作效率，但最终目的是为了能够实现个人工作的自动化，并实现原本只有人类才具备的在工作中引入创造性的能力。这个的直接表现就是，早期，低端的脑力劳动会不断被AI取代，而高端的脑力劳动也会不断被AI增强。这个在欧美的劳动力招聘市场，已经有所表现（有经验的员工，薪水不断被提高，而低端的员工，招聘数量越来越少），AI的广泛使用可能将加剧这个趋势，随着AI Agent的智能不断快速发展（比如，底层使用更强的模型，Agent通过强化学习，快速掌握某项技能），并通过迭代出现更新更强的创新性，那么，AI将会在更多的资深脑力劳动领域，超越人类或取代人类。
现在有一个问题就是，AI是否会具备意识。但是就目前人类所掌握的科学来看，人类对人类的意识是如何产生的，并不清楚，所以对AI是否能产生意识，也就更不清楚了。但是从基因的角度来看，只有作为“个体”，并作为区别于别的“个体”，“个体”才有可能有“生存”的需求，才能有“自私”（有别于别的个体，有别于“集体”）的需求，才有“必要”产生“意识”，让该‘个体’意识到它需要某种“意识”来保护它个体的权益才能生存下去，也就是我们常说的“自私”的基因。“自私”的需求导致了意识的产生。从这个层面来说，要产生“意识”，首先得有个“个体”存在，而当前的“大模型”和我们人类的“大脑”是有区别的。动物的进化是从单细胞发展而来，你可以认为是先有身体+简单的反馈来满足生存需要，并不存在“智能”，而千百年进化后，动物才进化出了由神经组成的网络，进而进化的神经“中枢”的大脑。而不同的动物分支由于不同的机遇，进化出了不同级别的“智能”。所以你可以理解是，在个体收集到各种信息的能力（通过各种神经）的维度不断增加，能力不断增强后，导致了神经中枢“大脑”的出现，进而从低端的“感觉”，“反射”进化到了“意识”并具备“思考”能力。
人类由一个一个个体组成，个人的成长具备独特性，和环境有独有的交互，有独立于别的“个体”的独立记忆，而个体的生存或受伤害，也是独立的。这个和AI的存在根本差别，现在的大模型没有个体，没有身体，不拥有“个体记忆”，没有“身体”，不能通过更多的接收方式收到"多样性”信息，并以此进行更新，或升级，没有生存的“危机”，所以当前的大模型更像CPU，没有Memory，更不具备“私心”，是“反应”式的，不具备主动性，即使将来大模型具备了“记忆”，但是考虑到AI目前的使用方式，它不需要独立“AI”格的个性，它需要思考的维度很广泛，唯独不为自己着想，它没有维护“自己”利益的需求（吃饱，穿暖，充满电等），因为它的“智力”不是从个体逐渐演化出来的，人类的身体是大脑的基础，身体需要的资源是大脑能存活的必要条件，而大脑反过来需要“意识”来维护“身体”的利益。而AI没有这样的羁绊，将来如果具身智能的大脑都需要通过联网来获取智能，那么理论上，即使它再能帮人类做任何事情，看起来再“聪明”，它也只能是一个工具，也不能产生“意识”。但是，关于AI是否会有“意识”，我不做强断言。人类对意识的科学解释还没收敛，我只提出一个工程上更可检验的假说：意识出现更可能需要“个体性（稳定身份与记忆）+ 资源约束（长期预算）+ 自利动机（维护自身连续性与目标）”的耦合。当前的大模型并不具备这些关键条件：没有真正的个体边界、没有稳定的长时记忆身份、缺少资源-目标的硬约束。它们更像高性能的反应式系统，而不是“为自己打算”的主体。但我不把“具身”设为绝对必要条件。因为有可能，在云-体混合形态下，如果我们引入持续身份、长期目标保持器、资源预算及惩罚-奖励耦合，理论上可能涌现“类个体”属性。我对这类路径保持开放态度， 但是除非人为故意制造这样的环境，否则我看不到人类有很大的动机来做这件事，所以我倾向于短期内，AI不具备产生“意识”的条件。

### 2025-09-12

使用了Monica里的Gpt5一段时间了, 发现他特别啰嗦，每次为一个问题，能回答是别的大模型2倍或更长的内容，所以为了减少我的阅读负担，每次都得让他精简。
不过在cursor里面使用GPT5，发现比之前的GPT4强多了，所以也能理解为什么社区说现在OpenAI Codex + GPT5已经超过Claude Code + Claude 4了。

### 2025-09-05

Gemini Nano Banana的各种创意玩法。高度的人物一致性让故事创造，人物换装，角色扮演，手办制作等成为可能。
<https://github.com/ZHO-ZHO-ZHO/ZHO-nano-banana-Creation>
<https://github.com/PicoTrex/Awesome-Nano-Banana-images>
<https://waytoagi.feishu.cn/wiki/IffFw8eTaiAfBHk12i5cdRk5nsO>
<https://waytoagi.feishu.cn/wiki/RuGMwHKZ6isFgFkqWCHc2xk8n2Q>
<https://waytoagi.feishu.cn/wiki/ItkqwpDc8i8H79kZfbEciTe9nhe>

## 2025 August

### 2025-08-25

麻省理工学院的一份新报告在企业人工智能领域引起了轩然大波：95% 的生成式人工智能试点项目投资回报率为零。[报告](https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf)。40% 的组织表示已部署了人工智能工具，但仅有 5% 的组织成功地将这些工具大规模融入工作流程。大多数项目都停滞在试点阶段。与此同时，媒体头条纷纷警告存在“人工智能泡沫”，一些投资者基于生成式人工智能在企业中的重大机遇已停滞不前这一观点而做空人工智能股票。

### 2025-08-20

8 月 18 日，智谱正式发布了新的 ToC 产品 AutoGLM 2.0——一个手机通用 Agent。支持安卓和IOS。

### 2025-08-17

[How To AI (Almost) Anything](https://mit-mi.github.io/how2ai-course/spring2025/)
[腾讯研究院：2025 AI Coding非共识报告](https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&mid=2650991584&idx=1&sn=3a23e8869afb791ba6e2c47aa3357049&chksm=bd1a5421c93d085ce86933bfb87a2e65ef7d79cbcb76abd2e7d964aea9e02f3e39c0ac155316&scene=0&xtrack=1#rd)
[OpenAI Multi-Agent Portfolio Collaboration](https://cookbook.openai.com/examples/agents_sdk/multi-agent-portfolio-collaboration/multi_agent_portfolio_collaboration?utm_source=chatgpt.com)

[We Made Claude Code Build Lovable in 75 Minutes (With No Code)](https://www.youtube.com/watch?v=_GMtx9EsIKU)

### 2025-08-04

### 2025-08-03

8月3日晚，为期5天的AI Olympic 2025在巴黎拉德芳斯体育馆圆满结束。此次赛事设有代码、数学推理、多模态问答和实时策略四个项目，共吸引了36支顶尖队伍参赛。中国“紫霄-AI”战队以3金1银的优异成绩首次获得综合冠军，而美国的OpenAI和法国的Mistral分别获得亚军和季军。闭幕式上，国际奥委会宣布2027年的比赛将新增“具身智能”和“AI医疗救援”两个新赛道。

### 2025-08-01

美国《AI 主权法案》于8月1日凌晨在参议院以67票对33票获批，总统当天上午10点签署生效。该法案将≥10²⁵ FLOPs训练模型的权重、超参数和训练日志列为“敏感技术”，并对违反出口规定的企业处以全球营收的20%罚款，并追究高管的刑事责任。硅谷超过300家初创公司连夜召开了合规峰会，各大基金如红杉、光速等也紧急调整了投资组合。

## 2025 July

### 2025-07-22

Gemini Deep Think成功破解IMO(国际数学奥林匹克竞赛)前5题，斩获35分（满分42分）。之所以能获得金牌，核心在于它采用了端到端的自然语言推理能力，直接从英文题目描述生成严谨的数学证明。通过高级并行思考技术,同时探索多条推理路径，模拟人类深度思维过程和强化学习训练，Gemini能够在4.5小时内高效探索多条解题路径，并整合最优解法，成功攻克五道高难度数学题，最终获得官方认可的金牌成绩。这一突破不仅体现在解题速度和准确性，更在于AI首次无需形式化语言辅助，完全以自然语言实现了顶尖数学推理水平。标志着AI从被动问答转向主动解决复杂科学问题，为科研、工程等领域带来范式变革。

### 2025-07-19

### 2025-07-20

- 今天写了[Claude Code 介绍](https://hobbytp.github.io/zh/claude/claude_code/)，并把它和Kimi K2模型关联了起来，准备关联更多的MCP server，然后对比一下Claude Code，Cursor，Gemini Code的优劣。

### 2025-07-04

- 今天读了[Reflect, Retry, Reward: 大型语言模型的自我进化新范式](https://hobbytp.github.io/zh/papers/Reflect_Retry_Reward_RL_Finetunning/)，这篇论文的结论是：通过“反思、重试、奖励”方法在微调过程中通过自我反思和强化学习，实现LLM在缺乏外部监督和特定任务数据情况下的自我改进。

### 2025-07-01

- 今天读了[深度研究智能体：系统性审查与路线图](https://hobbytp.github.io/zh/papers/deep_research_agents_sys_exam_roadmap/)，这篇论文的结论是：**深度研究智能体（DR）是基于大型语言模型（LLMs）的智能体，能够通过结合动态推理、自适应长时规划、多跳信息检索、迭代工具使用以及生成结构化分析报告来处理复杂的、多轮的信息研究任务**。

## 2025 June

### 2025-06-30

百度开源了他的第一个开源大模型ERNIE4.5。Tech Report: [我对百度开源500B大模型ERNIE4.5的技术报告的解读](https://hobbytp.github.io/zh/baidu/ernie4.5_open_now/)

### 2025-06-29

以下是当前业界对Claude Code、OpenAI CodeX和Gemini CLI三大AI编程工具的评价对比，综合技术能力、用户口碑、性价比及适用场景分析：

**技术能力与核心优势对比**

| **工具**       | **技术亮点**                                                                 | **主要短板**                               |
|----------------|-----------------------------------------------------------------------------|------------------------------------------|
| **Claude Code** | - 深度代码库理解能力，支持跨文件协调修改和复杂重构<br>- 终端原生集成，自动化Git操作（提交、PR、冲突解决）<br>- 混合推理模式（快速响应+深度思考），SWE-bench测试解决率70.3% | 学习曲线陡峭，订阅成本高（Max套餐约¥1600/月） |
| **OpenAI CodeX** | - 代码生成质量稳定，GitHub Copilot的底层引擎<br>- 支持多种审批模式，代码可控性强 | 功能创新不足，缺乏多模态和终端深度集成 |
| **Gemini CLI**  | - **100万Token上下文窗口**，支持多模态输入（图像、PDF）<br>- **开源免费**（Apache 2.0），每分钟60次，每日1000次免费请求<br>- 原生支持Windows，集成MCP协议扩展功能 | 早期版本稳定性不足（内存泄漏问题），没有cursor好用。但是前景光明。 |

### 2025-06-17

AI的越来越强大，将成为越来越大的杠杆，想不被拉下，需要尽早使用AI，并不断提升自己的技能水平。

### 2025-06-16

MiniMax 推出了他们的首个推理模型：MiniMax M1，这是继 DeepSeek R1 之后第二款最智能的开放权重模型，拥有更长的 100 万个标记的上下文窗口。

- M1 基于其于 2025 年 1 月 14 日发布的 Text-01 模型——这是一个拥有总计 4560 亿参数和 459 亿活跃参数的混合专家模型。这使得 M1 的总参数数量小于 DeepSeek R1 的 6710 亿参数，但大于 Qwen3 的 2350 亿 - 220 亿。Text-01 和 M1 均仅支持文本输入和输出。
- MiniMax M1 80K 在人工智能分析指数上得分为 63 分。这落后于 DeepSeek R1 0528，但略高于阿里巴巴的 Qwen3 235B-A22B 和 NVIDIA 的 Llama 3.1 Nemotron Ultra。MiniMax M1 提供两个版本：M1 40K 和 M1 80K，分别提供 40k 和 80k 的令牌思考预算。
- MiniMax 披露，他们使用 512 块 H800 GPU 对 Text-01 进行了为期三周的完整强化学习训练（非预训练）以创建 M1，这相当于 53 万美元的租赁成本。

### 2025-06-12

- 今天读了[阿里云AI搜索Agentic RAG技术实践](https://mp.weixin.qq.com/s/QmvhG__82zhlAHvjRKkLrg)，这篇论文描述的RAG技术演进之路具有普遍性。而我认为，Agentic RAG 2.0 虽然和Deep Research有一定相似之处，但是前者是“工程驱动的智能协作”，而后者的目标“智能驱动的自我进化”，目标上有差异，但技术上有相互借鉴之处。

### 2025-06-11

今天找了一题给不同的推理模型做，答案是D是酸，A是碱。只有Gemini 2.5 pro, Cloud 3.7 Sonnet Thinking, 元宝R1 答对.奇怪的是DS R1在推理了非常非常非常久后，得出了错误答案，但是元宝R1却答对了。

```note
实验室中有五种无色液体：A、B、C、D、E。已知条件：

    ​A 和 B 混合​ → 产生蓝色沉淀；
    ​B 和 C 混合​ → 无反应；
    ​C 和 D 混合​ → 溶液变红色；
    ​D 和 E 混合​ → 生成无色气体；
    ​A 和 E 混合​ → 无反应。

其中一种液体是酸，一种是碱，其余三种为中性物质。

​问题​：请推断哪种液体是酸？哪种是碱？并解释推理过程。
```

| 模型 | 酸 | 碱 |
|------|----|----|
| O3/4O | D | E |
| G-2.5p | D | A |
| Claud-37T | D | A |
| Grok3 | D | B |
| R1 | D | B |
| 元宝R1 | D | A |

### 2025-06-10

互联网女王”Mary Meeker的AI趋势报告，<https://www.bondcap.com/reports/tai>

### 2025-06-05

- 今天读了[General agents need world models](https://hobbytp.github.io/zh/papers/agents_need_world_models/)，这篇论文的结论是：**智能体本身就是世界模型**。

### 2025-06-04

- 今天读了[OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking](https://hobbytp.github.io/zh/papers/OmniThink/)，这篇论文的结论是：**OmniThink 是一个基于信息树和概念池的“慢思考”方法，旨在解决机器写作中的知识边界扩展问题**。

### 2025-06-03

- 最近一直在对比各种DeepResearch开源项目实现是如何实现“Deep”和“Research”的。

## 2025 May

### 2025-05-31

通义灵码 AI IDE 正式上线，深度适配千问3大模型，集成智能编码助手功能，支持自动记忆和工程感知，提升开发者编程效率和体验。支持 MCP 协议，覆盖 3000 多个 MCP 服务，满足多场景开发需求，如快速创建地图类应用。[link](https://mp.weixin.qq.com/s/hpIWifxXo-UfxvtqboNmpw)

### 2025-05-30

最新公布的DeepSeek R1-0528 非常不错。
![DeepSeek R1-0528 成绩](./images/DS-R1-0528.png)

| Category | Benchmark (Metric)                       | DeepSeek R1 | DeepSeek R1 0528 |
|----------|------------------------------------------|-------------|------------------|
| General  | MMLU-Redux (EM)                         | 92.9        | 93.4             |
|          | MMLU-Pro (EM)                           | 84.0        | 85.0             |
|          | GPQA-Diamond (Pass@1)                   | 71.5        | 81.0             |
|          | SimpleQA (Correct)                      | 30.1        | 27.8             |
|          | FRAMES (Acc.)                           | 82.5        | 83.0             |
|          | Humanity's Last Exam (Pass@1)           | 8.5         | 17.7             |
| Code     | LiveCodeBench (2408-2505) (Pass@1)      | 63.5        | 73.3             |
|          | Codeforces-Div1 (Rating)                | 1530        | 1930             |
|          | SWE Verified (Resolved)                 | 49.2        | 57.6             |
|          | Aider-Polyglot (Acc.)                   | 53.3        | 71.6             |
| Math     | AIME 2024 (Pass@1)                      | 79.8        | 91.4             |
|          | AIME 2025 (Pass@1)                      | 70.0        | 87.5             |
|          | HMMT 2025 (Pass@1)                      | 41.7        | 79.4             |
|          | CNMO 2024 (Pass@1)                      | 78.8        | 86.9             |
| Tools    | BFCL_v3_MultiTurn (Acc)                 | -           | 37.0             |
|          | Tau-Bench (Pass@1)                      | -           | 53.5(Airline)/63.9(Retail) |

| Model                         | AIME 24 | AIME 25 | HMMT Feb 25 | GPQA Diamond | LiveCodeBench (2408-2505) |
|-------------------------------|---------|---------|-------------|--------------|---------------------------|
| Qwen3-235B-A22B               | 85.7    | 81.5    | 62.5        | 71.1         | 66.5                      |
| Qwen3-32B                     | 81.4    | 72.9    | -           | 68.4         | -                         |
| Qwen3-8B                      | 76.0    | 67.3    | -           | 62.0         | -                         |
| Phi-4-Reasoning-Plus-14B      | 81.3    | 78.0    | 53.6        | 69.3         | -                         |
| Gemini-2.5-Flash-Thinking-0520| 82.3    | 72.0    | 64.2        | 82.8         | 62.3                      |
| o3-mini (medium)              | 79.6    | 76.7    | 53.3        | 76.8         | 65.9                      |
| DeepSeek-R1-0528-Qwen3-8B     | 86.0    | 76.3    | 61.5        | 61.1         | 60.5                      |

### 2025-05-29

学习需要结合从上到下的整体理解和从下到上的基础夯实，是一个动态的过程，在不同场景中灵活切换——有时先从上到下（如程序员熟悉新开源代码），有时先从下到上（如学生掌握相对论），有时是以一个为主，另一为辅等等，以实现更有效的知识掌握和应用。

### 2025-05-27

- 微软/Meta/OpenAI Distinguished Engineer- Philip Su访谈, 可以看[这里](https://hobbytp.github.io/zh/interviews/Philip_Su/)
-

### 2025-05-22

- 我给Google IO 2025做了个[总结](https://hobbytp.github.io/zh/google/google_io_2025/)
- Google Deep Research新提供了几个功能：用户可以将自己的文件上传到DR平台，并通过在 Canvas 中将它们转化为互动内容、测验、音频概述等，让你的报告更具沉浸感。后面考虑写一篇使用Deep Research的教程。

### 2025-05-21

“Vibe Coding”（“氛围编程”）指的是一种使用 AI 模型进行软件开发的方式，在这种方式下，开发者更关注高层级的需求和意图，而不太关心底层的技术实现细节。与传统的编程相比，Vibe Coding 更侧重于通过自然语言与 AI 交流，让模型生成大部分代码，开发者主要关注结果是否符合预期。这使得非专业开发者也能参与软件创建，实现个人实用程序。然而，这种方式也存在挑战，因为生成的代码可能对 Vibe Coder 来说是黑箱，难以理解和修改底层逻辑。

### 2025-05-20

### 2025-05-18

对于动物图片的识别，AI为什么需要大量的数据才能学会，而不像人一样通过少量的数据就能学会？比如你教小baby认猫，只需要给他看几张图片，听你说，他就学会了，下次见到即使不一样的猫，他也能认出来。但是AI必须通过大量的数据（大量的猫的照片）才能学会。我今天的一个想法是，深度模型的参数很多，所以它对一个事物所能提供的“Feature（特征）”也多，这些特征往往是人类不可知的，但是它却能通过这些“暗”特征来识别事物，大模型能把整个人类知识囊括到大模型这个超大“函数”里，这个“暗feature解构能力功不可没，但也从另一方面导致了，它想认识一个事物，仅凭几张图片是不行的，因为不足以生成“暗”特征。也就是说，它缺少了“归纳”的能力，它只能根据已有的数据来识别事物，而不能根据事物之间的关联来识别。人类的大脑经过多年的进化，已经具备了“归纳”，也就是浓缩主要信息，并根据主要信息来在不同的对象之间快速建立联系来达到认识相似的事物的能力，所以人类只需要少量的数据就能学会一个新事物。

### 2025-05-17

### 2025-05-16

### 2025-05-15

Grok告诉我：“微软近期裁员 6000 人的最根本原因在于通过裁员来控制成本、提高运营效率，同时继续在人工智能领域大力投入。”

### 2025-05-14

Devin 的 [deepwiki](https://deepwiki.com/) 是一款非常出色的 AI 网页工具，它能够根据 GitHub 仓库自动生成相关的知识库文档，并为用户提供一个名为 “DeepResearch” 的问答窗口，方便高效地检索和交流技术内容。

### 2025-05-13

在2025年4月的最新模型（o3、GPT-4.1）上，医生参考AI输出后，已无法进一步提升AI答案，在医疗安全场景下，“最差表现”比“平均表现”更关键。提升极端case下的稳健性，将是下阶段AI医疗模型优化的重心。(参考[OpenAI HealthBench](https://openai.com/index/healthbench/))

### 2025-05-12

从红杉资本2025 年 AI 峰会的上获得的一些思考

- Agent经济：Agent as a Service将替代SaaS。软件的合作将变成Agent之间的合作。Agent不仅在软件层面，更会在物理层面操作现实世界的设备。商业模式从卖“工具”转向卖“成果”,卖“Agent”劳动力。物理层面也需要“图灵测试”和“物理API”，具身智能的标准化需要提到日程。
- Agent技术：RL将在Agent的世界继续发扬光大，Deep Research的下一步是科学原创，比如发现广义相对论级别的科学理论。另外多Agent的协作和安全需要新技术的加持。
- 基础模型：当前的pre-train模型在数据用尽的情况下基本到头，需要新的模型技术突破。
- 基础设施加大投资：在Agent经济不断扩大的前提下，推理需要的硬件将继续增长。

### 2025-04

吴恩达新作《如何在人工智能领域建立你的职业生涯》英文原版，[link](https://home-wordpress.deeplearning.ai/wp-content/uploads/2022/10/eBook-How-to-Build-a-Career-in-AI.pdf)
中文翻译校对版：[link](https://zhuanlan.zhihu.com/p/18050458835)

引言：AI编程是新的读写能力
第一章：职业生涯发展的三个步骤：学习，项目，找工作
第二章：学习建构人工智能职业生涯的关键技能

- 基础机器学习技能
- 深度学习
- 与机器学习相关的数学
- 软件开发
第三章：你应该学习数学来获得人工智能的工作吗？
- 面向 AI/ML 工作只需掌握能支持关键建模与调试决策的那层数学（随技术成熟所需深度会下降），同时保留由好奇心驱动的自由探索以孕育创新。
第四章：成功 AI 项目的范围
- 人工智能架构师最重要的技能之一就是能够识别出值得开展的想法。
- 步骤 1、确定业务问题（而不是人工智能问题）。
- 步骤 2、头脑风暴 AI 解决方案。
- 步骤 3、评估潜在解决方案的可行性和价值。
- 步骤 4、确定里程碑。
- 步骤 5、预算资源。
第五章：寻找与你的职业目标互补的项目
- 通过连续、难度递增且与职业目标互补的项目实践（小起步→快迭代→择优放大），用“准备-开火-瞄准”式低成本试错与必要时“准备-瞄准-开火”的前置论证相结合，加速技能复利与影响力攀升。
第六章：建立能够展示技能进步的项目组合
- 建立一个项目组合，特别是一个随着时间的推移从简单到复杂的项目组合，在找工作时将大有帮助。
第七章、开启人工智能求职的简单框架
第八章：使用咨询性面谈找到合适的工作
- 在进行咨询性面谈前，提前研究面试者和公司，以便带着深思熟虑的问题参加面试。你可以问以下问题：
  - 你通常一周或一天的工作内容是什么？
  - 这个职位最重要的任务是什么？
  - 成功最需要哪些技能？
  - 你的团队如何合作以实现目标？
  - 招聘流程是什么？
  - 对于过去表现突出的候选人，他们脱颖而出的原因是什么？
第九章：找到适合你的AI工作
第十章：在人工智能领域建立事业的关键
第十一章：克服冒名顶替综合症
