---
title: "深度研究智能体：系统性审查与路线图"
date: "2025-07-01T23:10:00+08:00"
draft: false
tags: ["deep_research_agents", "systematic_examination", "roadmap"]
categories: ["papers"]
description: "本文介绍了深度研究智能体：系统性审查与路线图。"
---

DEEP RESEARCH AGENTS: A SYSTEMATIC EXAMINATION AND ROADMAP
[深度研究智能体：系统性审查与路线图](https://arxiv.org/pdf/2506.18096)

- [Google NotebookLM Link](https://notebooklm.google.com/notebook/1e30bc99-651f-4684-bb64-7e8976b44d00?_gl=1*1mc7ba*_ga*NjM2Mzk2MTMzLjE3MTkzNjY0MjE.*_ga_W0LDH41ZCB*MTcxOTM2NjQyMC4xLjAuMTcxOTM2NjQyMC42MC4wLjA.&original_referer=https:%2F%2Fnotebooklm.google%23&pli=1)

## 摘要

该文深入探讨了基于大型语言模型（LLMs）的深度研究（DR）智能体，这些智能体能够通过结合动态推理、自适应长时规划、多跳信息检索、迭代工具使用以及生成结构化分析报告来处理复杂的、多轮的信息研究任务。本报告将详细分析DR智能体的核心技术、架构组成、评估基准及其面临的挑战和未来发展方向。

## 核心概念与技术

### 1. 深度研究智能体的定义

**DR智能体被正式定义为：**
“由LLMs驱动的AI智能体，集成动态推理、自适应规划、多迭代外部数据检索和工具使用，以及为信息研究任务生成全面的分析报告。”（Huang et al., 2025, p.1）
与传统的检索增强生成（RAG）方法和常规工具使用（TU）系统相比，DR智能体具备更高的自主性、持续深入的推理能力、动态任务规划和自适应实时交互能力。

### 2. 信息获取策略

DR智能体通过搜索引擎获取外部知识，主要分为两类：

- API-Based Retrieval（基于API的检索）：
  - 通过结构化API接口获取数据，例如Semantic Scholar API、SerpApi、PubMed API和Bing Search API。
  - 优点：擅长结构化、高吞吐量的数据获取。
  - 局限性：难以处理深度嵌套的客户端JavaScript渲染内容、交互式组件或认证障碍。
- Browser-Based Exploration（基于浏览器的探索）：
  - 通过模拟人类浏览器行为进行探索，能够全面提取和分析动态或非结构化信息。
  - 能够访问传统API无法触及的信息，如企业软件、移动应用程序和订阅服务（例如Bloomberg Terminal）。

### 3. 模块化工具使用框架

为了扩展与外部环境交互的能力，DR智能体引入了以下核心工具模块：

- 代码解释器（Code Interpreter）：
  - 使DR智能体能够在推理过程中执行脚本，进行数据处理、算法验证和模型仿真。
  - 大多数DR智能体都嵌入了脚本执行环境，通常依赖Python或Java工具。
- 数据分析（Data Analytics）：
  - 通过集成数据分析模块，将原始检索结果转换为结构化洞察，例如计算统计数据、生成可视化图表和进行定量模型评估。
  - 许多商业DR智能体已实现此功能，但技术细节通常不公开。学术研究中CoSearchAgent、AutoGLM和Search-o1提供了具体示例。
- 多模态处理（Multimodal Processing）：
  - 处理文本、图像等多种模态输入，例如Grok DeepSearch能够从各种来源收集文本、图像和代码等多种模态输入。
  - 处理文本、图像等多种模态输入，例如Grok DeepSearch能够从各种来源收集文本、图像和代码等多种模态输入。
- 模型上下文协议（Model Context Protocols, MCPs）：
  - 一种标准化的接口，支持工具的可扩展性和生态系统开发，使得智能体能够动态访问和配置新的工具服务器。

### 4. 架构与工作流

DR系统架构和工作流根据其规划策略和智能体组成可分为以下类型：

- 静态工作流（Static Workflow）：
  - 预定义任务序列，固定智能体角色，适应性简单，需要针对每个任务进行定制。
  - 示例：Avatar、Agent Laboratory、CoSearchAgent等。
- 动态工作流（Dynamic Workflow）：
  - 规划策略：
    - 仅规划（Planning-Only）：直接根据用户初始提示生成任务计划，不进行进一步澄清。大多数现有DR智能体采用此方法，如Grok DeepSearch、H2O和Manus。
    - 意图到规划（Intent-to-Planning）：在规划前通过提问主动澄清用户意图。OpenAI DR采用此方法。
    - 统一意图规划（Unified Intent-Planning）：从初始提示生成初步计划，并与用户交互以确认或修改计划。Gemini DR是此策略的代表。
  - 智能体组成：
    - 动态单智能体系统（Dynamic Single-Agent Systems）：
      - 将规划、工具调用和执行集成在一个统一的LTM中，任务管理简化为内聚的认知循环。
      - 优点：简化任务管理，实现端到端强化学习优化，推理、规划和工具调用集成更流畅。
      - 局限性：对基础模型的推理能力、上下文理解和工具选择调用能力要求高；模块化灵活性受限。
      - 示例：Agent-R1、ReSearch、Search-R1。
    - 动态多智能体系统（Dynamic Multi-Agent Systems）：
      - 利用多个专业智能体通过自适应规划策略协同执行子任务。通常采用分层或集中式规划机制。
      - 优点：能够处理复杂、可并行化的研究任务，提高灵活性和可扩展性。
      - 挑战：协调多个独立智能体的复杂性，端到端强化学习优化困难。
      - 示例：OpenManus、Manus、OWL、Alita。

### 5. 记忆机制

为处理长上下文任务，DR系统采用多种优化策略：

- 扩展上下文窗口长度：例如Google的Gemini模型支持高达一百万个token的上下文窗口。计算成本高，资源利用效率低。
- 压缩中间步骤：通过压缩或总结中间推理步骤减少处理的token数量，提高效率和输出质量。可能导致细节信息丢失，影响后续推理精度。
- 利用外部结构化存储：将历史信息存储在外部结构化存储中，例如文件系统、向量数据库或知识图谱，以提高记忆容量、检索速度和语义相关性。开发和维护成本较高。
利用外部结构化存储：将历史信息存储在外部结构化存储中，例如文件系统、向量数据库或知识图谱，以提高记忆容量、检索速度和语义相关性。开发和维护成本较高。

### 6. 强化学习（RL）优化

RL在DR智能体中扮演关键角色，例如：

- RAG-RL：通过强化学习和课程学习技术，使推理语言模型更有效地识别和利用相关上下文。
- ToolRL：通过精心设计的奖励结构（评估最终答案正确性、工具选择适当性、参数指定准确性和推理效率），显著增强模型的工具推理能力。
- Pangu DeepDiver：通过两阶段的SFT和RL课程训练，实现搜索深度的自适应调整。
- Agent-R1：将RL集成到LLM智能体的端到端训练中，实现了自适应规划、迭代执行和任务精炼的高级能力。

### 现有DR智能体系统

文章列举了多个行业领先的DR智能体解决方案：

- OpenAI DR：专注于复杂的推理和信息检索，采用“意图到规划”策略。
- Gemini DR (Google DeepMind)：基于多模态Gemini 2.0 Flash Thinking模型，通过强化学习驱动的微调增强规划和自适应研究能力，实现交互式研究规划、异步任务管理、大规模上下文窗口RAG集成和高速自适应检索。
- Perplexity DR：擅长将复杂查询分解为子任务，进行迭代式网络搜索，并生成结构化报告，具备动态提示引导的模型选择能力。
- Grok DeepSearch (xAI)：结合实时信息检索与多模态推理，处理复杂的信息密集型问题，具有分段模块处理流水线（包括可信度评估、实时数据获取、交叉验证和多模态集成）和动态资源分配能力。
- AutoGLM Rumination (Zhipu AI)：一个基于RL的系统，通过自我反思和迭代改进机制增强多步推理和高级函数调用能力，能够自主与网络环境交互、执行代码、调用外部API并生成综合报告。在实际执行中的自主性优于OpenAI DR，并能访问用户认证资源。
- Microsoft 365 Copilot：引入了研究员和分析师功能。

### 评估基准与挑战

#### 1. 评估基准

评估DR智能体需要捕捉其完整研究工作流的基准，包括多步信息检索、跨源合成、动态工具调用和结构化报告生成。现有评估主要分为两类：

- 问答（QA）基准：
  - 从简单的事实查询到复杂的研究型问题，评估智能体的事实知识、领域特定推理和信息集成能力。
  - 包括：TriviaQA、Natural Questions (NQ)、PopQA (单跳事实召回)；HotpotQA、2WikiMultihopQA (多跳推理)；以及高难度的Humanity’s Last Exam (HLE) 和BrowseComp。
  - HLE和BrowseComp被认为是DR智能体评估中最关键和未解决的挑战，因为它们要求专家级、开放域的科学问题解决能力和从网络中查找难以发现的信息的能力，且过滤了可通过参数知识直接解决的问题。

- 任务执行（Task Execution）基准：
  - 评估智能体更广泛的能力，如长时规划、多模态理解、工具使用和环境交互。
  - 包括：GAIA、AssistantBench、Magentic-One (通用助手任务)；SWE-bench、HumanEvalFix、MLE-bench (研究和代码导向任务)；RE-Bench、RESEARCHTOWN (多智能体研究环境)。
  - GAIA是其中最重要的基准之一，提供多样化、真实且人类易解但对当前智能体极具挑战性的任务。

任务执行（Task Execution）基准：

- 评估智能体更广泛的能力，如长时规划、多模态理解、工具使用和环境交互。
- 包括：GAIA、AssistantBench、Magentic-One (通用助手任务)；SWE-bench、HumanEvalFix、MLE-bench (研究和代码导向任务)；RE-Bench、RESEARCHTOWN (多智能体研究环境)。
- GAIA是其中最重要的基准之一，提供多样化、真实且人类易解但对当前智能体极具挑战性的任务。

包括：GAIA、AssistantBench、Magentic-One (通用助手任务)；SWE-bench、HumanEvalFix、MLE-bench (研究和代码导向任务)；RE-Bench、RESEARCHTOWN (多智能体研究环境)。
◦
GAIA是其中最重要的基准之一，提供多样化、真实且人类易解但对当前智能体极具挑战性的任务。

#### 2. 基准错位（Benchmark Misalignment）

当前DR评估面临的主要问题是基准错位：

- 大多数公共DR评估仍依赖于传统QA套件，其内容往往已被模型参数内化，导致智能体无需实际研究即可给出答案，从而虚高了性能。
- 急需开放网络、时间敏感的基准，以真实探测智能体的检索、推理和工具使用能力。
- 现有基准的指标过于狭窄，主要关注信息检索、提取和工具调用，忽视了DR智能体的核心产出——结构化、多模态的研究报告。
未来研究需要开发能评估DR智能体端到端报告生成能力的综合基准，包括长篇叙述、集成表格和图表以及多模态一致性，从而评估事实准确性、篇章结构和跨模态对齐。

#### 3. 主要挑战与未来方向

- 拓宽信息来源：现有DR智能体依赖静态知识库或公共网络内容，无法访问应用程序、专有接口或专业数据库后的信息。未来需通过MCP集成更细粒度和广泛的模块化工具，实现对专有应用程序、数据库或API的动态访问。
- 事实核查与自我反思：需要引入结构化验证循环和自我反思能力，例如多源交叉验证和对中间结果的检查与测试，以显著降低事实错误和幻觉。Grok DeepSearch和Zhipu的Rumination模型已在此方面做出探索。
- 异步并行执行：现有DR智能体多依赖线性任务规划。未来可采用基于有向无环图（DAG）的异步并行架构和通过强化学习训练的调度智能体，以提高效率、鲁棒性和动态调整能力。
- 工具集成推理（Tool-Integrated Reasoning, TIR）：要求智能体不仅按逻辑顺序调用工具，还能根据中间结果自适应调整推理路径。强化学习与精心设计的奖励结构可显著提升TIR能力。
- 优化多智能体架构：通过分层强化学习（HRL）和后训练优化流水线，促进智能体间的协作学习和交互。
- 自进化语言模型智能体：借鉴案例推理（CBR）等非参数持续学习方法，使智能体能够动态检索、适应和重用结构化问题解决轨迹，从而实现持续适应和优化，而无需更新模型参数。未来应扩展至更全面的案例推理框架和自主工作流进化，以探索、修改和优化执行计划。
- 任务泛化能力有限：现有DR智能体主要针对特定任务进行优化，缺乏泛化能力，难以处理新任务或适应不同领域。
- 任务工作流不灵活：现有DR智能体的工作流通常是预定义的，缺乏灵活性，难以适应不同任务需求。
- 集成细粒度外部工具困难：现有DR智能体通常只能集成有限的工具，缺乏灵活性，难以适应不同任务需求。
- 高级规划和优化的计算复杂度高：现有DR智能体通常只能集成有限的工具，缺乏灵活性，难以适应不同任务需求。  

**未来研究方向包括：**

- 通过模块化能力提供者（如基于操作符的架构）实现更广泛、更灵活的工具集成。
- 开发异步和并行规划框架（如基于有向无环图的方法）。
- 为多代理架构开发复杂的端到端优化方法，如层次强化学习或多阶段微调管道。

**论文强调，随着LLM技术的持续进步，DR代理有潜力改造复杂研究工作流程，提升人类生产力，推动学术和工业领域的创新。**

## 结论

LLM驱动的深度研究智能体代表了自动化研究支持的新兴范式。它们通过集成迭代信息检索、长篇内容生成、自主规划和复杂工具利用等先进技术，在效率和成本效益上具备巨大潜力。未来的研究将集中于拓展信息获取范围、实现异步并行执行、开发更全面的多模态基准以及优化多智能体架构，从而使DR智能体成为下一代智能协作研究平台的基础技术支柱。

相关资源链接为[awesome-deep-research-agent](https://github.com/ai-agents-2030/awesome-deep-research-agent)，这是一个持续更新的DR代理研究仓库。
