---
title: 通过代码执行提高模型上下文协议（MCP）效率的机制
date: "2025-11-10T21:10:00+08:00"
draft: false
description: 通过代码执行提高模型上下文协议（MCP）效率的机制，主要在于优化了上下文窗口的使用、降低了Token消耗、加速了复杂任务的执行，并提高了代理处理工具的能力。
tags: [MCP, Code Mode, 模型上下文协议, 代码模式, 代码执行, 高效, 优化, 延迟, 节省, 节省时间和成本, 节省Token, 优化效率, 优化延迟, 优化Token消耗, 优化复杂任务执行, 代理处理工具能力]
categories: ["big_companies", "context_engineering"]
---

## 背景

在用过Claude Skills后，我就想到了一个问题：既然Claude Skills使用文件系统和脚本的方式来按需加载skills相关的上下文，那么为什么不能使用相似的方法来动态加载MCP的工具呢？毕竟，当前大量地把MCP加载到LLM的上下文里，对于某些复杂任务来说仍然显得捉襟见肘。

今天Claude工程文档就公布了这个“Code Mode”调用MCP的方式。这个方式与Claude Skills的加载方式有很高的相似度。

## 介绍

Claude这篇文章提出的“在代理中使用代码执行访问 MCP（而非直接工具调用）”主要解决了两类导致成本和时延激增的问题，并带来一系列工程化收益。核心要点如下：

### 一、直接解决的两大痛点

- **工具定义挤爆上下文窗口**
  - 现状：大量 MCP 服务器、成百上千工具的 schema/描述被一次性塞进上下文，导致初始提示极肥、吞吐慢、费用高。
  - 方案：将工具以“代码 API + 文件系统浏览”的方式按需发现与加载，模型只读取当前任务必要的少量文件/接口定义，极大降低初始 tokens（示例从约150k降到约2k）。

- **巨量中间结果反复穿过模型上下文**
  - 现状：A 工具产出的巨量数据被写回上下文，再由模型拼装调用 B 工具，导致大文档多次过模、易超窗口，还容易复制粘贴出错。
  - 方案：把数据处理放到代码执行环境内完成（过滤/聚合/抽取/连接等），仅将必要的摘要或少量样例回显给模型，大幅减少中间结果 token 消耗与差错率。

### 二、由代码执行带来的工程化优势

- **渐进披露（Progressive disclosure）**
  - 通过文件系统枚举/搜索工具，实现“按需读定义”，可配置不同详情级别（仅名称、名称+描述、含 schema 全量），进一步节流。

- **上下文高效的控制流与数据管道**
  - 用循环、条件、重试、错误处理等常规代码逻辑替代“工具调用-等待-再工具调用”的回合式 orchestration，减少往返时延与上下文噪声；也降低 TTFT（time-to-first-token）。

- **隐私与合规**
  - 中间数据默认留在执行环境中；可在客户端层面对 PII 做自动 tokenization，模型仅看匿名化占位符，实际数据在后续调用中由客户端反向映射，避免敏感数据进入模型上下文与日志。

- **状态持久化与“技能”复用**
  - 借助文件系统落盘中间产物与可复用函数，形成可持续积累的“技能库”（SKILL.md + 可执行脚本），提高后续任务的启动效率与稳定性。

### 三、权衡与注意事项

- 引入代码执行需要安全沙盒、资源配额与监控，带来一定运维与安全复杂度；需要在成本（token/时延/可组合性）和基础设施投入之间做平衡。

### 四、一句话总结

- 方法论本质：把“工具编排问题”转化为“写代码问题”。让模型去写/读/调用少量代码，而不是在上下文里搬运庞大的工具定义与数据，从而实现更低 token、更低延迟、更少错误、更强可组合性。

## Code Mode 和 Skills 相似点和细微区别

- **相似点**：
  - **动态加载机制：** 两者都采用“按需加载”的策略。Claude Skills将技能定义为文件夹（包含指令、脚本和资源），Claude模型通过文件系统（如file_read工具）动态读取和加载特定技能，而非一次性注入所有内容到上下文窗口中。 同样，MCP允许代理生成代码来探索虚拟文件系统（VFS），动态加载工具和数据，只在需要时执行，避免了静态工具列表的冗余。
  - **代码/脚本与文件系统集成：** Skills运行在代码执行沙箱中，支持文件系统访问、bash命令和脚本执行，模型可以编写代码来处理复杂任务（如循环、数据过滤），中间结果在沙箱内生成，不全塞进LLM上下文。 MCP也正是通过代码执行（在沙箱中运行Python或其他脚本）来处理工具交互和数据加工，同样依赖文件系统来管理工具描述和状态持久化，只将精炼的处理结果（如总结或关键输出）反馈给模型。
  - **上下文优化：** 核心目标一致——减少token消耗。Skills避免了“上下文膨胀”（context bloat），因为中间文本（如大数据集的原始输出）留在沙箱外，只注入必要结果；MCP更进一步，将token使用从150k降到2k（约98.7%减少），通过外部执行实现“零中间数据暴露”。

- **细微区别**：
  - **触发与范围：** Skills更侧重“技能文件夹”的声明式定义，适合特定任务的定制（如领域专家技能），触发时模型主动读取文件。 MCP更通用，聚焦于工具协议（Model Context Protocol），允许代理在运行时动态发现和调用任意MCP服务器上的工具，扩展性更强（已催生数千社区服务器）。
  - **依赖关系：** Skills依赖Code Execution Tool（beta版）来运行脚本，而MCP正是这个执行环境的协议层优化，常与Skills结合使用（如Claude编写代码 → 沙箱执行 → 调用MCP）。

总体上，MCP可以视为Claude Skills动态加载哲学的演进版，两者都体现了Anthropic对高效代理设计的理念：让LLM“思考”而非“存储”，通过外部计算保持上下文精简。

## 总结

通过将 MCP 工具转化为 TypeScript API 并允许 LLM 编写代码，代理能够利用其强大的编码能力来处理复杂的逻辑和数据流。这种方法将软件工程中已知的解决方案（如上下文管理和状态持久化）应用于代理，核心提升在于通过按需加载工具和在执行环境中过滤数据，**极大地提高了Token效率**，同时通过沙盒执行环境保证了速度和安全性。

将 MCP 的代码执行模式想象成一位厨师（LLM）从一本完整的烹饪书（所有工具定义）切换到只使用一张智能配方卡。传统模式下，厨师需要大声朗读并抄写配方卡上的每一步（高Token消耗），并将每一步的中间结果（切好的菜、混合的酱汁）反复向你汇报。而在代码执行模式下，厨师拿到配方卡后，可以进入一个高效的准备区（沙盒隔离），在那里用熟悉的技巧（TypeScript 代码）快速完成所有的切菜、混合、过滤等操作，最终只向你展示成品（最终结果），从而节省了大量的中间沟通时间、精力和原材料（Token）。

## 参考资料

- [Code execution with MCP: Building more efficient agents](https://www.anthropic.com/engineering/code-execution-with-mcp)
- [Code Mode: the better way to use MCP](https://blog.cloudflare.com/code-mode/)
- [NotebookLM](https://notebooklm.google.com/notebook/b256d48e-f8a0-4764-91a3-bae3ac8213d3)
