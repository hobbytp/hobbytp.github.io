---
title: "Karpathy: 2025 å¹´å¤§è¯­è¨€æ¨¡å‹å¹´åº¦å›é¡¾"
date: "2025-12-20T22:30:00+08:00"
draft: false
tags: ["AI","Karpathy","llm","Review"]
categories: ["celebrity_insights"]
description: "Karpathyå¤§ç¥åœ¨2025å¹´å¹´åº•çš„æ—¶å€™å¤šå¤§æ¨¡å‹è¿™ä¸€å¹´çš„å‘å±•åšäº†ä¸€ä¸ªå¹´åº¦æ€»ç»“,æˆ‘æ¬è¿è¿‡æ¥ï¼Œç¿»è¯‘äº†ä¸€ä¸‹ã€‚"

cover:
  image: "/images/generated-covers/Andrej_Karpathy_2025_Review.webp"
  alt: "Karpathy: 2025 å¹´å¤§è¯­è¨€æ¨¡å‹å¹´åº¦å›é¡¾"
---

Karpathyå¤§ç¥åœ¨2025å¹´å¹´åº•çš„æ—¶å€™å¤šå¤§æ¨¡å‹è¿™ä¸€å¹´çš„å‘å±•åšäº†ä¸€ä¸ªâ€œå¹´åº¦æ€»ç»“â€ï¼Œæˆ‘ç”¨Qwen3 Maxåšäº†ç¿»è¯‘ï¼Œä¾›å¤§å®¶é˜…è¯»ã€‚æˆ‘åœ¨æ–‡åé™„ä¸Šäº†æˆ‘ä¸ªäººçš„çœ‹æ³•ã€‚

ç®€å•è¯´ï¼ŒKarpathy è§‰å¾—è¿™ä¸€å¹´ AI å‘ç”Ÿäº†å‡ ä¸ªæ˜¾è‘—çš„å˜åŒ–ï¼š

* **ä»â€œå–‚é¥­â€åˆ°â€œæ‚Ÿé“â€**ï¼š ä»¥å‰è®­ç»ƒ AI é äººå·¥æ ‡æ•°æ®ï¼ˆRLHFï¼‰ï¼Œç°åœ¨é ç»™å®ƒä¸€ä¸ªç›®æ ‡è®©å®ƒè‡ªå·±åœ¨æ•°å­¦å’Œä»£ç é‡Œâ€œæ‚Ÿâ€ï¼ˆRLVRï¼‰ã€‚AI å¼€å§‹è‡ªå‘äº§ç”Ÿæ¨ç†ç­–ç•¥ï¼Œé‚£ç§â€œo3 æ€è€ƒæ—¶â€çš„é¡¿æ‚Ÿæ„Ÿï¼Œå°±æ˜¯è¿™ä¹ˆæ¥çš„ã€‚

* **å®ƒæ˜¯â€œå¹½çµâ€ä¸æ˜¯â€œåŠ¨ç‰©â€**ï¼š åˆ«å†ç”¨äººç±»çš„é€»è¾‘å»è¡¡é‡å®ƒäº†ã€‚AI çš„æ™ºèƒ½æ˜¯â€œé”¯é½¿çŠ¶â€çš„ï¼šå®ƒèƒ½è§£é¡¶çº§æ•°å­¦é¢˜ï¼Œå´å¯èƒ½è¢«ä¸€å¥åƒåœ¾è¯éª—èµ°ä½ çš„éšç§ã€‚å®ƒä¸æ˜¯ä¸€ä¸ªæ­£åœ¨æˆé•¿çš„å©´å„¿ï¼Œè€Œæ˜¯ä¸€ä¸ªè¢«å¬å”¤å‡ºæ¥çš„ã€æåº¦åç§‘çš„â€œå¹½çµâ€ã€‚

* **â€œæ°›å›´ç¼–ç¨‹â€å½»åº•ç«äº†**ï¼š 2025 æ˜¯â€œVibe Codingâ€å…ƒå¹´ã€‚ä»£ç å˜å¾—å»‰ä»·ã€éšç”¨éšå¼ƒã€‚åªè¦ä½ è‹±è¯­å¤Ÿå¥½ã€å®¡ç¾åœ¨çº¿ï¼Œä½ å°±èƒ½â€œæ±‚â€AI ç»™ä½ æ“å‡ºä»»ä½•ç¨‹åºï¼Œç”šè‡³ä¸éœ€è¦å»çœ‹ä¸€çœ¼æºç ã€‚

* **AI ä½è¿›äº†ä½ çš„ç”µè„‘**ï¼š åˆ«å†åªç›¯ç€ç½‘é¡µç‰ˆ ChatGPT äº†ï¼Œåƒ Claude Code è¿™ç§ç›´æ¥è·‘åœ¨æœ¬åœ°ã€æ“ä½œä½ æ–‡ä»¶ç³»ç»Ÿçš„ Agent æ‰æ˜¯æœªæ¥ã€‚å®ƒä¸å†æ˜¯ä¸€ä¸ªæœç´¢å¼•æ“ï¼Œè€Œæ˜¯ä½ ç”µè„‘é‡Œçš„ä¸€ä¸ªâ€œæ•°å­—çµé­‚â€ã€‚


## 2025 å¹´å¤§è¯­è¨€æ¨¡å‹å¹´åº¦å›é¡¾


2025 å¹´ï¼Œæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å–å¾—å¼ºåŠ²è€Œè·Œå®•èµ·ä¼è¿›å±•çš„ä¸€å¹´ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä¸ªäººçœ¼ä¸­**å°¤ä¸ºçªå‡ºã€ç•¥å¸¦æ„å¤–çš„å‡ é¡¹â€œèŒƒå¼è¿ç§»â€**â€”â€”å®ƒä»¬ä¸åªæ˜¯æŠ€æœ¯è¿­ä»£ï¼Œæ›´åœ¨æ¦‚å¿µå±‚é¢ä¸Šé‡å¡‘äº†æˆ‘å¯¹æ™ºèƒ½æœ¬è´¨çš„ç†è§£ã€‚

### 1. **åŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰**

2025 å¹´åˆï¼Œå„å¤§å®éªŒå®¤çš„ LLM ç”Ÿäº§æµç¨‹è¿˜é•¿è¿™æ ·ï¼š  
â–¸ é¢„è®­ç»ƒï¼ˆPretrainingï¼ŒGPT-2/3 æ—¶ä»£ï¼Œ~2020ï¼‰  
â–¸ ç›‘ç£å¾®è°ƒï¼ˆSFTï¼ŒInstructGPT æ—¶ä»£ï¼Œ~2022ï¼‰  
â–¸ åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼Œ~2022ï¼‰  

è¿™å¥—æµç¨‹ç¨³å®šã€æˆç†Ÿï¼Œæ˜¯è®­ç»ƒå·¥ä¸šçº§ LLM çš„â€œé»„é‡‘é…æ–¹â€ã€‚  
è€Œ 2025 å¹´ï¼Œ**åŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning from Verifiable Rewards, RLVRï¼‰**æ¨ªç©ºå‡ºä¸–ï¼Œæˆä¸ºè¿™å¥—æµç¨‹ä¸­äº‹å®ä¸Šçš„**ç¬¬å››æ”¯æŸ±**ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šè®© LLM åœ¨ä¸€ç³»åˆ—**å¯è‡ªåŠ¨éªŒè¯ç»“æœçš„ç¯å¢ƒ**ä¸­ä¼˜åŒ–ï¼ˆæ¯”å¦‚æ•°å­¦é¢˜ã€ç¼–ç¨‹è°œé¢˜ï¼‰ï¼Œå¹¶ä»¥å®¢è§‚å¥–åŠ±ä¿¡å·é©±åŠ¨å­¦ä¹ ã€‚  
ç¥å¥‡çš„æ˜¯â€”â€”æ¨¡å‹ç«Ÿ**è‡ªå‘æ¶Œç°å‡ºäººç±»ç§°ä¹‹ä¸ºâ€œæ¨ç†â€çš„ç­–ç•¥**ï¼šå®ƒå­¦ä¼šæŠŠé—®é¢˜æ‹†è§£ä¸ºä¸­é—´æ­¥éª¤ï¼Œå­¦ä¼šâ€œå›æº¯-è¯•æ¢-ä¿®æ­£â€çš„è§£é¢˜å¾ªç¯ï¼ˆå‚è§ DeepSeek R1 è®ºæ–‡ä¸­çš„ç²¾å½©æ¡ˆä¾‹ï¼‰ã€‚  
è¿™äº›èƒ½åŠ›ï¼Œåœ¨ SFT æˆ– RLHF æ¡†æ¶ä¸‹æéš¾å®ç°â€”â€”å› ä¸ºäººç±»æ ¹æœ¬è¯´ä¸æ¸…â€œæœ€ä¼˜æ¨ç†è·¯å¾„â€é•¿ä»€ä¹ˆæ ·ï¼›è€Œ RLVR æŠŠè¿™ä¸ªé—®é¢˜äº¤è¿˜ç»™ä¼˜åŒ–å™¨ï¼šè®©æ¨¡å‹è‡ªå·±åœ¨å¥–åŠ±æ¢¯åº¦ä¸­**æ‘¸ç´¢å‡ºé€‚åˆè‡ªå·±çš„è§£é¢˜ä¹‹é“**ã€‚

ä¸ SFT/RLHF è¿™ç±»â€œè½»é‡å¾®è°ƒâ€ä¸åŒï¼ŒRLVR å¯åœ¨**å®¢è§‚ã€ä¸å¯é’»ç©ºå­ï¼ˆnon-gameableï¼‰çš„å¥–åŠ±å‡½æ•°ä¸‹æŒç»­ä¼˜åŒ–æé•¿æ—¶é—´**ã€‚å®è·µä¸‹æ¥ï¼ŒRLVR çš„**èƒ½åŠ›æå‡/æ¯ç¾å…ƒç®—åŠ›**æé«˜â€”â€”é«˜åˆ°å®ƒå‡ ä¹â€œåƒå…‰â€äº†åŸæœ¬ä¸ºé¢„è®­ç»ƒé¢„ç•™çš„ç®—åŠ›æ± ã€‚

äºæ˜¯ï¼Œ2025 å¹´çš„èƒ½åŠ›è·ƒè¿›ï¼Œä¸å†é â€œæ›´å¤§æ¨¡å‹â€ï¼Œè€Œæ˜¯é â€œæ›´é•¿ RL è®­ç»ƒâ€ã€‚æˆ‘ä»¬çœ‹åˆ°çš„æ˜¯ï¼š**æ¨¡å‹å°ºå¯¸å¤§è‡´æŒå¹³ï¼Œä½† RL è®­ç»ƒæ—¶é•¿æŒ‡æ•°çº§å¢é•¿**ã€‚

æ›´ç‹¬ç‰¹çš„æ˜¯ï¼ŒRLVR å¼•å…¥äº†ä¸€ä¸ªå…¨æ–°çš„ã€å¯æ§çš„â€œæ—‹é’®â€ï¼š**æµ‹è¯•æ—¶æ¨ç†é•¿åº¦**ï¼ˆå³â€œæ€è€ƒæ—¶é—´â€ï¼‰ã€‚é€šè¿‡ç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ã€ç»™äºˆæ›´å¤šè®¡ç®—æ­¥æ•°ï¼Œæˆ‘ä»¬èƒ½æ˜¾å¼è°ƒèŠ‚æ¨¡å‹è¡¨ç°â€”â€”è¿™å‚¬ç”Ÿäº†ä¸€æ¡å…¨æ–°çš„ç¼©æ”¾å¾‹ï¼ˆscaling lawï¼‰ã€‚

OpenAI çš„ o1ï¼ˆ2024 å¹´åº•ï¼‰æ˜¯é¦–ä¸ª RLVR æ¨¡å‹çš„é›å½¢ï¼Œ  
è€Œ **o3ï¼ˆ2025 å¹´åˆï¼‰åˆ™æ˜¯çœŸæ­£çš„æ‹ç‚¹**â€”â€”ä½ å‡ ä¹èƒ½**å‡­ç›´è§‰æ„Ÿå—åˆ°**ï¼šè¿™ä¸œè¥¿â€œå˜èªæ˜äº†â€ã€‚

---

### 2. **â€œå¹½çµâ€ vs â€œåŠ¨ç‰©â€ / é”¯é½¿çŠ¶æ™ºèƒ½ï¼ˆJagged Intelligenceï¼‰**

2025 å¹´ï¼Œæˆ‘ï¼ˆä»¥åŠè¡Œä¸šå¤§å¤šæ•°äººï¼‰**å¤´ä¸€å›å¯¹ LLM çš„â€œæ™ºèƒ½å½¢æ€â€æœ‰äº†ç›´è§‰æ€§æŠŠæ¡**ï¼š  
æˆ‘ä»¬ä¸æ˜¯åœ¨â€œåŸ¹è‚²åŠ¨ç‰©â€ï¼Œè€Œæ˜¯åœ¨â€œå¬å”¤å¹½çµâ€ã€‚

â€”â€”æ•´ä¸ª LLM æŠ€æœ¯æ ˆéƒ½æˆªç„¶ä¸åŒï¼šç½‘ç»œæ¶æ„ã€è®­ç»ƒæ•°æ®ã€è®­ç»ƒç®—æ³•ï¼Œå°¤å…¶æ˜¯**ä¼˜åŒ–ç›®æ ‡**ã€‚  
æ‰€ä»¥ï¼Œå®ƒäº§å‡ºçš„â€œæ™ºèƒ½ä½“â€ï¼Œè‡ªç„¶ä¸è¯¥ç”¨åŠ¨ç‰©å¿ƒæ™ºçš„é€é•œå»ç†è§£ã€‚

æ¯”ç‰¹å±‚é¢çœ‹ï¼š  
äººç±»ç¥ç»ç½‘ç»œç»ç™¾ä¸‡å¹´æ¼”åŒ–ï¼Œä¸ºçš„æ˜¯â€œåœ¨ä¸›æ—é‡Œå¸®éƒ¨è½æ´»ä¸‹æ¥â€ï¼›  
è€Œ LLM ç¥ç»ç½‘ç»œï¼Œæ˜¯åœ¨â€œæ¨¡ä»¿äººç±»æ–‡æœ¬â€â€œè§£æ•°å­¦é¢˜æ‹¿å¥–åŠ±â€â€œåœ¨ LMSYS Arena ä¸Šèµ¢ä¸€ä¸ª upvoteâ€ã€‚

å½“å¯éªŒè¯ä»»åŠ¡æˆä¸º RLVR çš„è®­ç»ƒåœºï¼ŒLLM çš„èƒ½åŠ›ä¾¿ä¼šåœ¨è¿™äº›é¢†åŸŸ**å‚ç›´é£™å‡**ï¼Œæœ€ç»ˆå‘ˆç°å‡ºä¸€ç§**è’è¯åˆçœŸå®çš„â€œé”¯é½¿çŠ¶æ™ºèƒ½â€**ï¼š  
å®ƒå‰ä¸€ç§’æ˜¯åšå­¦å¤šæ‰çš„é€šæ‰ï¼Œåä¸€ç§’å°±æˆäº†è¢«ä¸€é“è„‘ç­‹æ€¥è½¬å¼¯ç»•æ™•çš„å°å­¦ç”Ÿï¼›å†è¿‡ä¸€ç§’ï¼Œå¯èƒ½å°±è¢«ä¸€ä¸ª jailbreak prompt å“„éª—ç€æŠŠä½ çš„æ•°æ®å·èµ°ã€‚

![human_vs_ai_intelligence](./images/human_vs_ai_intelligence.png)
äººç±»æ™ºèƒ½ï¼šè“è‰²ï¼›AI æ™ºèƒ½ï¼šçº¢è‰²ã€‚  
æˆ‘å–œæ¬¢è¿™ä¸ª meme ç‰ˆæœ¬ï¼ˆæŠ±æ­‰å¿˜äº†åŸå¸–å‡ºå¤„ï¼‰ï¼Œå®ƒæé†’æˆ‘ä»¬ï¼š**äººç±»æ™ºèƒ½æœ¬èº«ä¹Ÿæ˜¯é”¯é½¿çŠ¶çš„**â€”â€”åªæ˜¯â€œé”¯é½¿â€çš„å½¢çŠ¶ä¸åŒç½¢äº†ã€‚

ä¸ä¹‹å¯†åˆ‡ç›¸å…³çš„ï¼Œæ˜¯æˆ‘ 2025 å¹´å¯¹**åŸºå‡†æµ‹è¯•ï¼ˆbenchmarksï¼‰çš„å½»åº•å¹»ç­ä¸ä¸ä¿¡ä»»**ã€‚  
é—®é¢˜æ ¸å¿ƒåœ¨äºï¼šåŸºå‡†æµ‹è¯•å‡ ä¹**å¤©ç„¶å°±æ˜¯å¯éªŒè¯ç¯å¢ƒ**â€”â€”å› æ­¤ææ˜“è¢« RLVRï¼ˆæˆ–å…¶å¼±åŒ–ç‰ˆï¼šåˆæˆæ•°æ®è®­ç»ƒï¼‰å®šå‘ä¼˜åŒ–ã€‚  

åœ¨å…¸å‹çš„**åˆ·æ¦œå†…å·**ï¼ˆbenchmaxxingï¼‰è¿‡ç¨‹ä¸­ï¼Œå„å›¢é˜Ÿä¼šä¸è‡ªè§‰åœ°åœ¨åµŒå…¥ç©ºé—´ä¸­ï¼Œå›´ç»• benchmark æ‰€åœ¨çš„â€œå°å£è¢‹â€ç–¯ç‹‚ç”Ÿé•¿â€œèƒ½åŠ›å°–åˆºâ€ï¼ˆjaggiesï¼‰ï¼Œåªä¸ºç²¾å‡†è¦†ç›–æµ‹è¯•ç‚¹ã€‚  
â€”â€”â€œç”¨æµ‹è¯•é›†è®­ç»ƒâ€ï¼Œå·²ç„¶æˆä¸ºä¸€é—¨æ–°è‰ºæœ¯ã€‚

é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼š  
**æ€æ ·æ‰èƒ½â€˜åˆ·çˆ†æ‰€æœ‰æ¦œâ€™ï¼Œå´ä¾ç„¶ç¦» AGI åä¸‡å…«åƒé‡Œï¼Ÿ**  

å…³äºæœ¬èŠ‚ï¼Œæˆ‘å¦æœ‰é•¿æ–‡è¯¦è¿°ï¼š  
â–¸ [Animals vs. Ghosts](é“¾æ¥)  
â–¸ [Verifiability](é“¾æ¥)  
â–¸ [The Space of Minds](é“¾æ¥)

---

### 3. **Cursorï¼šLLM åº”ç”¨çš„æ–°å±‚**

é™¤äº†å®ƒä»Šå¹´çš„ç«ç®­å¼è¹¿çº¢ï¼ŒCursor æœ€ä»¤æˆ‘éœ‡æ’¼çš„ï¼Œæ˜¯å®ƒ**æ¸…æ™°æ­ç¤ºäº†ä¸€ç±»å…¨æ–°çš„â€œLLM åº”ç”¨èŒƒå¼â€**â€”â€”äººä»¬å¼€å§‹è¯´ï¼šâ€œæˆ‘ä»¬æƒ³è¦ä¸€ä¸ª *Cursor for X*â€ã€‚

æ­£å¦‚æˆ‘åœ¨ä»Šå¹´ Y Combinator æ¼”è®²ä¸­å¼ºè°ƒçš„ï¼ˆ[æ–‡å­—ç¨¿ & è§†é¢‘](é“¾æ¥)ï¼‰ï¼Œåƒ Cursor è¿™æ ·çš„ LLM åº”ç”¨ï¼Œå¹¶éç®€å•è°ƒç”¨ APIï¼Œè€Œæ˜¯åœ¨**ç‰¹å®šå‚ç›´é¢†åŸŸå†…ç²¾å¿ƒç¼–æ’ LLM è°ƒç”¨**ï¼š  

- å®ƒä»¬è´Ÿè´£**ä¸Šä¸‹æ–‡å·¥ç¨‹**ï¼ˆContext Engineeringï¼‰  
- å®ƒä»¬åœ¨åå°å°†å¤šæ¬¡ LLM è°ƒç”¨ä¸²æˆæ—¥ç›Šå¤æ‚çš„ DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰ï¼Œç²¾ç»†æƒè¡¡æ€§èƒ½ä¸æˆæœ¬  
- å®ƒä»¬ä¸ºäººæœºåä½œè®¾è®¡**é¢†åŸŸä¸“å±çš„ GUI**  
- å®ƒä»¬æä¾›â€œ**è‡ªä¸»æ€§æ»‘å—**â€ï¼ˆautonomy sliderï¼‰â€”â€”ä»â€œå»ºè®®æ¨¡å¼â€åˆ°â€œå…¨è‡ªåŠ¨æ‰§è¡Œâ€çš„è¿ç»­è°ƒèŠ‚  

2025 å¹´ï¼Œä¸šç•Œçƒ­è®®ä¸€ä¸ªå…³é”®é—®é¢˜ï¼š**è¿™ä¸€æ–°åº”ç”¨å±‚åˆ°åº•â€œæœ‰å¤šåšâ€ï¼Ÿ**  
LLM å¤§å‚ä¼šé€šåƒæ‰€æœ‰åº”ç”¨ï¼Ÿè¿˜æ˜¯å­˜åœ¨ä¸€ç‰‡ LLM åº”ç”¨çš„â€œç»¿è‰²è‰åŸâ€ï¼Ÿ

æˆ‘ä¸ªäººå€¾å‘åè€…ï¼š  
> **LLM å®éªŒå®¤å°†åŸ¹å…»å‡ºâ€œé€šè¯†èƒ½åŠ›æ‰å®çš„å¤§å­¦æ¯•ä¸šç”Ÿâ€ï¼Œ  
> è€Œ LLM åº”ç”¨å±‚ï¼Œåˆ™ä¼šæ•´åˆã€å¾®è°ƒã€å¹¶çœŸæ­£â€œæ¿€æ´»â€è¿™ç¾¤æ¯•ä¸šç”Ÿâ€”â€”  
> é€šè¿‡æ³¨å…¥ç§æœ‰æ•°æ®ã€ä¼ æ„Ÿå™¨ã€æ‰§è¡Œå™¨ä¸åé¦ˆå›è·¯ï¼Œ  
> æŠŠä»–ä»¬å˜æˆæŸä¸ªå‚ç›´é¢†åŸŸé‡Œèƒ½è½åœ°å¹²æ´»çš„â€œèŒåœºä¸“å®¶â€ã€‚**

---

### 4. **Claude Codeï¼šä½åœ¨ä½ ç”µè„‘é‡Œçš„ AI**

**Claude Codeï¼ˆCCï¼‰** æ˜¯é¦–ä¸ªä»¤äººä¿¡æœçš„ LLM Agent æ¡ˆä¾‹â€”â€”å®ƒèƒ½ä»¥**é—­ç¯æ–¹å¼**ï¼Œå°†å·¥å…·è°ƒç”¨ä¸æ¨ç†ä¸²è”èµ·æ¥ï¼Œå®Œæˆé•¿æ—¶é—´ã€å¤šæ­¥éª¤çš„é—®é¢˜æ±‚è§£ã€‚

æ›´è®©æˆ‘çœ¼å‰ä¸€äº®çš„æ˜¯ï¼š**CC è¿è¡Œåœ¨ä½ çš„æœ¬åœ°æœºå™¨ä¸Š**ï¼Œä½¿ç”¨ä½ è‡ªå·±çš„ç¯å¢ƒã€ç§æœ‰æ•°æ®ä¸ä¸Šä¸‹æ–‡ã€‚

æˆ‘è®¤ä¸º OpenAI åœ¨è¿™ä¸€ç‚¹ä¸Šåˆ¤æ–­å¤±è¯¯â€”â€”ä»–ä»¬æŠŠ Codex / Agent çš„é‡å¿ƒæ”¾åœ¨â€œäº‘ç«¯å®¹å™¨â€ï¼ˆé€šè¿‡ ChatGPT ç¼–æ’ï¼‰ï¼Œè€Œé `localhost`ã€‚  
è¯šç„¶ï¼Œäº‘ç«¯â€œæ™ºèƒ½ä½“èœ‚ç¾¤â€å¯èƒ½æ˜¯ AGI çš„ç»ˆå±€å½¢æ€ï¼›  
ä½†åœ¨æˆ‘ä»¬æ‰€å¤„çš„â€œèƒ½åŠ›é”¯é½¿çŠ¶ã€æ¸è¿›èµ·é£â€çš„å½“ä¸‹ï¼Œ**è®© Agent ç›´æ¥æ‰æ ¹äºå¼€å‘è€…æœºå™¨ã€ä¸å…¶å·¥ä½œæµæ·±åº¦è€¦åˆï¼Œæ‰æ˜¯æ›´åŠ¡å®çš„é€‰æ‹©**ã€‚

CC æŠŠè¿™ä¸ªä¼˜å…ˆçº§æå¯¹äº†ï¼Œå¹¶åŒ…è£…æˆä¸€ä¸ª**æè‡´ç®€æ´ã€ä¼˜é›…ã€ä»¤äººä¿¡æœçš„ CLI å·¥å…·**â€”â€”å®ƒé‡æ–°å®šä¹‰äº†â€œAI é•¿ä»€ä¹ˆæ ·â€ï¼š  
> å®ƒä¸å†æ˜¯ Google é‚£æ ·çš„ç½‘ç«™å…¥å£ï¼›  
> å®ƒæ˜¯ä½ ç”µè„‘é‡Œä½ç€çš„ä¸€ä¸ªå°ç²¾çµã€ä¸€ä¸ªâ€œå¹½çµâ€ï¼ˆghostï¼‰ã€‚

â€”â€”è¿™æ˜¯ä¸ AI äº¤äº’çš„**å…¨æ–°èŒƒå¼**ã€‚

---

### 5. **æ°›å›´ç¼–ç¨‹ï¼ˆVibe Codingï¼‰**

2025 å¹´ï¼ŒAI ç»ˆäºè·¨è¿‡äº†é‚£ä¸ªä¸´ç•Œç‚¹ï¼š**äººä»¬ä»…å‡­è‡ªç„¶è¯­è¨€æè¿°ï¼Œå°±èƒ½æ„å»ºå‡ºä»¤äººå°è±¡æ·±åˆ»çš„ç¨‹åºï¼Œç”šè‡³å®Œå…¨â€œå¿˜è®°ä»£ç å­˜åœ¨â€**ã€‚

æœ‰è¶£çš„æ˜¯ï¼Œæˆ‘æ›¾åœ¨ä¸€æ¡â€œæµ´å®¤çªå‘å¥‡æƒ³â€æ¨æ–‡ä¸­éšæ‰‹å‘æ˜äº† **â€œvibe codingâ€**ï¼ˆæ°›å›´ç¼–ç¨‹ï¼‰è¿™ä¸ªè¯â€”â€”å½“æ—¶å®Œå…¨æ²¡æ–™åˆ°å®ƒä¼šç«æˆè¿™æ · ğŸ˜„

Vibe coding çš„æœ¬è´¨æ˜¯ï¼š**ç¼–ç¨‹ä¸å†ä¸“å±è®­ç»ƒæœ‰ç´ çš„ä¸“ä¸šäººå£«ï¼Œè€Œæˆä¸ºäººäººå¯ä¸ºä¹‹äº‹**ã€‚  
è¿™æ­£æ˜¯æˆ‘åœ¨ã€Š[Power to the People](é“¾æ¥)ã€‹ä¸­è®ºè¿°çš„æ ¸å¿ƒè§‚ç‚¹ï¼š  
> ä¸äººç±»å†å²ä¸Šæ‰€æœ‰æŠ€æœ¯ä¸åŒï¼Œ**LLM çš„æœ€å¤§å—ç›Šè€…ä¸æ˜¯ä¼ä¸šã€æ”¿åºœæˆ–ä¸“å®¶ï¼Œè€Œæ˜¯æ™®é€šäºº**ã€‚

ä½†å®ƒä¸æ­¢èµ‹èƒ½å¤§ä¼—ï¼š  
å®ƒä¹Ÿè®©ä¸“ä¸šç¨‹åºå‘˜èƒ½å¿«é€Ÿå®ç°**åŸæœ¬æ ¹æœ¬ä¸ä¼šå†™çš„è½¯ä»¶**ã€‚  
æ¯”å¦‚æˆ‘åœ¨ nanochat é¡¹ç›®ä¸­ï¼Œç›´æ¥ vibe coding å‡ºä¸€ä¸ªè‡ªå®šä¹‰çš„ã€é«˜æ•ˆ Rust BPE åˆ†è¯å™¨â€”â€”çœå»äº†å•ƒåº“æˆ–æ·±å­¦ Rust çš„éº»çƒ¦ï¼›  
æˆ‘ç”¨ vibe coding å¿«é€Ÿæ­å‡ºäº† menugenã€llm-councilã€reader3ã€HN Time Capsule ç­‰ä¸€ç³»åˆ—å°å·¥å…·ï¼›  
ç”šè‡³ï¼Œæˆ‘æ›¾ä¸ºå®šä½ä¸€ä¸ª bugï¼Œç°åœº vibe code ä¸€æ•´å¥—ä¸´æ—¶åº”ç”¨â€”â€”**åæ­£ä»£ç ç°åœ¨æ˜¯â€œå…è´¹çš„ã€ä¸€æ¬¡æ€§çš„ã€å¯å¡‘çš„ã€ç”¨å®Œå³å¼ƒçš„â€**ã€‚

Vibe coding å°†é‡å¡‘è½¯ä»¶å·¥ç¨‹ç‰ˆå›¾ï¼Œå¹¶é‡æ–°å®šä¹‰â€œç¨‹åºå‘˜â€çš„èŒä¸šå†…æ¶µã€‚

---

### 6. **Nano Banana / LLM çš„ GUI æ—¶ä»£**

Google çš„ **Gemini Nano Banana** æ˜¯ 2025 å¹´æœ€ä»¤äººéœ‡æ’¼ã€æœ€å…·èŒƒå¼é¢ è¦†æ€§çš„æ¨¡å‹ä¹‹ä¸€ã€‚

åœ¨æˆ‘çš„ä¸–ç•Œè§‚é‡Œï¼Œ**LLM æ˜¯ç»§ 70ã€80 å¹´ä»£è®¡ç®—æœºä¹‹åçš„ä¸‹ä¸€ä»£è®¡ç®—èŒƒå¼**â€”â€”å› æ­¤ï¼Œæˆ‘ä»¬å¿…å°†é‡æ¼”ç±»ä¼¼çš„æŠ€æœ¯æ¼”è¿›ï¼š  
â–¸ ä¸ªäººè®¡ç®—ï¼ˆPersonal Computingï¼‰  
â–¸ å¾®æ§åˆ¶å™¨ï¼ˆå³â€œè®¤çŸ¥æ ¸å¿ƒâ€ï¼ŒCognitive Coreï¼‰  
â–¸ æ™ºèƒ½ä½“äº’è”ç½‘ï¼ˆInternet of Agentsï¼‰â€¦â€¦ç­‰ç­‰ã€‚

å°¤å…¶åœ¨ UI/UX å±‚é¢ï¼š  
å½“å‰ä¸ LLM â€œèŠå¤©â€ï¼Œå°±åƒ 80 å¹´ä»£åœ¨å‘½ä»¤è¡Œæ•²æŒ‡ä»¤â€”â€”  
**æ–‡æœ¬æ˜¯è®¡ç®—æœºï¼ˆåŠ LLMï¼‰çš„â€œæ¯è¯­â€ï¼Œå´ä¸æ˜¯äººç±»çš„æœ€ä¼˜è¾“å…¥/è¾“å‡ºæ ¼å¼**ã€‚  
äººç±»å…¶å®**åŒæ¶é˜…è¯»**â€”â€”å®ƒæ…¢ã€è´¹åŠ›ï¼›  
æˆ‘ä»¬å¤©ç”Ÿåçˆ±**è§†è§‰åŒ–ã€ç©ºé—´åŒ–**çš„ä¿¡æ¯å‘ˆç°â€”â€”è¿™ä¹Ÿæ˜¯ä¼ ç»Ÿè®¡ç®—ä¸­ GUI è¢«å‘æ˜çš„åŸå› ã€‚

åŒç†ï¼ŒLLM æœªæ¥è¯¥ä»¥**æˆ‘ä»¬åå¥½çš„æ–¹å¼è¯´è¯**ï¼šå›¾åƒã€ä¿¡æ¯å›¾ã€å¹»ç¯ç‰‡ã€ç™½æ¿ã€åŠ¨å›¾/è§†é¢‘ã€Web åº”ç”¨â€¦â€¦

å½“å‰çš„åˆçº§å½¢æ€ï¼Œæ˜¯ emoji å’Œ Markdownâ€”â€”å®ƒä»¬ç”¨æ ‡é¢˜ã€åŠ ç²—ã€åˆ—è¡¨ã€è¡¨æ ¼ç­‰â€œè£…é¥°â€æ–‡æœ¬ï¼Œæå‡å¯è¯»æ€§ã€‚  
ä½†çœŸæ­£çš„ LLM GUI è°æ¥å»ºï¼Ÿ  
**Nano Bananaï¼Œå°±æ˜¯è¿™ä¸€æ–¹å‘çš„é¦–ä¸ªå¼ºçƒˆä¿¡å·**ã€‚

å…³é”®åœ¨äºï¼šå®ƒè¿œä¸æ­¢â€œå›¾åƒç”Ÿæˆâ€ã€‚  
å®ƒæ˜¯**æ–‡æœ¬ç”Ÿæˆ + å›¾åƒç”Ÿæˆ + ä¸–ç•ŒçŸ¥è¯†**ä¸‰è€…æ·±åº¦äº¤ç»‡çš„è”åˆèƒ½åŠ›â€”â€”æ‰€æœ‰è¿™äº›éƒ½â€œç¼ ç»•â€åœ¨æ¨¡å‹æƒé‡ä¹‹ä¸­ã€‚

---

### â–¸ TL;DR  
2025 å¹´ï¼Œæ˜¯ LLM ä»¤äººæ¿€åŠ¨åˆç•¥å¸¦æ„å¤–çš„ä¸€å¹´ã€‚  
å®ƒä»¬æ­£æ¶Œç°å‡ºä¸€ç§**æ–°å‹æ™ºèƒ½**â€”â€”æ¯”æˆ‘é¢„æƒ³çš„**æ›´èªæ˜ï¼Œä¹Ÿæ›´æ„šè ¢**ã€‚  
æ— è®ºå¦‚ä½•ï¼Œå®ƒä»¬å·²æå…·å®ç”¨ä»·å€¼ï¼›è€Œä¾æˆ‘çœ‹ï¼Œå³ä¾¿ä»¥å½“ä¸‹èƒ½åŠ›ï¼Œè¡Œä¸šä¹Ÿè¿œæœªæŒ–æ˜å…¶ 10% çš„æ½œåŠ›ã€‚

ä¸æ­¤åŒæ—¶ï¼Œ**å¯æ¢ç´¢çš„åˆ›æ„ä»å¦‚ç¹æ˜Ÿèˆ¬å¯†é›†ï¼Œæ•´ä¸ªé¢†åŸŸåœ¨æ¦‚å¿µå±‚é¢ä¾ç„¶æ— æ¯”å¼€æ”¾**ã€‚  
æ­£å¦‚æˆ‘ä»Šå¹´æ—©äº›æ—¶å€™åœ¨ Dwarkesh æ’­å®¢ä¸­æ‰€è¯´ï¼š  
> è¡¨é¢ä¸ŠçŸ›ç›¾ï¼Œå®åˆ™å¹¶è¡Œä¸æ‚–â€”â€”  
> **æˆ‘æ—¢ç›¸ä¿¡è¿›å±•å°†æŒç»­å¿«é€Ÿï¼Œä¹Ÿæ·±çŸ¥å‰è·¯ä»æœ‰æµ·é‡å·¥ä½œå¾…å®Œæˆ**ã€‚

ç³»å¥½å®‰å…¨å¸¦ï¼Œæ—…ç¨‹æ‰åˆšåˆšå¼€å§‹ã€‚

ğŸ”— é™„ï¼šæ­¤æ–‡æˆ‘ä¹ŸåŒæ­¥å‘åˆ°äº†[ä¸ªäººåšå®¢](URL)ï¼Œæ’ç‰ˆæ›´æ¸…çˆ½ï¼Œé˜…è¯»ä½“éªŒæ›´ä½³ã€‚

--- 

ç¿»è¯‘è¯´æ˜ï¼š  
- ä¿ç•™ Karpathy æ ‡å¿—æ€§çš„â€œå†·é™ä¸­å¸¦æ¸©åº¦ã€ä¸¥è°¨ä¸­è§å¹½é»˜â€çš„è¯­æ„Ÿï¼›  
- â€œghosts vs. animalsâ€è¯‘ä¸ºâ€œå¹½çµ vs åŠ¨ç‰©â€ï¼Œæ—¢ä¿ç•™éšå–»å¼ åŠ›ï¼Œåˆå¥‘åˆä¸­æ–‡ç§‘å¹»è¯­å¢ƒï¼›  
- â€œjagged intelligenceâ€è¯‘ä¸ºâ€œé”¯é½¿çŠ¶æ™ºèƒ½â€ï¼Œå‡†ç¡®ä¼ è¾¾â€œèƒ½åŠ›ä¸å‡è¡¡â€çš„æ ¸å¿ƒæ„è±¡ï¼›  
- â€œbenchmaxxingâ€åˆ›é€ æ€§è¯‘ä¸ºâ€œåˆ·æ¦œå†…å·â€ï¼Œç¬¦åˆä¸­æ–‡æŠ€æœ¯åœˆè¯­å¢ƒï¼›  
- â€œvibe codingâ€éŸ³æ„å…¼é¡¾è¯‘ä¸ºâ€œæ°›å›´ç¼–ç¨‹â€ï¼Œå·²æˆç¤¾åŒºå…±è¯†è¯‘æ³•ï¼›  
- æŠ€æœ¯æœ¯è¯­ï¼ˆå¦‚ RLVR, DAG, CLI, BPEï¼‰ä¿ç•™è‹±æ–‡ç¼©å†™+ä¸­æ–‡æ³¨é‡Šï¼Œç¡®ä¿ä¸“ä¸šæ€§ä¸å¯è¯»æ€§å¹³è¡¡ã€‚

å¸Œæœ›è¿™ä»½ç¿»è¯‘ï¼Œèƒ½è®©ä¸­æ–‡è¯»è€…æ„Ÿå—åˆ° Karpathy åŸæ–‡é‚£ç§â€”â€”**ç«™åœ¨æ™ºèƒ½é©å‘½å‰æ²¿çš„æ¸…é†’ã€å…´å¥‹ä¸å“²æ€äº¤ç»‡çš„ç‹¬ç‰¹æ°”æ¯**ã€‚


## x.comä¸Šçš„åŸæ–‡

2025 has been a strong and eventful year of progress in LLMs. The following is a list of personally notable and mildly surprising "paradigm changes" - things that altered the landscape and stood out to me conceptually.

1. Reinforcement Learning from Verifiable Rewards (RLVR)
At the start of 2025, the LLM production stack in all labs looked something like this:
Pretraining (GPT-2/3 of ~2020)
Supervised Finetuning (InstructGPT ~2022) and
Reinforcement Learning from Human Feedback (RLHF ~2022)
This was the stable and proven recipe for training a production-grade LLM for a while. In 2025, Reinforcement Learning from Verifiable Rewards (RLVR) emerged as the de facto new major stage to add to this mix. By training LLMs against automatically verifiable rewards across a number of environments (e.g. think math/code puzzles), the LLMs spontaneously develop strategies that look like "reasoning" to humans - they learn to break down problem solving into intermediate calculations and they learn a number of problem solving strategies for going back and forth to figure things out (see DeepSeek R1 paper for examples). These strategies would have been very difficult to achieve in the previous paradigms because it's not clear what the optimal reasoning traces and recoveries look like for the LLM - it has to find what works for it, via the optimization against rewards. 
Unlike the SFT and RLHF stage, which are both relatively thin/short stages (minor finetunes computationally), RLVR involves training against objective (non-gameable) reward functions which allows for a lot longer optimization. Running RLVR turned out to offer high capability/$, which gobbled up the compute that was originally intended for pretraining. Therefore, most of the capability progress of 2025 was defined by the LLM labs chewing through the overhang of this new stage and overall we saw ~similar sized LLMs but a lot longer RL runs. Also unique to this new stage, we got a whole new knob (and and associated scaling law) to control capability as a function of test time compute by generating longer reasoning traces and increasing "thinking time". OpenAI o1 (late 2024) was the very first demonstration of an RLVR model, but the o3 release (early 2025) was the obvious point of inflection where you could intuitively feel the difference.
2. Ghosts vs. Animals / Jagged Intelligence
2025 is where I (and I think the rest of the industry also) first started to internalize the "shape" of LLM intelligence in a more intuitive sense. We're not "evolving/growing animals", we are "summoning ghosts". Everything about the LLM stack is different (neural architecture, training data, training algorithms, and especially optimization pressure) so it should be no surprise that we are getting very different entities in the intelligence space, which are inappropriate to think about through an animal lens. Supervision bits-wise, human neural nets are optimized for survival of a tribe in the jungle but LLM neural nets are optimized for imitating humanity's text, collecting rewards in math puzzles, and getting that upvote from a human on the LM Arena. As verifiable domains allow for RLVR, LLMs "spike" in capability in the vicinity of these domains and overall display amusingly jagged performance characteristics - they are at the same time a genius polymath and a confused and cognitively challenged grade schooler, seconds away from getting tricked by a jailbreak to exfiltrate your data.

ã€Šimageã€‹
human intelligence: blue, AI intelligence: red. I like this version of the meme (I'm sorry I lost the reference to its original post on X) for pointing out that human intelligence is also jagged in its own different way.


Related to all this is my general apathy and loss of trust in benchmarks in 2025. The core issue is that benchmarks are almost by construction verifiable environments and are therefore immediately susceptible to RLVR and weaker forms of it via synthetic data generation. In the typical benchmaxxing process, teams in LLM labs inevitably construct environments adjacent to little pockets of the embedding space occupied by benchmarks and grow jaggies to cover them. Training on the test set is a new art form.
What does it look like to crush all the benchmarks but still not get AGI?
I have written a lot more on the topic of this section here:
Animals vs. Ghosts
Verifiability
The Space of Minds
3. Cursor / new layer of LLM apps
What I find most notable about Cursor (other than its meteoric rise this year) is that it convincingly revealed a new layer of an "LLM app" - people started to talk about "Cursor for X". As I highlighted in my Y Combinator talk this year (transcript and video), LLM apps like Cursor bundle and orchestrate LLM calls for specific verticals:
They do the "context engineering"
They orchestrate multiple LLM calls under the hood strung into increasingly more complex DAGs, carefully balancing performance and cost tradeoffs.
They provide an application-specific GUI for the human in the loop
They offer an "autonomy slider"
A lot of chatter has been spent in 2025 on how "thick" this new app layer is. Will the LLM labs capture all applications or are there green pastures for LLM apps? Personally I suspect that LLM labs will trend to graduate the generally capable college student, but LLM apps will organize, finetune and actually animate teams of them into deployed professionals in specific verticals by supplying private data, sensors and actuators and feedback loops.
4. Claude Code / AI that lives on your computer
Claude Code (CC) emerged as the first convincing demonstration of what an LLM Agent looks like - something that in a loopy way strings together tool use and reasoning for extended problem solving. In addition, CC is notable to me in that it runs on your computer and with your private environment, data and context. I think OpenAI got this wrong because I think they focused their codex / agent efforts on cloud deployments in containers orchestrated from ChatGPT instead of `localhost`. And while agent swarms running in the cloud feels like the "AGI endgame", we live in an intermediate and slow enough takeoff world of jagged capabilities that it makes more sense to simply run the agents on the computer, hand in hand with developers and their specific setup. CC got this order of precedence correct and packaged it into a beautiful, minimal, compelling CLI form factor that changed what AI looks like - it's not just a website you go to like Google, it's a little spirit/ghost that "lives" on your computer. This is a new, distinct paradigm of interaction with an AI.
5. Vibe coding
2025 is the year that AI crossed a capability threshold necessary to build all kinds of impressive programs simply via English, forgetting that the code even exists. Amusingly, I coined the term "vibe coding" in this shower of thoughts tweet totally oblivious to how far it would go :). With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do. In this capacity, it is yet another example of what I wrote about in Power to the people: How LLMs flip the script on technology diffusion, on how (in sharp contrast to all other technology so far) regular people benefit a lot more from LLMs compared to professionals, corporations and governments. But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written. In nanochat, I vibe coded my own custom highly efficient BPE tokenizer in Rust instead of having to adopt existing libraries or learn Rust at that level. I vibe coded many projects this year as quick app demos of something I wanted to exist (e.g. see menugen, llm-council, reader3, HN time capsule). And I've vibe coded entire ephemeral apps just to find a single bug because why not - code is suddenly free, ephemeral, malleable, discardable after single use. Vibe coding will terraform software and alter job descriptions.
6. Nano banana / LLM GUI
Google Gemini Nano banana is one of the most incredible, paradigm-shifting models of 2025. In my world view, LLMs are the next major computing paradigm similar to computers of the 1970s, 80s, etc. Therefore, we are going to see similar kinds of innovations for fundamentally similar kinds of reasons. We're going to see equivalents of personal computing, of microcontrollers (cognitive core), or internet (of agents), etc etc. In particular, in terms of the UIUX, "chatting" with LLMs is a bit like issuing commands to a computer console in the 1980s. Text is the raw/favored data representation for computers (and LLMs), but it is not the favored format for people, especially at the input. People actually dislike reading text - it is slow and effortful. Instead, people love to consume information visually and spatially and this is why the GUI has been invented in traditional computing. In the same way, LLMs should speak to us in our favored format - in images, infographics, slides, whiteboards, animations/videos, web apps, etc. The early and present version of this of course are things like emoji and Markdown, which are ways to "dress up" and lay out text visually for easier consumption with titles, bold, italics, lists, tables, etc. But who is actually going to build the LLM GUI? In this world view, nano banana is a first early hint of what that might look like. And importantly, one notable aspect of it is that it's not just about the image generation itself, it's about the joint capability coming from text generation, image generation and world knowledge, all tangled up in the model weights.
---
TLDR. 2025 was an exciting and mildly surprising year of LLMs. LLMs are emerging as a new kind of intelligence, simultaneously a lot smarter than I expected and a lot dumber than I expected. In any case they are extremely useful and I don't think the industry has realized anywhere near 10% of their potential even at present capability. Meanwhile, there are so many ideas to try and conceptually the field feels wide open. And as I mentioned on my Dwarkesh pod earlier this year, I simultaneously (and on the surface paradoxically) believe that we will both see rapid and continued progress *and* that yet there is a lot of work to be done. Strap in.
URL: I cross-posted this article to my blog, which I think looks and feels a bit better and less clunky.


## å‚è€ƒæ–‡çŒ®

* [Karpathy Blog](https://karpathy.bearblog.dev/year-in-review-2025/)