#!/usr/bin/env python3
"""
æ¯æ—¥AIåŠ¨æ€æ”¶é›†è„šæœ¬
è‡ªåŠ¨æ”¶é›†AIé¢†åŸŸçš„æœ€æ–°åŠ¨æ€ï¼ŒåŒ…æ‹¬æ–°æ¨¡å‹ã€æ–°æ¡†æ¶ã€æ–°åº”ç”¨ç­‰
"""

import os
import json
import requests
import datetime
from typing import List, Dict, Any
import openai
from pathlib import Path
import yaml

class DailyAICollector:
    def __init__(self):
        #self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.openai_client = openai.OpenAI(
            api_key=os.getenv('GEMINI_API_KEY'),
            base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
        )

        self.github_token = os.getenv('GITHUB_TOKEN')
        self.hf_token = os.getenv('HUGGINGFACE_API_KEY')
        self.content_dir = Path("content/zh/daily_ai")
        self.content_dir.mkdir(exist_ok=True)
        
    def get_date_range(self) -> tuple:
        """è·å–æ—¶é—´èŒƒå›´ï¼ˆæ˜¨å¤©8ç‚¹åˆ°ä»Šå¤©8ç‚¹ï¼‰"""
        now = datetime.datetime.now()
        today_8am = now.replace(hour=8, minute=0, second=0, microsecond=0)
        yesterday_8am = today_8am - datetime.timedelta(days=1)
        return yesterday_8am, today_8am
    
    def search_github_trending(self) -> List[Dict]:
        """æœç´¢GitHubçƒ­é—¨AIé¡¹ç›®"""
        if not self.github_token:
            return []
            
        headers = {'Authorization': f'token {self.github_token}'}
        url = 'https://api.github.com/search/repositories'
        
        # æœç´¢è¿‡å»24å°æ—¶åˆ›å»ºçš„AIç›¸å…³é¡¹ç›®
        yesterday, today = self.get_date_range()
        date_str = yesterday.strftime('%Y-%m-%d')
        
        params = {
            'q': f'AI machine-learning deep-learning created:>{date_str}',
            'sort': 'stars',
            'order': 'desc',
            'per_page': 10
        }
        
        try:
            response = requests.get(url, headers=headers, params=params)
            if response.status_code == 200:
                data = response.json()
                return data.get('items', [])
        except Exception as e:
            print(f"GitHubæœç´¢é”™è¯¯: {e}")
            
        return []
    
    def search_huggingface_models(self) -> List[Dict]:
        """æœç´¢Hugging Faceæ–°æ¨¡å‹"""
        if not self.hf_token:
            return []
            
        headers = {'Authorization': f'Bearer {self.hf_token}'}
        url = 'https://huggingface.co/api/models'
        
        yesterday, today = self.get_date_range()
        date_str = yesterday.strftime('%Y-%m-%d')
        
        params = {
            'filter': 'pytorch',
            'sort': 'downloads',
            'direction': -1,
            'limit': 10
        }
        
        try:
            response = requests.get(url, headers=headers, params=params)
            if response.status_code == 200:
                models = response.json()
                # è¿‡æ»¤æœ€è¿‘åˆ›å»ºçš„æ¨¡å‹
                recent_models = [
                    model for model in models 
                    if model.get('created_at', '').startswith(date_str)
                ]
                return recent_models[:5]
        except Exception as e:
            print(f"Hugging Faceæœç´¢é”™è¯¯: {e}")
            
        return []
    
    def search_arxiv_papers(self) -> List[Dict]:
        """æœç´¢ArXivæœ€æ–°AIè®ºæ–‡"""
        url = 'http://export.arxiv.org/api/query'
        
        yesterday, today = self.get_date_range()
        date_str = yesterday.strftime('%Y%m%d')
        
        params = {
            'search_query': f'cat:cs.AI OR cat:cs.LG OR cat:cs.CL AND submittedDate:[{date_str}0000 TO {date_str}2359]',
            'start': 0,
            'max_results': 10,
            'sortBy': 'submittedDate',
            'sortOrder': 'descending'
        }
        
        try:
            response = requests.get(url, params=params)
            if response.status_code == 200:
                # è§£æXMLå“åº”
                import xml.etree.ElementTree as ET
                root = ET.fromstring(response.content)
                
                papers = []
                for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):
                    paper = {
                        'title': entry.find('{http://www.w3.org/2005/Atom}title').text,
                        'authors': [author.find('{http://www.w3.org/2005/Atom}name').text 
                                  for author in entry.findall('{http://www.w3.org/2005/Atom}author')],
                        'summary': entry.find('{http://www.w3.org/2005/Atom}summary').text,
                        'link': entry.find('{http://www.w3.org/2005/Atom}id').text
                    }
                    papers.append(paper)
                return papers[:5]
        except Exception as e:
            print(f"ArXivæœç´¢é”™è¯¯: {e}")
            
        return []
    
    def generate_ai_summary(self, collected_data: Dict) -> str:
        """ä½¿ç”¨AIç”Ÿæˆæ¯æ—¥åŠ¨æ€æ‘˜è¦"""
        prompt = f"""
        åŸºäºä»¥ä¸‹æ”¶é›†çš„AIæŠ€æœ¯åŠ¨æ€æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ¯æ—¥AIåŠ¨æ€æŠ¥å‘Šï¼š

        æ•°æ®ï¼š
        {json.dumps(collected_data, ensure_ascii=False, indent=2)}

        è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆå†…å®¹ï¼š
        1. ğŸ¤– æ–°æ¨¡å‹å‘å¸ƒ
        2. ğŸ› ï¸ æ–°æ¡†æ¶å·¥å…·  
        3. ğŸ“± æ–°åº”ç”¨äº§å“
        4. ğŸ“‹ æ–°æ ‡å‡†è§„èŒƒ
        5. ğŸ”¬ æ–°å¼€æºé¡¹ç›®
        6. ğŸ“„ æ–°è®ºæ–‡å‘å¸ƒ
        7. ğŸ¤ ç§‘æŠ€è®¿è°ˆ
        8. ğŸ“Š æŠ€æœ¯æŠ¥å‘Š
        9. ğŸ›ï¸ è®ºå›ä¼šè®®
        10. ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿

        æ¯ä¸ªåˆ†ç±»ä¸‹åŒ…å«2-3ä¸ªé‡è¦åŠ¨æ€ï¼Œæ¯ä¸ªåŠ¨æ€åŒ…å«æ ‡é¢˜ã€ç®€è¦æè¿°å’Œé“¾æ¥ã€‚
        ä½¿ç”¨ä¸­æ–‡ï¼Œå†…å®¹è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰ä»·å€¼ã€‚
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gemini-2.5-flash",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"AIç”Ÿæˆæ‘˜è¦é”™è¯¯: {e}")
            return self.generate_fallback_summary(collected_data)
    
    def generate_fallback_summary(self, collected_data: Dict) -> str:
        """ç”Ÿæˆå¤‡ç”¨æ‘˜è¦"""
        summary = "# æ¯æ—¥AIåŠ¨æ€\n\n"
        
        if collected_data.get('github_projects'):
            summary += "## ğŸ”¬ æ–°å¼€æºé¡¹ç›®\n"
            for project in collected_data['github_projects'][:3]:
                summary += f"- **{project['name']}**: {project.get('description', 'æ— æè¿°')}\n"
            summary += "\n"
        
        if collected_data.get('hf_models'):
            summary += "## ğŸ¤– æ–°æ¨¡å‹å‘å¸ƒ\n"
            for model in collected_data['hf_models'][:3]:
                summary += f"- **{model['modelId']}**: {model.get('pipeline_tag', 'æœªçŸ¥ç±»å‹')}\n"
            summary += "\n"
        
        if collected_data.get('arxiv_papers'):
            summary += "## ğŸ“„ æ–°è®ºæ–‡å‘å¸ƒ\n"
            for paper in collected_data['arxiv_papers'][:3]:
                summary += f"- **{paper['title']}**: {paper['summary'][:100]}...\n"
            summary += "\n"
        
        return summary
    
    def create_daily_content(self) -> str:
        """åˆ›å»ºæ¯æ—¥å†…å®¹æ–‡ä»¶"""
        yesterday, today = self.get_date_range()
        date_str = today.strftime('%Y-%m-%d')
        time_range = f"{yesterday.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} - {today.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}"
        
        # æ”¶é›†æ•°æ®
        collected_data = {
            'github_projects': self.search_github_trending(),
            'hf_models': self.search_huggingface_models(),
            'arxiv_papers': self.search_arxiv_papers()
        }
        
        # ç”ŸæˆAIæ‘˜è¦
        ai_summary = self.generate_ai_summary(collected_data)
        
        # åˆ›å»ºMarkdownå†…å®¹
        content = f"""---
title: "æ¯æ—¥AIåŠ¨æ€ - {date_str}"
date: {today.isoformat()}+08:00
draft: false
categories: ["daily_ai"]
tags: ["AIåŠ¨æ€", "æŠ€æœ¯æ›´æ–°", "è¡Œä¸šè¶‹åŠ¿"]
description: "{date_str}çš„AIæŠ€æœ¯åŠ¨æ€æ±‡æ€»"
---

# æ¯æ—¥AIåŠ¨æ€ - {date_str}

> ğŸ“… **æ—¶é—´èŒƒå›´**: {time_range} (åŒ—äº¬æ—¶é—´)

{ai_summary}

---

> ğŸ’¡ **æç¤º**: æœ¬å†…å®¹ç”±GitHub Actionè‡ªåŠ¨ç”Ÿæˆï¼Œæ¯æ—¥æ›´æ–°ã€‚å¦‚æœ‰é—æ¼æˆ–é”™è¯¯ï¼Œæ¬¢è¿é€šè¿‡Issuesåé¦ˆã€‚
"""
        
        return content
    
    def save_daily_content(self):
        """ä¿å­˜æ¯æ—¥å†…å®¹"""
        content = self.create_daily_content()
        date_str = datetime.datetime.now().strftime('%Y-%m-%d')
        file_path = self.content_dir / f"{date_str}.md"
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… æ¯æ—¥AIåŠ¨æ€å·²ä¿å­˜åˆ°: {file_path}")
        return file_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ”¶é›†æ¯æ—¥AIåŠ¨æ€...")
    
    collector = DailyAICollector()
    file_path = collector.save_daily_content()
    
    print(f"âœ… æ¯æ—¥AIåŠ¨æ€æ”¶é›†å®Œæˆ: {file_path}")

if __name__ == "__main__":
    main()
