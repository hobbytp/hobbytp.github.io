#!/usr/bin/env python3
"""
AI Cover Image Generator for Hugo Blog
æ ¹æ®æ–‡ç« descriptionè‡ªåŠ¨ç”Ÿæˆå°é¢å›¾ç‰‡
æ”¯æŒModelScope Qwen-imageå’ŒOpenAI DALL-E
"""

import os
import hashlib
import requests
import json
import argparse
from pathlib import Path
from typing import Optional, Dict
from dataclasses import dataclass
import logging
import time
from PIL import Image
from io import BytesIO

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰python-dotenvï¼Œæ‰‹åŠ¨è¯»å–.envæ–‡ä»¶
    env_file = Path('.env')
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value.strip('"').strip("'")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ImageGenConfig:
    """å›¾ç‰‡ç”Ÿæˆé…ç½®"""
    # APIé…ç½®
    api_provider: str = "modelscope"  # modelscope, openai
    api_key: str = ""
    model: str = "Qwen/Qwen-Image"  # Qwen/Qwen-Image, dall-e-3

    # ModelScopeé…ç½®
    modelscope_base_url: str = "https://api-inference.modelscope.cn/"
    modelscope_timeout: int = 300  # 5åˆ†é’Ÿè¶…æ—¶
    modelscope_retry_interval: int = 5  # 5ç§’é‡è¯•é—´éš”

    # OpenAIé…ç½®
    openai_base_url: str = "https://api.openai.com/v1/images/generations"

    # å›¾ç‰‡é…ç½® - æ¨ªå±å°ºå¯¸é€‚é…åšå®¢å¡ç‰‡å¤´éƒ¨
    width: int = 1200  # æ¨ªå±å®½åº¦
    height: int = 630   # æ¨ªå±é«˜åº¦ (16:9æ¯”ä¾‹)
    quality: str = "standard"  # standard, hd
    style: str = "vivid"  # vivid, natural

    # å­˜å‚¨é…ç½®
    output_dir: str = "static/images/generated-covers"
    cache_dir: str = "cache/image-generation"

    # ç”Ÿæˆé…ç½®
    max_description_length: int = 1000
    style_suffix: str = ", abstract geometric pattern, professional blog cover, clean design, minimal, technology theme, no text, no letters, no words, no people, no faces, no portraits, landscape orientation, widescreen format"

class CoverImageGenerator:
    """å°é¢å›¾ç‰‡ç”Ÿæˆå™¨"""

    def __init__(self, config: ImageGenConfig):
        self.config = config
        self._ensure_directories()
        self._load_cache()

    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        Path(self.config.output_dir).mkdir(parents=True, exist_ok=True)
        Path(self.config.cache_dir).mkdir(parents=True, exist_ok=True)

    def _load_cache(self):
        """åŠ è½½ç”Ÿæˆç¼“å­˜"""
        self.cache_file = Path(self.config.cache_dir) / "generation_cache.json"
        if self.cache_file.exists():
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                self.cache = json.load(f)
        else:
            self.cache = {}

    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜"""
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(self.cache, f, ensure_ascii=False, indent=2)

    def _get_content_hash(self, title: str, description: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œä½œä¸ºç¼“å­˜é”®"""
        content = f"{title}|{description}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()

    def _optimize_description(self, description: str, title: str, category: str = "") -> str:
        """ä¼˜åŒ–æè¿°ä¸ºé€‚åˆå›¾ç‰‡ç”Ÿæˆçš„prompt"""
        # æˆªæ–­æè¿°å¹¶æå–å…³é”®æ¦‚å¿µ
        if len(description) > self.config.max_description_length:
            description = description[:self.config.max_description_length] + "..."

        # æå–æ–‡ç« ä¸»é¢˜çš„å…³é”®è¯ï¼Œé¿å…ç›´æ¥åŒ…å«æ ‡é¢˜æ–‡å­—
        keywords = self._extract_keywords(description, title)

        # æ„å»ºprompt - ä¸“æ³¨äºæŠ½è±¡æ¦‚å¿µï¼Œä¸åŒ…å«å…·ä½“æ–‡å­—
        prompt_parts = [
            f"Abstract geometric blog cover representing concepts from: {keywords}",
            f"Technology and innovation theme inspired by {category}" if category else "Technology and innovation theme",
            "Clean professional design suitable for blog header",
            "Minimalist modern aesthetic",
            "Digital art style with smooth gradients",
            "Subtle tech-inspired patterns",
            self.config.style_suffix
        ]

        prompt = " ".join(filter(None, prompt_parts))
        return prompt.strip()

    def _extract_keywords(self, description: str, title: str) -> str:
        """ä»æè¿°å’Œæ ‡é¢˜ä¸­æå–å…³é”®è¯ï¼Œç§»é™¤å¸¸è§çš„åœç”¨è¯"""
        import re

        # åˆå¹¶æ ‡é¢˜å’Œæè¿°
        text = f"{title} {description}".lower()

        # å¸¸è§çš„åœç”¨è¯å’Œä¸éœ€è¦è§†è§‰åŒ–çš„è¯
        stop_words = {
            'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'å¦‚æœ', 'å› ä¸º', 'æ‰€ä»¥', 'è¿™', 'é‚£', 'è¿™äº›', 'é‚£äº›',
            'the', 'a', 'an', 'and', 'or', 'but', 'if', 'because', 'so', 'this', 'that', 'these', 'those',
            'blog', 'article', 'post', 'news', 'report', 'analysis', 'review', 'guide', 'tutorial'
        }

        # æå–æŠ€æœ¯ç›¸å…³å…³é”®è¯
        tech_keywords = re.findall(r'\b(ai|artificial intelligence|machine learning|deep learning|neural network|algorithm|data|code|software|app|api|cloud|digital|technology|computer|programming|development|framework|model|system|platform|service|tool|automation|robot|chatbot|language model|llm|gpt|claude|openai|google|microsoft|apple|meta|tesla|bitcoin|blockchain|web3|metaverse|vr|ar|iot|edge|security|privacy|encryption|hack|cyber|quantum|5g|mobile|android|ios)\b', text)

        # å»é‡å¹¶ç§»é™¤åœç”¨è¯
        unique_keywords = []
        for word in tech_keywords:
            if word not in stop_words and word not in unique_keywords:
                unique_keywords.append(word)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŠ€æœ¯å…³é”®è¯ï¼Œä½¿ç”¨é€šç”¨çš„ç§‘æŠ€è¯æ±‡
        if not unique_keywords:
            unique_keywords = ['technology', 'digital', 'innovation', 'data', 'software']

        # é™åˆ¶å…³é”®è¯æ•°é‡
        return ' '.join(unique_keywords[:5])

    def _generate_with_modelscope(self, prompt: str) -> Optional[str]:
        """ä½¿ç”¨ModelScope Qwen-Imageç”Ÿæˆå›¾ç‰‡"""
        try:
            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json",
            }

            # æäº¤å¼‚æ­¥ä»»åŠ¡
            response = requests.post(
                f"{self.config.modelscope_base_url}v1/images/generations",
                headers={**headers, "X-ModelScope-Async-Mode": "true"},
                data=json.dumps({
                    "model": self.config.model,
                    "prompt": prompt,
                    "width": self.config.width,
                    "height": self.config.height
                }, ensure_ascii=False).encode('utf-8'),
                timeout=60
            )

            response.raise_for_status()
            task_id = response.json()["task_id"]
            logger.info(f"ModelScope task submitted: {task_id}")

            # è½®è¯¢ä»»åŠ¡çŠ¶æ€
            start_time = time.time()
            while True:
                if time.time() - start_time > self.config.modelscope_timeout:
                    logger.error(f"ModelScope task timeout after {self.config.modelscope_timeout} seconds")
                    return None

                result = requests.get(
                    f"{self.config.modelscope_base_url}v1/tasks/{task_id}",
                    headers={**headers, "X-ModelScope-Task-Type": "image_generation"},
                    timeout=30
                )
                result.raise_for_status()
                data = result.json()

                if data["task_status"] == "SUCCEED":
                    image_url = data["output_images"][0]
                    logger.info(f"ModelScope image generated successfully: {image_url}")
                    return image_url
                elif data["task_status"] == "FAILED":
                    error_msg = data.get("message", "Unknown error")
                    logger.error(f"ModelScope image generation failed: {error_msg}")
                    return None
                elif data["task_status"] == "RUNNING":
                    logger.info(f"ModelScope task running, elapsed: {int(time.time() - start_time)}s")
                    time.sleep(self.config.modelscope_retry_interval)
                else:
                    logger.warning(f"Unknown ModelScope task status: {data['task_status']}")
                    time.sleep(self.config.modelscope_retry_interval)

        except Exception as e:
            logger.error(f"ModelScope generation error: {e}")
            return None

    def _generate_with_openai(self, prompt: str) -> Optional[str]:
        """ä½¿ç”¨OpenAI DALL-Eç”Ÿæˆå›¾ç‰‡"""
        try:
            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json"
            }

            data = {
                "model": self.config.model,
                "prompt": prompt,
                "n": 1,
                "size": f"{self.config.width}x{self.config.height}",
                "quality": self.config.quality,
                "style": self.config.style
            }

            response = requests.post(
                self.config.openai_base_url,
                headers=headers,
                json=data,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                image_url = result["data"][0]["url"]
                return image_url
            else:
                logger.error(f"OpenAI API error: {response.status_code} - {response.text}")
                return None

        except Exception as e:
            logger.error(f"OpenAI generation error: {e}")
            return None

    def _download_image(self, url: str, filepath: str) -> bool:
        """ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡å¹¶è½¬æ¢ä¸ºwebpæ ¼å¼"""
        try:
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                # ä½¿ç”¨PILæ‰“å¼€å›¾ç‰‡ï¼ˆæ”¯æŒå„ç§æ ¼å¼ï¼‰
                image = Image.open(BytesIO(response.content))
                
                # å¦‚æœå›¾ç‰‡æœ‰é€æ˜é€šé“ï¼ˆRGBAï¼‰ï¼Œè½¬æ¢ä¸ºRGBä»¥æ”¯æŒwebp
                if image.mode in ('RGBA', 'LA', 'P'):
                    # åˆ›å»ºç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', image.size, (255, 255, 255))
                    if image.mode == 'P':
                        image = image.convert('RGBA')
                    background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                    image = background
                elif image.mode != 'RGB':
                    image = image.convert('RGB')
                
                # ä¿å­˜ä¸ºwebpæ ¼å¼ï¼Œä¼˜åŒ–è´¨é‡
                image.save(filepath, 'WEBP', quality=85, method=6)
                logger.info(f"Image converted to webp: {filepath}")
                return True
            else:
                logger.error(f"Image download error: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"Image download/convert error: {e}")
            return False

    def generate_cover(self, title: str, description: str, category: str = "", force: bool = False) -> Optional[str]:
        """
        ç”Ÿæˆå°é¢å›¾ç‰‡

        Args:
            title: æ–‡ç« æ ‡é¢˜
            description: æ–‡ç« æè¿°
            category: æ–‡ç« åˆ†ç±»
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆ

        Returns:
            å›¾ç‰‡URLè·¯å¾„ï¼ˆç›¸å¯¹äºstaticç›®å½•ï¼‰
        """
        # ç”Ÿæˆå†…å®¹å“ˆå¸Œ
        content_hash = self._get_content_hash(title, description)

        # æ£€æŸ¥ç¼“å­˜
        if not force and content_hash in self.cache:
            cached_path = self.cache[content_hash]["image_path"]
            if Path(cached_path).exists():
                logger.info(f"Using cached image: {cached_path}")
                return cached_path.replace("static/", "/", 1)

        # ç”Ÿæˆprompt
        prompt = self._optimize_description(description, title, category)
        logger.info(f"Generating image with prompt: {prompt[:1000]}...")

        # è°ƒç”¨AIç”Ÿæˆå›¾ç‰‡
        image_url = None
        if self.config.api_provider == "modelscope":
            image_url = self._generate_with_modelscope(prompt)
        elif self.config.api_provider == "openai":
            image_url = self._generate_with_openai(prompt)
        else:
            logger.error(f"Unsupported API provider: {self.config.api_provider}")
            return None

        if not image_url:
            logger.error("Failed to generate image")
            return None

    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"{content_hash}.webp"
    filepath = Path(self.config.output_dir) / filename

        # ä¸‹è½½å›¾ç‰‡
        if not self._download_image(image_url, str(filepath)):
            return None

    # ç”Ÿæˆç›¸å¯¹è·¯å¾„ï¼ˆç»Ÿä¸€ä¸ºwebè·¯å¾„ï¼‰
    web_friendly_path = str(filepath).replace("\\", "/")
    relative_path = web_friendly_path.replace("static/", "/", 1)

        # æ›´æ–°ç¼“å­˜
        self.cache[content_hash] = {
            "title": title,
            "description": description[:200],
            "category": category,
            "image_path": str(filepath),
            "relative_path": relative_path,
            "prompt": prompt,
            "generated_at": str(Path().resolve())
        }
        self._save_cache()

        logger.info(f"Generated cover image: {relative_path}")
        return relative_path

class HugoArticleUpdater:
    """Hugoæ–‡ç« æ›´æ–°å™¨"""

    def __init__(self, content_dir: str = "content", generator: CoverImageGenerator = None):
        self.content_dir = Path(content_dir)
        self.generator = generator

    def find_articles_without_covers(self) -> list:
        """æŸ¥æ‰¾æ²¡æœ‰å°é¢çš„æ–‡ç« """
        articles = []

        for md_file in self.content_dir.rglob("*.md"):
            if md_file.name == "_index.md":
                continue

            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æfront matter
                if content.startswith('---'):
                    first_line_end = content.find('\n')
                    if first_line_end == -1:
                        continue

                    front_matter_end = content.find('\n---', first_line_end + 1)
                    if front_matter_end == -1:
                        continue

                    front_matter = content[first_line_end + 1:front_matter_end]
                    article_content = content[front_matter_end + 4:]

                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å›¾ç‰‡
                    has_cover = ('cover.image:' in front_matter or
                               'image:' in front_matter or
                               'ai_cover:' in front_matter)

                    # æ£€æŸ¥æ˜¯å¦æœ‰description
                    has_description = 'description:' in front_matter

                    if not has_cover and has_description:
                        articles.append(md_file)

            except Exception as e:
                logger.warning(f"Error processing {md_file}: {e}")

        return articles

    def update_article_with_cover(self, article_path: Path, image_path: str):
        """ä¸ºæ–‡ç« æ·»åŠ å°é¢å›¾ç‰‡"""
        try:
            with open(article_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if not content.startswith('---'):
                logger.warning(f"No front matter found in {article_path}")
                return False

            # Split content by the front matter delimiters
            parts = content.split('---', 2)
            if len(parts) < 3:
                logger.warning(f"Invalid front matter format in {article_path}")
                return False

            # parts[0] is empty (before first ---)
            # parts[1] is the front matter content
            # parts[2] is the article content
            front_matter = parts[1]
            article_content = parts[2]

            # è§£æå¿…è¦ä¿¡æ¯
            title = ""
            description = ""
            category = ""

            for line in front_matter.split('\n'):
                if line.startswith('title:'):
                    title = line.split(':', 1)[1].strip().strip('"\'')
                elif line.startswith('description:'):
                    description = line.split(':', 1)[1].strip().strip('"\'')
                elif line.startswith('categories:'):
                    # ç®€å•å¤„ç†ï¼Œå–ç¬¬ä¸€ä¸ªåˆ†ç±»
                    if '[' in line:
                        category = line.split('[', 1)[1].split(']', 1)[0].split(',')[0].strip().strip('"\'')

            if not title or not description:
                logger.warning(f"Missing title or description in {article_path}")
                return False

            # è½¬æ¢Windowsè·¯å¾„ä¸ºWebè·¯å¾„
            web_image_path = image_path.replace('\\', '/')

            # åœ¨front matterä¸­æ·»åŠ AIç”Ÿæˆå›¾ç‰‡ä¿¡æ¯
            cover_image_block = f"""
ai_cover: "{web_image_path}"
cover:
  image: "{web_image_path}"
  alt: "{title}"
  ai_generated: true
"""

            # ç¡®ä¿front matterä»¥æ¢è¡Œç¬¦ç»“æŸï¼Œç„¶åæ·»åŠ coverä¿¡æ¯
            if not front_matter.endswith('\n'):
                front_matter += '\n'

            updated_front_matter = front_matter + cover_image_block
            updated_content = f"---{updated_front_matter}---{article_content}"

            # å†™å›æ–‡ä»¶
            with open(article_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)

            logger.info(f"Updated {article_path} with cover image: {web_image_path}")
            return True

        except Exception as e:
            logger.error(f"Error updating {article_path}: {e}")
            return False

    def find_articles_with_descriptions(self) -> list:
        """æŸ¥æ‰¾æœ‰descriptionçš„æ–‡ç« """
        articles = []

        for md_file in self.content_dir.rglob("*.md"):
            if md_file.name == "_index.md":
                continue

            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æfront matter
                if content.startswith('---'):
                    first_line_end = content.find('\n')
                    if first_line_end == -1:
                        continue

                    front_matter_end = content.find('\n---', first_line_end + 1)
                    if front_matter_end == -1:
                        continue

                    front_matter = content[first_line_end + 1:front_matter_end]
                    article_content = content[front_matter_end + 4:]

                    # æ£€æŸ¥æ˜¯å¦æœ‰description
                    has_description = 'description:' in front_matter

                    if has_description:
                        articles.append(md_file)

            except Exception as e:
                logger.warning(f"Error processing {md_file}: {e}")

        return articles

    def has_ai_cover(self, article_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²æœ‰AIå°é¢"""
        try:
            with open(article_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if content.startswith('---'):
                first_line_end = content.find('\n')
                if first_line_end == -1:
                    return False

                front_matter_end = content.find('\n---', first_line_end + 1)
                if front_matter_end == -1:
                    return False

                front_matter = content[first_line_end + 1:front_matter_end]
                return 'ai_cover:' in front_matter

        except Exception as e:
            logger.warning(f"Error checking AI cover for {article_path}: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='AI Cover Image Generator for Hugo Blog')
    parser.add_argument('--workflow-mode', action='store_true', help='Run in workflow mode')
    parser.add_argument('--target', choices=['covers', 'articles'], default='covers', help='Generation target')
    parser.add_argument('--force', action='store_true', help='Force regenerate existing images')
    parser.add_argument('--limit', type=int, default=10, help='Limit number of articles to process')
    parser.add_argument('--specific-file', type=str, help='Process a specific file only')
    args = parser.parse_args()

    # é…ç½®
    api_provider = os.getenv("TEXT2IMAGE_PROVIDER", "modelscope")  # modelscope, openai
    workflow_mode = args.workflow_mode or os.getenv("WORKFLOW_MODE", "").lower() == "true"
    force_regenerate = args.force or os.getenv("FORCE_REGENERATE", "").lower() == "true"

    if api_provider == "modelscope":
        config = ImageGenConfig(
            api_provider="modelscope",
            api_key=os.getenv("MODELSCOPE_API_KEY", ""),
            model="Qwen/Qwen-Image",
            output_dir="static/images/generated-covers",
            style_suffix=", professional blog cover, clean design, technology theme, minimal"
        )

        if not config.api_key:
            logger.error("Please set MODELSCOPE_API_KEY environment variable")
            return

    elif api_provider == "openai":
        config = ImageGenConfig(
            api_provider="openai",
            api_key=os.getenv("OPENAI_API_KEY", ""),
            model="dall-e-3",
            output_dir="static/images/generated-covers",
            style_suffix=", professional blog cover, clean design, technology theme, minimal"
        )

        if not config.api_key:
            logger.error("Please set OPENAI_API_KEY environment variable")
            return
    else:
        logger.error(f"Unsupported provider: {api_provider}. Use 'modelscope' or 'openai'")
        return

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = CoverImageGenerator(config)

    if workflow_mode:
        logger.info("ğŸ¤– Running in GitHub Actions workflow mode")
        logger.info(f"Target: {args.target}, Force: {force_regenerate}, Limit: {args.limit}")

    # æŸ¥æ‰¾éœ€è¦å°é¢çš„æ–‡ç« 
    updater = HugoArticleUpdater(generator=generator)

    if args.specific_file:
        # å¤„ç†ç‰¹å®šæ–‡ä»¶
        if os.path.exists(args.specific_file):
            articles = [args.specific_file]
            logger.info(f"Processing specific file: {args.specific_file}")
        else:
            logger.error(f"File not found: {args.specific_file}")
            return
    elif force_regenerate:
        # å¼ºåˆ¶æ¨¡å¼ï¼šæŸ¥æ‰¾æ‰€æœ‰æœ‰descriptionçš„æ–‡ç« 
        articles = updater.find_articles_with_descriptions()
        logger.info(f"Force regenerate mode: Found {len(articles)} articles with descriptions")
    else:
        # æ­£å¸¸æ¨¡å¼ï¼šæŸ¥æ‰¾æ²¡æœ‰å°é¢çš„æ–‡ç« 
        articles = updater.find_articles_without_covers()
        logger.info(f"Found {len(articles)} articles without covers")

    # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆworkflowæ¨¡å¼ï¼Œä½†ä¸å½±å“ç‰¹å®šæ–‡ä»¶å¤„ç†ï¼‰
    if workflow_mode and not args.specific_file and args.limit > 0 and len(articles) > args.limit:
        articles = articles[:args.limit]
        logger.info(f"Limited to {args.limit} articles for workflow")

    # ä¸ºæ¯ç¯‡æ–‡ç« ç”Ÿæˆå°é¢
    success_count = 0
    for i, article_path in enumerate(articles):
        logger.info(f"Processing {i+1}/{len(articles)}: {article_path}")

        # è¯»å–æ–‡ç« ä¿¡æ¯
        with open(article_path, 'r', encoding='utf-8') as f:
            content = f.read()

        if content.startswith('---'):
            first_line_end = content.find('\n')
            if first_line_end == -1:
                front_matter = ""
            else:
                front_matter_end = content.find('\n---', first_line_end + 1)
                front_matter = content[first_line_end + 1:front_matter_end] if front_matter_end > 0 else ""
        else:
            front_matter = ""

        title = ""
        description = ""
        category = ""

        for line in front_matter.split('\n'):
            if line.startswith('title:'):
                title = line.split(':', 1)[1].strip().strip('"\'')
            elif line.startswith('description:'):
                description = line.split(':', 1)[1].strip().strip('"\'')
            elif line.startswith('categories:'):
                if '[' in line:
                    category = line.split('[', 1)[1].split(']', 1)[0].split(',')[0].strip().strip('"\'')

        if title and description:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰AIå°é¢ï¼ˆåœ¨forceæ¨¡å¼ä¸‹ï¼‰
            if force_regenerate and updater.has_ai_cover(article_path):
                logger.info(f"Skipping {article_path} - already has AI cover (use --force to override)")
                continue

            # ç”Ÿæˆå°é¢
            image_path = generator.generate_cover(title, description, category)

            if image_path:
                # æ›´æ–°æ–‡ç« 
                if updater.update_article_with_cover(article_path, image_path):
                    success_count += 1
                    logger.info(f"âœ… Successfully generated and updated cover for {article_path}")
                else:
                    logger.error(f"âŒ Failed to update article with cover {article_path}")
            else:
                logger.error(f"âŒ Failed to generate cover for {article_path}")
        else:
            logger.warning(f"âš ï¸ Skipping {article_path} - missing title or description")

        # é¿å…APIé™åˆ¶
        time.sleep(2)

    # ç”Ÿæˆå®ŒæˆæŠ¥å‘Š
    logger.info(f"ğŸ‰ AI cover generation completed!")
    logger.info(f"âœ… Successfully generated: {success_count}/{len(articles)} covers")

    if workflow_mode:
        logger.info(f"Workflow mode completed with {success_count} covers generated")

if __name__ == "__main__":
    main()