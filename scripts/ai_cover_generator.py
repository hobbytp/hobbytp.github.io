#!/usr/bin/env python3
"""
AI Cover Image Generator for Hugo Blog
æ ¹æ®æ–‡ç« descriptionè‡ªåŠ¨ç”Ÿæˆå°é¢å›¾ç‰‡
æ”¯æŒModelScope Qwen-imageå’ŒOpenAI DALL-E
"""

import os
import hashlib
import requests
import json
import argparse
from pathlib import Path
from typing import Optional, Dict
from dataclasses import dataclass
import logging
import time
from PIL import Image
from io import BytesIO

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰python-dotenvï¼Œæ‰‹åŠ¨è¯»å–.envæ–‡ä»¶
    env_file = Path('.env')
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value.strip('"').strip("'")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ImageGenConfig:
    """å›¾ç‰‡ç”Ÿæˆé…ç½®"""
    # APIé…ç½®
    api_provider: str = "volcengine"  # volcengine(é»˜è®¤), modelscope, openai
    api_key: str = ""
    model: str = "jimeng_t2i_v40"  # jimeng_t2i_v40, Qwen/Qwen-Image, dall-e-3

    # ç«å±±å¼•æ“é…ç½®ï¼ˆæ”¯æŒå³æ¢¦ç­‰æ¨¡å‹ï¼‰
    volcengine_base_url: str = "https://visual.volcengineapi.com"
    volcengine_region: str = "cn-north-1"
    volcengine_service: str = "cv"
    volcengine_access_key: str = ""  # ç«å±±å¼•æ“ Access Key
    volcengine_secret_key: str = ""  # ç«å±±å¼•æ“ Secret Key
    volcengine_model: str = "jimeng_t2i_v40"  # é»˜è®¤ä½¿ç”¨å³æ¢¦4.0
    volcengine_timeout: int = 300  # 5åˆ†é’Ÿè¶…æ—¶
    volcengine_retry_interval: int = 5  # 5ç§’é‡è¯•é—´éš”

    # ModelScopeé…ç½®
    modelscope_base_url: str = "https://api-inference.modelscope.cn/"
    modelscope_timeout: int = 300  # 5åˆ†é’Ÿè¶…æ—¶
    modelscope_retry_interval: int = 5  # 5ç§’é‡è¯•é—´éš”

    # OpenAIé…ç½®
    openai_base_url: str = "https://api.openai.com/v1/images/generations"

    # å›¾ç‰‡é…ç½® - æ¨ªå±å°ºå¯¸é€‚é…åšå®¢å¡ç‰‡å¤´éƒ¨
    # å³æ¢¦APIè¦æ±‚å®½é«˜ä¹˜ç§¯ >= 1024*1024ï¼Œä¸”æ¨è 2560x1440 (16:9)
    width: int = 2560  # æ¨ªå±å®½åº¦
    height: int = 1440   # æ¨ªå±é«˜åº¦ (16:9)
    quality: str = "standard"  # standard, hd
    style: str = "vivid"  # vivid, natural

    # å­˜å‚¨é…ç½®
    output_dir: str = "static/images/generated-covers"
    cache_dir: str = "cache/image-generation"

    # ç”Ÿæˆé…ç½®
    max_description_length: int = 1000
    style_suffix: str = ", abstract geometric pattern, professional blog cover, clean design, minimal, technology theme, no text, no letters, no words, no people, no faces, no portraits, landscape orientation, widescreen format"

class CoverImageGenerator:
    """å°é¢å›¾ç‰‡ç”Ÿæˆå™¨"""

    def __init__(self, config: ImageGenConfig):
        self.config = config
        self._ensure_directories()
        self._load_cache()

    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        Path(self.config.output_dir).mkdir(parents=True, exist_ok=True)
        Path(self.config.cache_dir).mkdir(parents=True, exist_ok=True)

    def _load_cache(self):
        """åŠ è½½ç”Ÿæˆç¼“å­˜"""
        self.cache_file = Path(self.config.cache_dir) / "generation_cache.json"
        if self.cache_file.exists():
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                self.cache = json.load(f)
        else:
            self.cache = {}

    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜"""
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(self.cache, f, ensure_ascii=False, indent=2)

    def _get_content_hash(self, title: str, description: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œä½œä¸ºç¼“å­˜é”®"""
        content = f"{title}|{description}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()

    def _optimize_description(self, description: str, title: str, category: str = "") -> str:
        """ä¼˜åŒ–æè¿°ä¸ºé€‚åˆå›¾ç‰‡ç”Ÿæˆçš„prompt"""
        # æˆªæ–­æè¿°
        if len(description) > 300:
            description = description[:300]

        # æå–å…³é”®è¯ä»¥å†³å®šé£æ ¼å€¾å‘
        text = f"{title} {description}".lower()
        
        # é»˜è®¤é£æ ¼å…ƒç´ 
        base_visuals = "æœªæ¥ç§‘æŠ€æ„Ÿï¼ŒæŠ½è±¡çº¿æ¡ï¼Œå…‰å½±äº¤é”™ï¼Œæµä½“å½¢æ€"
        color_tone = "å†·è‰²è°ƒï¼Œé«˜çº§æ„Ÿï¼Œæ¸å˜è‰²"
        
        # æ ¹æ®å…³é”®è¯è°ƒæ•´è§†è§‰å…ƒç´ å’Œé…è‰²
        if any(k in text for k in ['math', 'imo', 'number', 'logic', 'reasoning', 'geometry', 'æ•°å­¦', 'æ¨ç†', 'é€»è¾‘', 'å‡ ä½•', 'è¯æ˜']):
            base_visuals = "é»„é‡‘åˆ†å‰²ï¼Œåˆ†å½¢å‡ ä½•ï¼ŒæŸæ‹‰å›¾ç«‹ä½“ï¼ŒæŠ½è±¡æ•°å­¦ç¬¦å·ï¼Œç§©åºæ„Ÿï¼Œç†æ€§ç»“æ„ï¼Œæ‚¬æµ®çš„å‡ ä½•ä½“"
            color_tone = "æ·±é‚ƒè“ç´«è‰²ï¼Œæ­é…é‡‘è‰²çº¿æ¡ç‚¹ç¼€ï¼Œç¥ç§˜ï¼Œä¸¥è°¨"
        elif any(k in text for k in ['code', 'programming', 'software', 'github', 'linux', 'terminal', 'ä»£ç ', 'ç¼–ç¨‹', 'å¼€å‘', 'æºç ']):
            base_visuals = "æ•°å­—çŸ©é˜µï¼Œä»£ç æµï¼Œåƒç´ åŒ–æ„å»ºå—ï¼Œç»ˆç«¯ç•Œé¢å…ƒç´ ï¼Œèµ›åšç©ºé—´ï¼Œç”µè·¯æ¿çº¹ç†"
            color_tone = "é»‘å®¢ç»¿ï¼Œæš—é»‘èƒŒæ™¯ï¼Œéœ“è™¹å…‰æ•ˆï¼Œæå®¢é£"
        elif any(k in text for k in ['brain', 'neural', 'cognitive', 'think', 'llm', 'gpt', 'å¤§è„‘', 'ç¥ç»ç½‘ç»œ', 'è®¤çŸ¥', 'æ€è€ƒ', 'æ¨¡å‹']):
            base_visuals = "å‘å…‰çš„ç¥ç»å…ƒç½‘ç»œï¼Œçªè§¦è¿æ¥ï¼Œæ€ç»´ç«èŠ±ï¼Œç”Ÿç‰©ç§‘æŠ€èåˆï¼Œèƒ½é‡è„‰å†²ï¼Œæ™ºèƒ½ä½“"
            color_tone = "ç”µå…‰è“ï¼Œæ´‹çº¢ï¼Œç²‰ç´«æ¸å˜ï¼Œæ¢¦å¹»ï¼ŒçµåŠ¨"
        elif any(k in text for k in ['cloud', 'server', 'data', 'network', 'api', 'äº‘', 'æœåŠ¡å™¨', 'æ•°æ®', 'ç½‘ç»œ', 'è¿æ¥']):
            base_visuals = "äº‘ç«¯æ¶æ„ï¼Œé«˜é€Ÿæ•°æ®æµï¼Œäº’è”èŠ‚ç‚¹ï¼Œæ— é™å»¶ä¼¸çš„ç½‘æ ¼ï¼Œç»ç’ƒè´¨æ„Ÿï¼Œé€æ˜ä¼ è¾“"
            color_tone = "çº¯å‡€ç™½ï¼Œå¤©è“ï¼Œé’è‰²ï¼Œé€šé€æ„Ÿï¼Œè½»ç›ˆ"
        elif any(k in text for k in ['security', 'hack', 'privacy', 'lock', 'å®‰å…¨', 'é»‘å®¢', 'éšç§', 'åŠ å¯†']):
            base_visuals = "ç›¾ç‰Œæ¦‚å¿µï¼Œé”é“¾ï¼Œé˜²å¾¡ç½‘ï¼Œæ‰«æå…‰æŸï¼Œé‡‘å±è´¨æ„Ÿ"
            color_tone = "æ·±ç°ï¼Œé“¶è‰²ï¼Œè­¦ç¤ºçº¢å…‰ï¼Œåšç¡¬"

        # å°†æè¿°ä½œä¸ºè§†è§‰å…ƒç´ çš„ä¸€éƒ¨åˆ†ï¼Œå¢åŠ ç”»é¢çš„ç‹¬ç‰¹æ€§
        visual_elements = f"{base_visuals}ã€‚èåˆåŸºäº'{description}'çš„æŠ½è±¡æ¦‚å¿µå¯è§†åŒ–"

        # æ„å»ºä¸­æ–‡Prompt (é’ˆå¯¹å³æ¢¦/ç«å±±å¼•æ“ä¼˜åŒ–)
        prompt = (
            f"ä¸€å¼ æå…·è®¾è®¡æ„Ÿçš„åšå®¢å°é¢å›¾ã€‚ä¸»é¢˜ï¼š{title}ã€‚"
            f"æ ¸å¿ƒè§†è§‰å…ƒç´ ï¼š{visual_elements}ã€‚"
            f"è‰ºæœ¯é£æ ¼ï¼šC4D 3Dæ¸²æŸ“ï¼ŒOctane Renderï¼Œæç®€ä¸»ä¹‰ï¼Œè™šå¹»å¼•æ“5ç”»è´¨ï¼ŒTyndall effectï¼Œ8kåˆ†è¾¨ç‡ï¼Œè¶…é«˜æ¸…ï¼Œç»†èŠ‚ä¸°å¯Œã€‚"
            f"è‰²å½©æ°›å›´ï¼š{color_tone}ã€‚"
            f"æ„å›¾ï¼šå®½å±å£çº¸ï¼Œå¤§æ°”ç£…ç¤´ï¼Œç•™ç™½é€‚ä¸­ï¼Œä¸­å¿ƒæ„å›¾æˆ–ä¸‰åˆ†æ³•ã€‚"
            f"é‡è¦æç¤ºï¼šçº¯å›¾æ¡ˆèƒŒæ™¯ï¼Œç»å¯¹ä¸è¦åŒ…å«ä»»ä½•æ–‡å­—ã€å­—æ¯ã€æ•°å­—ã€æ‹¼éŸ³ã€æ±‰å­—ã€æ°´å°ã€LOGOã€‚ä¸è¦å‡ºç°äººè„¸ã€‚"
        )
        
        return prompt

    def _extract_keywords(self, description: str, title: str) -> str:
        """ä»æè¿°å’Œæ ‡é¢˜ä¸­æå–å…³é”®è¯ï¼Œç§»é™¤å¸¸è§çš„åœç”¨è¯"""
        import re

        # åˆå¹¶æ ‡é¢˜å’Œæè¿°
        text = f"{title} {description}".lower()

        # å¸¸è§çš„åœç”¨è¯å’Œä¸éœ€è¦è§†è§‰åŒ–çš„è¯
        stop_words = {
            'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'å¦‚æœ', 'å› ä¸º', 'æ‰€ä»¥', 'è¿™', 'é‚£', 'è¿™äº›', 'é‚£äº›',
            'the', 'a', 'an', 'and', 'or', 'but', 'if', 'because', 'so', 'this', 'that', 'these', 'those',
            'blog', 'article', 'post', 'news', 'report', 'analysis', 'review', 'guide', 'tutorial'
        }

        # æå–æŠ€æœ¯ç›¸å…³å…³é”®è¯
        tech_keywords = re.findall(r'\b(ai|artificial intelligence|machine learning|deep learning|neural network|algorithm|data|code|software|app|api|cloud|digital|technology|computer|programming|development|framework|model|system|platform|service|tool|automation|robot|chatbot|language model|llm|gpt|claude|openai|google|microsoft|apple|meta|tesla|bitcoin|blockchain|web3|metaverse|vr|ar|iot|edge|security|privacy|encryption|hack|cyber|quantum|5g|mobile|android|ios)\b', text)

        # å»é‡å¹¶ç§»é™¤åœç”¨è¯
        unique_keywords = []
        for word in tech_keywords:
            if word not in stop_words and word not in unique_keywords:
                unique_keywords.append(word)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŠ€æœ¯å…³é”®è¯ï¼Œä½¿ç”¨é€šç”¨çš„ç§‘æŠ€è¯æ±‡
        if not unique_keywords:
            unique_keywords = ['technology', 'digital', 'innovation', 'data', 'software']

        # é™åˆ¶å…³é”®è¯æ•°é‡
        return ' '.join(unique_keywords[:5])

    def _generate_with_modelscope(self, prompt: str) -> Optional[str]:
        """ä½¿ç”¨ModelScope Qwen-Imageç”Ÿæˆå›¾ç‰‡"""
        try:
            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json",
            }

            # æäº¤å¼‚æ­¥ä»»åŠ¡
            response = requests.post(
                f"{self.config.modelscope_base_url}v1/images/generations",
                headers={**headers, "X-ModelScope-Async-Mode": "true"},
                data=json.dumps({
                    "model": self.config.model,
                    "prompt": prompt,
                    "width": self.config.width,
                    "height": self.config.height
                }, ensure_ascii=False).encode('utf-8'),
                timeout=60
            )

            response.raise_for_status()
            task_id = response.json()["task_id"]
            logger.info(f"ModelScope task submitted: {task_id}")

            # è½®è¯¢ä»»åŠ¡çŠ¶æ€
            start_time = time.time()
            while True:
                if time.time() - start_time > self.config.modelscope_timeout:
                    logger.error(f"ModelScope task timeout after {self.config.modelscope_timeout} seconds")
                    return None

                result = requests.get(
                    f"{self.config.modelscope_base_url}v1/tasks/{task_id}",
                    headers={**headers, "X-ModelScope-Task-Type": "image_generation"},
                    timeout=30
                )
                result.raise_for_status()
                data = result.json()

                if data["task_status"] == "SUCCEED":
                    image_url = data["output_images"][0]
                    logger.info(f"ModelScope image generated successfully: {image_url}")
                    return image_url
                elif data["task_status"] == "FAILED":
                    error_msg = data.get("message", "Unknown error")
                    logger.error(f"ModelScope image generation failed: {error_msg}")
                    return None
                elif data["task_status"] == "RUNNING":
                    logger.info(f"ModelScope task running, elapsed: {int(time.time() - start_time)}s")
                    time.sleep(self.config.modelscope_retry_interval)
                else:
                    logger.warning(f"Unknown ModelScope task status: {data['task_status']}")
                    time.sleep(self.config.modelscope_retry_interval)

        except Exception as e:
            logger.error(f"ModelScope generation error: {e}")
            return None

    def _generate_with_volcengine(self, prompt: str) -> Optional[str]:
        """ä½¿ç”¨ç«å±±å¼•æ“è§†è§‰APIç”Ÿæˆå›¾ç‰‡ï¼ˆæ”¯æŒå³æ¢¦4.0ç­‰æ¨¡å‹ï¼‰"""
        try:
            import hashlib
            import hmac
            from datetime import datetime
            from urllib.parse import quote

            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "Action": "CVSync2AsyncSubmitTask",
                "Version": "2022-08-31"
            }
            
            # ä½¿ç”¨é…ç½®çš„æ¨¡å‹ï¼ˆé»˜è®¤jimeng_t2i_v40ï¼‰
            req_key = self.config.volcengine_model or "jimeng_t2i_v40"
            
            body = {
                "req_key": req_key,
                "prompt": prompt,
                "width": self.config.width,
                "height": self.config.height,
                "force_single": True  # å¼ºåˆ¶å•å›¾è¾“å‡º,æ§åˆ¶å»¶è¿Ÿå’Œæˆæœ¬
            }

            # ç«å±±å¼•æ“ç­¾åV4ï¼ˆä¿®æ­£ï¼šæŒ‰ç…§å®˜æ–¹HTTPæ–‡æ¡£å®ç°ï¼‰
            def sign_request(method, url, query_params, headers, payload):
                # è·å–å½“å‰æ—¶é—´
                from datetime import timezone
                now = datetime.now(timezone.utc)
                date_stamp = now.strftime('%Y%m%d')
                amz_date = now.strftime('%Y%m%dT%H%M%SZ')
                
                # è®¡ç®— payload hash
                payload_hash = hashlib.sha256(payload.encode('utf-8')).hexdigest()
                
                # Canonical Requestï¼ˆä¿®æ­£ï¼šæ·»åŠ  x-content-sha256ï¼‰
                canonical_uri = '/'
                # Queryå‚æ•°ç›´æ¥æ‹¼æ¥ï¼Œä¸è¿›è¡ŒURLç¼–ç ï¼ˆæŒ‰ç…§å®˜æ–¹Pythonç¤ºä¾‹ï¼‰
                canonical_querystring = '&'.join([f"{k}={v}" for k, v in sorted(query_params.items())])
                
                signed_headers = 'content-type;host;x-content-sha256;x-date'
                canonical_headers = f"content-type:{headers['Content-Type']}\nhost:{headers['Host']}\nx-content-sha256:{payload_hash}\nx-date:{amz_date}\n"
                
                canonical_request = f"{method}\n{canonical_uri}\n{canonical_querystring}\n{canonical_headers}\n{signed_headers}\n{payload_hash}"
                
                # String to Sign
                algorithm = 'HMAC-SHA256'
                credential_scope = f"{date_stamp}/{self.config.volcengine_region}/{self.config.volcengine_service}/request"
                string_to_sign = f"{algorithm}\n{amz_date}\n{credential_scope}\n{hashlib.sha256(canonical_request.encode('utf-8')).hexdigest()}"
                
                # Signing Keyï¼ˆä¿®æ­£ï¼šç§»é™¤VOLCå‰ç¼€ï¼Œä¸å®˜æ–¹Pythonç¤ºä¾‹ä¸€è‡´ï¼‰
                def get_signature_key(key, date_stamp, region_name, service_name):
                    k_date = hmac.new(key.encode('utf-8'), date_stamp.encode('utf-8'), hashlib.sha256).digest()
                    k_region = hmac.new(k_date, region_name.encode('utf-8'), hashlib.sha256).digest()
                    k_service = hmac.new(k_region, service_name.encode('utf-8'), hashlib.sha256).digest()
                    k_signing = hmac.new(k_service, b"request", hashlib.sha256).digest()
                    return k_signing
                
                signing_key = get_signature_key(self.config.volcengine_secret_key, date_stamp, self.config.volcengine_region, self.config.volcengine_service)
                signature = hmac.new(signing_key, string_to_sign.encode('utf-8'), hashlib.sha256).hexdigest()
                
                # Authorization Header
                authorization_header = f"{algorithm} Credential={self.config.volcengine_access_key}/{credential_scope}, SignedHeaders={signed_headers}, Signature={signature}"
                
                return authorization_header, amz_date, payload_hash

            # æ„å»ºURLå’ŒHeaders
            from urllib.parse import urlparse
            parsed_url = urlparse(self.config.volcengine_base_url)
            host = parsed_url.netloc
            url = self.config.volcengine_base_url
            
            headers = {
                "Content-Type": "application/json",
                "Host": host
            }
            
            payload = json.dumps(body, ensure_ascii=False)
            authorization, amz_date, payload_hash = sign_request('POST', url, params, headers, payload)
            
            headers['Authorization'] = authorization
            headers['X-Date'] = amz_date
            headers['X-Content-Sha256'] = payload_hash
            
            # æäº¤ä»»åŠ¡
            query_string = '&'.join([f"{k}={v}" for k, v in params.items()])
            submit_url = f"{url}?{query_string}"
            
            logger.info(f"Submitting Volcengine task (model: {req_key})...")
            
            response = requests.post(
                submit_url,
                headers=headers,
                data=payload,
                timeout=60
            )
            
            if response.status_code != 200:
                logger.error(f"Volcengine API Error: {response.status_code}")
                logger.error(f"Response Body: {response.text}")
                
                # Check for AccessDenied
                try:
                    err_data = response.json()
                    if err_data.get("ResponseMetadata", {}).get("Error", {}).get("Code") == "AccessDenied":
                        logger.error("âŒ æƒé™ä¸è¶³ (AccessDenied): è¯·æ£€æŸ¥ç«å±±å¼•æ“IAMç­–ç•¥ï¼Œç¡®ä¿æ‹¥æœ‰ 'cv:CVSync2AsyncSubmitTask' æƒé™")
                except:
                    pass
            
            response.raise_for_status()
            result = response.json()
            
            if result.get("code") != 10000:
                logger.error(f"Volcengine task submission failed: {result.get('message')}")
                return None
            
            task_id = result["data"]["task_id"]
            logger.info(f"Volcengine task submitted: {task_id}")
            
            # è½®è¯¢æŸ¥è¯¢ç»“æœ
            query_params = {
                "Action": "CVSync2AsyncGetResult",
                "Version": "2022-08-31"
            }
            
            query_body = {
                "req_key": req_key,
                "task_id": task_id,
                "req_json": json.dumps({"return_url": True}, ensure_ascii=False)
            }
            
            start_time = time.time()
            while True:
                if time.time() - start_time > self.config.volcengine_timeout:
                    logger.error(f"Volcengine task timeout after {self.config.volcengine_timeout} seconds")
                    return None
                
                # é‡æ–°ç­¾åæŸ¥è¯¢è¯·æ±‚
                query_payload = json.dumps(query_body, ensure_ascii=False)
                query_authorization, query_amz_date, query_payload_hash = sign_request('POST', url, query_params, headers, query_payload)
                
                query_headers = {
                    "Content-Type": "application/json",
                    "Host": host,
                    "Authorization": query_authorization,
                    "X-Date": query_amz_date,
                    "X-Content-Sha256": query_payload_hash
                }
                
                query_string = '&'.join([f"{k}={v}" for k, v in query_params.items()])
                query_url = f"{url}?{query_string}"
                
                result_response = requests.post(
                    query_url,
                    headers=query_headers,
                    data=query_payload,
                    timeout=30
                )
                
                if result_response.status_code != 200:
                    logger.error(f"Volcengine Query Error: {result_response.status_code}")
                    logger.error(f"Response Body: {result_response.text}")
                
                result_response.raise_for_status()
                query_result = result_response.json()
                
                if query_result.get("code") != 10000:
                    logger.error(f"Volcengine query failed: {query_result.get('message')}")
                    return None
                
                status = query_result["data"]["status"]
                
                if status == "done":
                    image_urls = query_result["data"].get("image_urls", [])
                    if image_urls:
                        image_url = image_urls[0]
                        logger.info(f"Volcengine image generated successfully: {image_url}")
                        return image_url
                    else:
                        logger.error("Volcengine generation completed but no image URLs returned")
                        return None
                elif status == "not_found":
                    logger.error("Volcengine task not found")
                    return None
                elif status == "expired":
                    logger.error("Volcengine task expired")
                    return None
                elif status in ["in_queue", "generating"]:
                    logger.info(f"Volcengine task {status}, elapsed: {int(time.time() - start_time)}s")
                    time.sleep(self.config.volcengine_retry_interval)
                else:
                    logger.warning(f"Unknown Volcengine task status: {status}")
                    time.sleep(self.config.volcengine_retry_interval)
                    
        except Exception as e:
            logger.error(f"Volcengine generation error: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    def _generate_with_openai(self, prompt: str) -> Optional[str]:
        """ä½¿ç”¨OpenAI DALL-Eç”Ÿæˆå›¾ç‰‡"""
        try:
            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json"
            }

            data = {
                "model": self.config.model,
                "prompt": prompt,
                "n": 1,
                "size": f"{self.config.width}x{self.config.height}",
                "quality": self.config.quality,
                "style": self.config.style
            }

            response = requests.post(
                self.config.openai_base_url,
                headers=headers,
                json=data,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                image_url = result["data"][0]["url"]
                return image_url
            else:
                logger.error(f"OpenAI API error: {response.status_code} - {response.text}")
                return None

        except Exception as e:
            logger.error(f"OpenAI generation error: {e}")
            return None

    def _download_image(self, url: str, filepath: str) -> bool:
        """ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡å¹¶è½¬æ¢ä¸ºwebpæ ¼å¼"""
        try:
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                # ä½¿ç”¨PILæ‰“å¼€å›¾ç‰‡ï¼ˆæ”¯æŒå„ç§æ ¼å¼ï¼‰
                image = Image.open(BytesIO(response.content))
                
                # å¦‚æœå›¾ç‰‡æœ‰é€æ˜é€šé“ï¼ˆRGBAï¼‰ï¼Œè½¬æ¢ä¸ºRGBä»¥æ”¯æŒwebp
                if image.mode in ('RGBA', 'LA', 'P'):
                    # åˆ›å»ºç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', image.size, (255, 255, 255))
                    if image.mode == 'P':
                        image = image.convert('RGBA')
                    background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                    image = background
                elif image.mode != 'RGB':
                    image = image.convert('RGB')
                
                # ä¿å­˜ä¸ºwebpæ ¼å¼ï¼Œä¼˜åŒ–è´¨é‡
                image.save(filepath, 'WEBP', quality=85, method=6)
                logger.info(f"Image converted to webp: {filepath}")
                return True
            else:
                logger.error(f"Image download error: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"Image download/convert error: {e}")
            return False

    def generate_cover(self, title: str, description: str, category: str = "", force: bool = False) -> Optional[str]:
        """
        ç”Ÿæˆå°é¢å›¾ç‰‡

        Args:
            title: æ–‡ç« æ ‡é¢˜
            description: æ–‡ç« æè¿°
            category: æ–‡ç« åˆ†ç±»
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆ

        Returns:
            å›¾ç‰‡URLè·¯å¾„ï¼ˆç›¸å¯¹äºstaticç›®å½•ï¼‰
        """
        # ç”Ÿæˆå†…å®¹å“ˆå¸Œ
        content_hash = self._get_content_hash(title, description)

        # æ£€æŸ¥ç¼“å­˜
        if not force and content_hash in self.cache:
            cached_path = self.cache[content_hash]["image_path"]
            if Path(cached_path).exists():
                logger.info(f"Using cached image: {cached_path}")
                return cached_path.replace("static/", "/", 1)

        # ç”Ÿæˆprompt
        prompt = self._optimize_description(description, title, category)
        logger.info(f"Generating image with prompt: {prompt[:1000]}...")

        # è°ƒç”¨AIç”Ÿæˆå›¾ç‰‡
        image_url = None
        if self.config.api_provider == "volcengine":
            image_url = self._generate_with_volcengine(prompt)
        elif self.config.api_provider == "modelscope":
            image_url = self._generate_with_modelscope(prompt)
        elif self.config.api_provider == "openai":
            image_url = self._generate_with_openai(prompt)
        else:
            logger.error(f"Unsupported API provider: {self.config.api_provider}")
            return None

        if not image_url:
            logger.error("Failed to generate image")
            return None

        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"{content_hash}.webp"
        filepath = Path(self.config.output_dir) / filename

        # ä¸‹è½½å›¾ç‰‡
        if not self._download_image(image_url, str(filepath)):
            return None

        # ç”Ÿæˆç›¸å¯¹è·¯å¾„ï¼ˆç»Ÿä¸€ä¸ºwebè·¯å¾„ï¼‰
        web_friendly_path = str(filepath).replace("\\", "/")
        relative_path = web_friendly_path.replace("static/", "/", 1)

        # æ›´æ–°ç¼“å­˜
        self.cache[content_hash] = {
            "title": title,
            "description": description[:200],
            "category": category,
            "image_path": str(filepath),
            "relative_path": relative_path,
            "prompt": prompt,
            "generated_at": str(Path().resolve())
        }
        self._save_cache()

        logger.info(f"Generated cover image: {relative_path}")
        return relative_path

class HugoArticleUpdater:
    """Hugoæ–‡ç« æ›´æ–°å™¨"""

    def __init__(self, content_dir: str = "content", generator: CoverImageGenerator = None):
        self.content_dir = Path(content_dir)
        self.generator = generator

    def find_articles_without_covers(self) -> list:
        """æŸ¥æ‰¾æ²¡æœ‰å°é¢çš„æ–‡ç« """
        articles = []

        for md_file in self.content_dir.rglob("*.md"):
            if md_file.name == "_index.md":
                continue

            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æfront matter
                if content.startswith('---'):
                    first_line_end = content.find('\n')
                    if first_line_end == -1:
                        continue

                    front_matter_end = content.find('\n---', first_line_end + 1)
                    if front_matter_end == -1:
                        continue

                    front_matter = content[first_line_end + 1:front_matter_end]
                    article_content = content[front_matter_end + 4:]

                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å›¾ç‰‡
                    has_cover = ('cover.image:' in front_matter or
                               'image:' in front_matter or
                               'ai_cover:' in front_matter)

                    # æ£€æŸ¥æ˜¯å¦æœ‰description
                    has_description = 'description:' in front_matter

                    if not has_cover and has_description:
                        articles.append(md_file)

            except Exception as e:
                logger.warning(f"Error processing {md_file}: {e}")

        return articles

    def update_article_with_cover(self, article_path: Path, image_path: str):
        """ä¸ºæ–‡ç« æ·»åŠ å°é¢å›¾ç‰‡"""
        try:
            with open(article_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if not content.startswith('---'):
                logger.warning(f"No front matter found in {article_path}")
                return False

            # Split content by the front matter delimiters
            parts = content.split('---', 2)
            if len(parts) < 3:
                logger.warning(f"Invalid front matter format in {article_path}")
                return False

            # parts[0] is empty (before first ---)
            # parts[1] is the front matter content
            # parts[2] is the article content
            front_matter = parts[1]
            article_content = parts[2]

            # è§£æå¿…è¦ä¿¡æ¯
            title = ""
            description = ""
            category = ""

            for line in front_matter.split('\n'):
                if line.startswith('title:'):
                    title = line.split(':', 1)[1].strip().strip('"\'')
                elif line.startswith('description:'):
                    description = line.split(':', 1)[1].strip().strip('"\'')
                elif line.startswith('categories:'):
                    # ç®€å•å¤„ç†ï¼Œå–ç¬¬ä¸€ä¸ªåˆ†ç±»
                    if '[' in line:
                        category = line.split('[', 1)[1].split(']', 1)[0].split(',')[0].strip().strip('"\'')

            if not title or not description:
                logger.warning(f"Missing title or description in {article_path}")
                return False

            # è½¬æ¢Windowsè·¯å¾„ä¸ºWebè·¯å¾„
            web_image_path = image_path.replace('\\', '/')

            # ç§»é™¤æ—§çš„å°é¢é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            lines = front_matter.split('\n')
            new_lines = []
            skip_mode = False
            
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å°é¢ç›¸å…³çš„é…ç½®è¡Œ
                if line.strip().startswith('ai_cover:') or \
                   line.strip().startswith('cover:') or \
                   (skip_mode and (line.strip().startswith('image:') or line.strip().startswith('alt:') or line.strip().startswith('ai_generated:'))):
                    
                    if line.strip().startswith('cover:'):
                        skip_mode = True
                    continue
                
                # å¦‚æœé‡åˆ°éç¼©è¿›çš„è¡Œï¼Œä¸”ä¸æ˜¯å°é¢é…ç½®ï¼Œåˆ™é€€å‡ºè·³è¿‡æ¨¡å¼
                if skip_mode and line.strip() and not line.startswith(' '):
                    skip_mode = False
                
                # å¦‚æœæ˜¯ç©ºè¡Œï¼Œä¹Ÿä¿ç•™ï¼ˆé™¤éåœ¨è·³è¿‡æ¨¡å¼ä¸­ï¼‰
                if skip_mode and not line.strip():
                    continue
                    
                new_lines.append(line)

            # é‡å»ºfront matter
            clean_front_matter = '\n'.join(new_lines).strip()

            # åœ¨front matterä¸­æ·»åŠ AIç”Ÿæˆå›¾ç‰‡ä¿¡æ¯
            cover_image_block = f"""
ai_cover: "{web_image_path}"
cover:
  image: "{web_image_path}"
  alt: "{title}"
  ai_generated: true"""

            updated_front_matter = f"{clean_front_matter}\n{cover_image_block}\n"
            updated_content = f"---{updated_front_matter}---{article_content}"

            # å†™å›æ–‡ä»¶
            with open(article_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)

            logger.info(f"Updated {article_path} with cover image: {web_image_path}")
            return True

        except Exception as e:
            logger.error(f"Error updating {article_path}: {e}")
            return False

    def find_articles_with_descriptions(self) -> list:
        """æŸ¥æ‰¾æœ‰descriptionçš„æ–‡ç« """
        articles = []

        for md_file in self.content_dir.rglob("*.md"):
            if md_file.name == "_index.md":
                continue

            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æfront matter
                if content.startswith('---'):
                    first_line_end = content.find('\n')
                    if first_line_end == -1:
                        continue

                    front_matter_end = content.find('\n---', first_line_end + 1)
                    if front_matter_end == -1:
                        continue

                    front_matter = content[first_line_end + 1:front_matter_end]
                    article_content = content[front_matter_end + 4:]

                    # æ£€æŸ¥æ˜¯å¦æœ‰description
                    has_description = 'description:' in front_matter

                    if has_description:
                        articles.append(md_file)

            except Exception as e:
                logger.warning(f"Error processing {md_file}: {e}")

        return articles

    def has_ai_cover(self, article_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²æœ‰AIå°é¢"""
        try:
            with open(article_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if content.startswith('---'):
                first_line_end = content.find('\n')
                if first_line_end == -1:
                    return False

                front_matter_end = content.find('\n---', first_line_end + 1)
                if front_matter_end == -1:
                    return False

                front_matter = content[first_line_end + 1:front_matter_end]
                return 'ai_cover:' in front_matter

        except Exception as e:
            logger.warning(f"Error checking AI cover for {article_path}: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='AI Cover Image Generator for Hugo Blog')
    parser.add_argument('--workflow-mode', action='store_true', help='Run in workflow mode')
    parser.add_argument('--target', choices=['covers', 'articles'], default='covers', help='Generation target')
    parser.add_argument('--force', action='store_true', help='Force regenerate existing images')
    parser.add_argument('--limit', type=int, default=10, help='Limit number of articles to process')
    parser.add_argument('--specific-file', type=str, help='Process a specific file only')
    args = parser.parse_args()

    # é…ç½®
    api_provider = os.getenv("TEXT2IMAGE_PROVIDER", "volcengine")  # volcengine(é»˜è®¤), modelscope, openai
    workflow_mode = args.workflow_mode or os.getenv("WORKFLOW_MODE", "").lower() == "true"
    force_regenerate = args.force or os.getenv("FORCE_REGENERATE", "").lower() == "true"

    if api_provider == "volcengine":
        # æ”¯æŒä»ç¯å¢ƒå˜é‡é…ç½®æ¨¡å‹ï¼ˆé»˜è®¤jimeng_t2i_v40ï¼‰
        volcengine_model = os.getenv("VOLCENGINE_MODEL", "jimeng_t2i_v40")
        
        # è·å–Access Keyå’ŒSecret Key
        # ç«å±±å¼•æ“APIå¯†é’¥æ ¼å¼è¯´æ˜ï¼š
        # - Access Key: æ˜æ–‡å­—ç¬¦ä¸²ï¼Œä»¥AKLTå¼€å¤´
        # - Secret Key: å¯èƒ½æ˜¯Base64ç¼–ç æˆ–æ˜æ–‡ï¼Œå…ˆå°è¯•ç›´æ¥ä½¿ç”¨
        import base64
        
        access_key_raw = os.getenv("VOLCENGINE_ACCESS_KEY", os.getenv("ARK_API_KEY", ""))
        secret_key_raw = os.getenv("VOLCENGINE_SECRET_KEY", os.getenv("ARK_SECRET_KEY", ""))
        
        # Access Key ç›´æ¥ä½¿ç”¨
        access_key = access_key_raw
        
        # Secret Key å…ˆå°è¯•ç›´æ¥ä½¿ç”¨ï¼ˆä¸è§£ç ï¼‰
        secret_key = secret_key_raw
        logger.info(f"âœ“ Using Access Key (length: {len(access_key)})")
        logger.info(f"âœ“ Using Secret Key (length: {len(secret_key)}, ends with: {'==' if secret_key.endswith('==') else 'other'})")
        
        config = ImageGenConfig(
            api_provider="volcengine",
            api_key="",  # ç«å±±å¼•æ“ä½¿ç”¨Access Key/Secret Keyè€Œéå•ä¸€API Key
            volcengine_access_key=access_key,
            volcengine_secret_key=secret_key,
            volcengine_model=volcengine_model,
            model=volcengine_model,
            output_dir="static/images/generated-covers",
            style_suffix=", professional blog cover, clean design, technology theme, minimal"
        )

        if not config.volcengine_access_key or not config.volcengine_secret_key:
            logger.error("âš ï¸  è­¦å‘Š: æœªè®¾ç½® VOLCENGINE_ACCESS_KEY æˆ– VOLCENGINE_SECRET_KEY ç¯å¢ƒå˜é‡")
            logger.error("è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ :")
            logger.error("  VOLCENGINE_ACCESS_KEY=AKLT... (æ˜æ–‡ï¼ŒAKLTå¼€å¤´)")
            logger.error("  VOLCENGINE_SECRET_KEY=...== (Base64ç¼–ç ï¼Œä»ç«å±±æ§åˆ¶å°è·å–)")
            logger.error("  VOLCENGINE_MODEL=jimeng_t2i_v40  # å¯é€‰ï¼Œé»˜è®¤å³æ¢¦4.0")
            logger.error("  VOLCENGINE_MODEL=jimeng_t2i_v40  # å¯é€‰ï¼Œé»˜è®¤å³æ¢¦4.0")
            return

    elif api_provider == "modelscope":
        config = ImageGenConfig(
            api_provider="modelscope",
            api_key=os.getenv("MODELSCOPE_API_KEY", ""),
            model="Qwen/Qwen-Image",
            output_dir="static/images/generated-covers",
            style_suffix=", professional blog cover, clean design, technology theme, minimal"
        )

        if not config.api_key:
            logger.error("Please set MODELSCOPE_API_KEY environment variable")
            return

    elif api_provider == "openai":
        config = ImageGenConfig(
            api_provider="openai",
            api_key=os.getenv("OPENAI_API_KEY", ""),
            model="dall-e-3",
            output_dir="static/images/generated-covers",
            style_suffix=", professional blog cover, clean design, technology theme, minimal"
        )

        if not config.api_key:
            logger.error("Please set OPENAI_API_KEY environment variable")
            return
    else:
        logger.error(f"Unsupported provider: {api_provider}. Use 'volcengine', 'modelscope' or 'openai'")
        return

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = CoverImageGenerator(config)

    if workflow_mode:
        logger.info("ğŸ¤– Running in GitHub Actions workflow mode")
        logger.info(f"Target: {args.target}, Force: {force_regenerate}, Limit: {args.limit}")

    # æŸ¥æ‰¾éœ€è¦å°é¢çš„æ–‡ç« 
    updater = HugoArticleUpdater(generator=generator)

    if args.specific_file:
        # å¤„ç†ç‰¹å®šæ–‡ä»¶æˆ–ç›®å½•
        path = Path(args.specific_file)
        if path.exists():
            if path.is_file():
                articles = [str(path)]
                logger.info(f"Processing specific file: {path}")
            elif path.is_dir():
                articles = [str(p) for p in path.rglob("*.md") if p.name != "_index.md"]
                logger.info(f"Processing directory: {path}, found {len(articles)} articles")
        else:
            logger.error(f"File or directory not found: {args.specific_file}")
            return
    elif force_regenerate:
        # å¼ºåˆ¶æ¨¡å¼ï¼šæŸ¥æ‰¾æ‰€æœ‰æœ‰descriptionçš„æ–‡ç« 
        articles = updater.find_articles_with_descriptions()
        logger.info(f"Force regenerate mode: Found {len(articles)} articles with descriptions")
    else:
        # æ­£å¸¸æ¨¡å¼ï¼šæŸ¥æ‰¾æ²¡æœ‰å°é¢çš„æ–‡ç« 
        articles = updater.find_articles_without_covers()
        logger.info(f"Found {len(articles)} articles without covers")

    # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆworkflowæ¨¡å¼ï¼Œä½†ä¸å½±å“ç‰¹å®šæ–‡ä»¶å¤„ç†ï¼‰
    if workflow_mode and not args.specific_file and args.limit > 0 and len(articles) > args.limit:
        articles = articles[:args.limit]
        logger.info(f"Limited to {args.limit} articles for workflow")

    # ä¸ºæ¯ç¯‡æ–‡ç« ç”Ÿæˆå°é¢
    success_count = 0
    for i, article_path in enumerate(articles):
        logger.info(f"Processing {i+1}/{len(articles)}: {article_path}")

        # è¯»å–æ–‡ç« ä¿¡æ¯
        with open(article_path, 'r', encoding='utf-8') as f:
            content = f.read()

        if content.startswith('---'):
            first_line_end = content.find('\n')
            if first_line_end == -1:
                front_matter = ""
            else:
                front_matter_end = content.find('\n---', first_line_end + 1)
                front_matter = content[first_line_end + 1:front_matter_end] if front_matter_end > 0 else ""
        else:
            front_matter = ""

        title = ""
        description = ""
        category = ""

        for line in front_matter.split('\n'):
            if line.startswith('title:'):
                title = line.split(':', 1)[1].strip().strip('"\'')
            elif line.startswith('description:'):
                description = line.split(':', 1)[1].strip().strip('"\'')
            elif line.startswith('categories:'):
                if '[' in line:
                    category = line.split('[', 1)[1].split(']', 1)[0].split(',')[0].strip().strip('"\'')

        if title and description:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰AIå°é¢
            if updater.has_ai_cover(article_path) and not force_regenerate:
                logger.info(f"Skipping {article_path} - already has AI cover (use --force to override)")
                continue

            # ç”Ÿæˆå°é¢
            image_path = generator.generate_cover(title, description, category)

            if image_path:
                # æ›´æ–°æ–‡ç« 
                if updater.update_article_with_cover(article_path, image_path):
                    success_count += 1
                    logger.info(f"âœ… Successfully generated and updated cover for {article_path}")
                else:
                    logger.error(f"âŒ Failed to update article with cover {article_path}")
            else:
                logger.error(f"âŒ Failed to generate cover for {article_path}")
        else:
            logger.warning(f"âš ï¸ Skipping {article_path} - missing title or description")

        # é¿å…APIé™åˆ¶
        time.sleep(2)

    # ç”Ÿæˆå®ŒæˆæŠ¥å‘Š
    logger.info(f"ğŸ‰ AI cover generation completed!")
    logger.info(f"âœ… Successfully generated: {success_count}/{len(articles)} covers")

    if workflow_mode:
        logger.info(f"Workflow mode completed with {success_count} covers generated")

if __name__ == "__main__":
    main()